{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Setting up imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pdb off\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "__author__ = \"Joseph Gomes\"\n",
    "__copyright__ = \"Copyright 2016, Stanford University\"\n",
    "__license__ = \"LGPL\"\n",
    "\n",
    "import os\n",
    "import unittest\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "\n",
    "from deepchem import metrics\n",
    "from deepchem.datasets import Dataset\n",
    "from deepchem.featurizers.featurize import DataFeaturizer\n",
    "from deepchem.hyperparameters import HyperparamOpt\n",
    "from deepchem.metrics import Metric\n",
    "from deepchem.models import Model\n",
    "from deepchem.models.tensorflow_models.fcnet import TensorflowMultiTaskRegressor\n",
    "from deepchem.models.tensorflow_models import TensorflowModel\n",
    "from deepchem.transformers import NormalizationTransformer\n",
    "from deepchem.utils.evaluate import Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating temporary directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_dir = tempfile.mkdtemp()\n",
    "train_dir = tempfile.mkdtemp()\n",
    "valid_dir = tempfile.mkdtemp()\n",
    "test_dir = tempfile.mkdtemp()\n",
    "model_dir = tempfile.mkdtemp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up model variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from deepchem.featurizers.coulomb_matrices import CoulombMatrixEig\n",
    "compound_featurizers = [CoulombMatrixEig(23, remove_hydrogens=False)]\n",
    "complex_featurizers = []\n",
    "tasks = [\"atomization_energy\"]\n",
    "task_type = \"regression\"\n",
    "task_types = {task: task_type for task in tasks}\n",
    "input_file = \"../datasets/gdb1k.sdf\"\n",
    "smiles_field = \"smiles\"\n",
    "mol_field = \"mol\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load featurized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featurizers = compound_featurizers + complex_featurizers\n",
    "featurizer = DataFeaturizer(tasks=tasks,\n",
    "                            smiles_field=smiles_field,\n",
    "                            mol_field=mol_field,\n",
    "                            featurizers=featurizers,\n",
    "                            verbosity=\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw samples now.\n",
      "Reading structures from ../datasets/gdb1k.sdf.\n",
      "Loaded shard 1 of size None from file.\n",
      "About to featurize shard.\n",
      "Applying processing transformation to shard.\n",
      "Currently featurizing feature_type: CoulombMatrixEig\n",
      "Featurizing sample 0\n",
      "About to start initializing dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joegomes/deepchem/deepchem/datasets/__init__.py:462: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  if features[feature_ind] == \"\":\n",
      "/home/joegomes/deepchem/deepchem/datasets/__init__.py:471: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  if y[ind, task] == \"\":\n"
     ]
    }
   ],
   "source": [
    "featurized_dataset = featurizer.featurize(input_file, feature_dir, shard_size=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Train, Validation, and Testing Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from deepchem.splits import RandomSplitter\n",
    "random_splitter = RandomSplitter()\n",
    "train_dataset, valid_dataset, test_dataset = random_splitter.train_valid_test_split(featurized_dataset,\n",
    "    train_dir, valid_dir, test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_transformers = [NormalizationTransformer(transform_X=True, dataset=train_dataset)]\n",
    "output_transformers = [NormalizationTransformer(transform_y=True, dataset=train_dataset)]\n",
    "transformers = input_transformers + output_transformers\n",
    "for transformer in transformers:\n",
    "    transformer.transform(train_dataset)\n",
    "for transformer in transformers:\n",
    "    transformer.transform(valid_dataset)\n",
    "for transformer in transformers:\n",
    "    transformer.transform(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Build a FCNet using Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model 1/8\n",
      "hyperparameters: {u'optimizer': u'rmsprop', u'layer_sizes': [1000, 1000, 100], u'data_shape': (23,), u'learning_rate': 0.0001, u'batch_size': 100, u'penalty': 0.0, u'bias_init_consts': [1.0, 1.0, 1.0], u'weight_init_stddevs': [0.077459666924148338, 0.077459666924148338, 0.077459666924148338], u'num_regression_tasks': 1, u'dropouts': [0.1, 0.1, 0.1], u'nb_epoch': 500, u'momentum': 0.9}\n",
      "Training for 500 epochs\n",
      "Ending epoch 0: loss 1.36035\n",
      "Ending epoch 1: loss 1.30184\n",
      "Ending epoch 2: loss 1.12685\n",
      "Ending epoch 3: loss 1.0381\n",
      "Ending epoch 4: loss 1.17485\n",
      "Ending epoch 5: loss 0.796555\n",
      "Ending epoch 6: loss 1.02207\n",
      "Ending epoch 7: loss 0.646329\n",
      "Ending epoch 8: loss 0.814315\n",
      "Ending epoch 9: loss 0.546832\n",
      "Ending epoch 10: loss 0.725649\n",
      "Ending epoch 11: loss 0.42637\n",
      "Ending epoch 12: loss 0.48826\n",
      "Ending epoch 13: loss 0.222245\n",
      "Ending epoch 14: loss 0.244443\n",
      "Ending epoch 15: loss 0.295166\n",
      "Ending epoch 16: loss 0.15471\n",
      "Ending epoch 17: loss 0.103894\n",
      "Ending epoch 18: loss 0.116969\n",
      "Ending epoch 19: loss 0.119632\n",
      "Ending epoch 20: loss 0.131814\n",
      "Ending epoch 21: loss 0.0726748\n",
      "Ending epoch 22: loss 0.0672342\n",
      "Ending epoch 23: loss 0.090519\n",
      "Ending epoch 24: loss 0.0643099\n",
      "Ending epoch 25: loss 0.0408836\n",
      "Ending epoch 26: loss 0.0418565\n",
      "Ending epoch 27: loss 0.0699464\n",
      "Ending epoch 28: loss 0.0476403\n",
      "Ending epoch 29: loss 0.0462395\n",
      "Ending epoch 30: loss 0.0524459\n",
      "Ending epoch 31: loss 0.0570136\n",
      "Ending epoch 32: loss 0.0402078\n",
      "Ending epoch 33: loss 0.0474686\n",
      "Ending epoch 34: loss 0.0461377\n",
      "Ending epoch 35: loss 0.0269026\n",
      "Ending epoch 36: loss 0.0406409\n",
      "Ending epoch 37: loss 0.0450361\n",
      "Ending epoch 38: loss 0.0539365\n",
      "Ending epoch 39: loss 0.0411016\n",
      "Ending epoch 40: loss 0.0341817\n",
      "Ending epoch 41: loss 0.032624\n",
      "Ending epoch 42: loss 0.0422184\n",
      "Ending epoch 43: loss 0.0372242\n",
      "Ending epoch 44: loss 0.0225117\n",
      "Ending epoch 45: loss 0.0255677\n",
      "Ending epoch 46: loss 0.0170791\n",
      "Ending epoch 47: loss 0.0360524\n",
      "Ending epoch 48: loss 0.0307417\n",
      "Ending epoch 49: loss 0.03488\n",
      "Ending epoch 50: loss 0.0189682\n",
      "Ending epoch 51: loss 0.030225\n",
      "Ending epoch 52: loss 0.0208301\n",
      "Ending epoch 53: loss 0.024648\n",
      "Ending epoch 54: loss 0.045711\n",
      "Ending epoch 55: loss 0.0264203\n",
      "Ending epoch 56: loss 0.0216523\n",
      "Ending epoch 57: loss 0.0304446\n",
      "Ending epoch 58: loss 0.0238859\n",
      "Ending epoch 59: loss 0.0266934\n",
      "Ending epoch 60: loss 0.0193\n",
      "Ending epoch 61: loss 0.0188482\n",
      "Ending epoch 62: loss 0.0366481\n",
      "Ending epoch 63: loss 0.02391\n",
      "Ending epoch 64: loss 0.0300643\n",
      "Ending epoch 65: loss 0.0199217\n",
      "Ending epoch 66: loss 0.022736\n",
      "Ending epoch 67: loss 0.0201766\n",
      "Ending epoch 68: loss 0.0226527\n",
      "Ending epoch 69: loss 0.0307271\n",
      "Ending epoch 70: loss 0.0203518\n",
      "Ending epoch 71: loss 0.0334964\n",
      "Ending epoch 72: loss 0.0266709\n",
      "Ending epoch 73: loss 0.0288182\n",
      "Ending epoch 74: loss 0.0285042\n",
      "Ending epoch 75: loss 0.022437\n",
      "Ending epoch 76: loss 0.0184745\n",
      "Ending epoch 77: loss 0.0240816\n",
      "Ending epoch 78: loss 0.021248\n",
      "Ending epoch 79: loss 0.0310496\n",
      "Ending epoch 80: loss 0.0238622\n",
      "Ending epoch 81: loss 0.0181497\n",
      "Ending epoch 82: loss 0.015349\n",
      "Ending epoch 83: loss 0.0238956\n",
      "Ending epoch 84: loss 0.017039\n",
      "Ending epoch 85: loss 0.020439\n",
      "Ending epoch 86: loss 0.02244\n",
      "Ending epoch 87: loss 0.0151816\n",
      "Ending epoch 88: loss 0.0194857\n",
      "Ending epoch 89: loss 0.0265809\n",
      "Ending epoch 90: loss 0.0215311\n",
      "Ending epoch 91: loss 0.0199141\n",
      "Ending epoch 92: loss 0.0221791\n",
      "Ending epoch 93: loss 0.014854\n",
      "Ending epoch 94: loss 0.0193601\n",
      "Ending epoch 95: loss 0.0188468\n",
      "Ending epoch 96: loss 0.0201052\n",
      "Ending epoch 97: loss 0.0196124\n",
      "Ending epoch 98: loss 0.0230605\n",
      "Ending epoch 99: loss 0.0207822\n",
      "Ending epoch 100: loss 0.0160266\n",
      "Ending epoch 101: loss 0.0215323\n",
      "Ending epoch 102: loss 0.0240483\n",
      "Ending epoch 103: loss 0.0189318\n",
      "Ending epoch 104: loss 0.0224917\n",
      "Ending epoch 105: loss 0.0273701\n",
      "Ending epoch 106: loss 0.0161326\n",
      "Ending epoch 107: loss 0.0209307\n",
      "Ending epoch 108: loss 0.0170188\n",
      "Ending epoch 109: loss 0.0199528\n",
      "Ending epoch 110: loss 0.0149382\n",
      "Ending epoch 111: loss 0.0178045\n",
      "Ending epoch 112: loss 0.0232842\n",
      "Ending epoch 113: loss 0.0181514\n",
      "Ending epoch 114: loss 0.024019\n",
      "Ending epoch 115: loss 0.0210169\n",
      "Ending epoch 116: loss 0.0282643\n",
      "Ending epoch 117: loss 0.0164147\n",
      "Ending epoch 118: loss 0.014465\n",
      "Ending epoch 119: loss 0.0144373\n",
      "Ending epoch 120: loss 0.0195604\n",
      "Ending epoch 121: loss 0.014438\n",
      "Ending epoch 122: loss 0.0144717\n",
      "Ending epoch 123: loss 0.0155709\n",
      "Ending epoch 124: loss 0.0199774\n",
      "Ending epoch 125: loss 0.0163946\n",
      "Ending epoch 126: loss 0.0172765\n",
      "Ending epoch 127: loss 0.0170669\n",
      "Ending epoch 128: loss 0.0197927\n",
      "Ending epoch 129: loss 0.0183057\n",
      "Ending epoch 130: loss 0.0190017\n",
      "Ending epoch 131: loss 0.0169681\n",
      "Ending epoch 132: loss 0.0194001\n",
      "Ending epoch 133: loss 0.0283259\n",
      "Ending epoch 134: loss 0.0157766\n",
      "Ending epoch 135: loss 0.0148821\n",
      "Ending epoch 136: loss 0.0131796\n",
      "Ending epoch 137: loss 0.0142487\n",
      "Ending epoch 138: loss 0.0224151\n",
      "Ending epoch 139: loss 0.0231514\n",
      "Ending epoch 140: loss 0.0138079\n",
      "Ending epoch 141: loss 0.018606\n",
      "Ending epoch 142: loss 0.0243612\n",
      "Ending epoch 143: loss 0.011895\n",
      "Ending epoch 144: loss 0.0149594\n",
      "Ending epoch 145: loss 0.0136293\n",
      "Ending epoch 146: loss 0.017598\n",
      "Ending epoch 147: loss 0.018709\n",
      "Ending epoch 148: loss 0.013153\n",
      "Ending epoch 149: loss 0.0131878\n",
      "Ending epoch 150: loss 0.0156796\n",
      "Ending epoch 151: loss 0.018611\n",
      "Ending epoch 152: loss 0.0151359\n",
      "Ending epoch 153: loss 0.0183792\n",
      "Ending epoch 154: loss 0.0238036\n",
      "Ending epoch 155: loss 0.015616\n",
      "Ending epoch 156: loss 0.0151722\n",
      "Ending epoch 157: loss 0.013026\n",
      "Ending epoch 158: loss 0.0125799\n",
      "Ending epoch 159: loss 0.0145542\n",
      "Ending epoch 160: loss 0.0143426\n",
      "Ending epoch 161: loss 0.0119449\n",
      "Ending epoch 162: loss 0.0155967\n",
      "Ending epoch 163: loss 0.0185394\n",
      "Ending epoch 164: loss 0.0167104\n",
      "Ending epoch 165: loss 0.0217674\n",
      "Ending epoch 166: loss 0.0152568\n",
      "Ending epoch 167: loss 0.0143404\n",
      "Ending epoch 168: loss 0.0148853\n",
      "Ending epoch 169: loss 0.016238\n",
      "Ending epoch 170: loss 0.0186907\n",
      "Ending epoch 171: loss 0.0254905\n",
      "Ending epoch 172: loss 0.0175589\n",
      "Ending epoch 173: loss 0.0124173\n",
      "Ending epoch 174: loss 0.0177116\n",
      "Ending epoch 175: loss 0.0146107\n",
      "Ending epoch 176: loss 0.0138058\n",
      "Ending epoch 177: loss 0.0112279\n",
      "Ending epoch 178: loss 0.0174127\n",
      "Ending epoch 179: loss 0.0181624\n",
      "Ending epoch 180: loss 0.0218982\n",
      "Ending epoch 181: loss 0.01754\n",
      "Ending epoch 182: loss 0.0157323\n",
      "Ending epoch 183: loss 0.0190189\n",
      "Ending epoch 184: loss 0.0190893\n",
      "Ending epoch 185: loss 0.0186117\n",
      "Ending epoch 186: loss 0.0134869\n",
      "Ending epoch 187: loss 0.0166201\n",
      "Ending epoch 188: loss 0.013964\n",
      "Ending epoch 189: loss 0.0140046\n",
      "Ending epoch 190: loss 0.0175967\n",
      "Ending epoch 191: loss 0.0167934\n",
      "Ending epoch 192: loss 0.0175423\n",
      "Ending epoch 193: loss 0.0154008\n",
      "Ending epoch 194: loss 0.0149367\n",
      "Ending epoch 195: loss 0.0175468\n",
      "Ending epoch 196: loss 0.0149411\n",
      "Ending epoch 197: loss 0.0161936\n",
      "Ending epoch 198: loss 0.0150586\n",
      "Ending epoch 199: loss 0.012876\n",
      "Ending epoch 200: loss 0.0146039\n",
      "Ending epoch 201: loss 0.0176512\n",
      "Ending epoch 202: loss 0.0173698\n",
      "Ending epoch 203: loss 0.0194483\n",
      "Ending epoch 204: loss 0.0110232\n",
      "Ending epoch 205: loss 0.0137678\n",
      "Ending epoch 206: loss 0.0139873\n",
      "Ending epoch 207: loss 0.0171511\n",
      "Ending epoch 208: loss 0.0139259\n",
      "Ending epoch 209: loss 0.0173143\n",
      "Ending epoch 210: loss 0.0118098\n",
      "Ending epoch 211: loss 0.0110848\n",
      "Ending epoch 212: loss 0.0147857\n",
      "Ending epoch 213: loss 0.0155847\n",
      "Ending epoch 214: loss 0.0125399\n",
      "Ending epoch 215: loss 0.0172979\n",
      "Ending epoch 216: loss 0.0225355\n",
      "Ending epoch 217: loss 0.0185346\n",
      "Ending epoch 218: loss 0.0154472\n",
      "Ending epoch 219: loss 0.0166431\n",
      "Ending epoch 220: loss 0.0176596\n",
      "Ending epoch 221: loss 0.0135967\n",
      "Ending epoch 222: loss 0.0160386\n",
      "Ending epoch 223: loss 0.011028\n",
      "Ending epoch 224: loss 0.0147114\n",
      "Ending epoch 225: loss 0.0141015\n",
      "Ending epoch 226: loss 0.0135168\n",
      "Ending epoch 227: loss 0.0133502\n",
      "Ending epoch 228: loss 0.0170998\n",
      "Ending epoch 229: loss 0.0176862\n",
      "Ending epoch 230: loss 0.0110747\n",
      "Ending epoch 231: loss 0.0143659\n",
      "Ending epoch 232: loss 0.0142449\n",
      "Ending epoch 233: loss 0.0203058\n",
      "Ending epoch 234: loss 0.0140439\n",
      "Ending epoch 235: loss 0.00910611\n",
      "Ending epoch 236: loss 0.0119522\n",
      "Ending epoch 237: loss 0.0115513\n",
      "Ending epoch 238: loss 0.0140661\n",
      "Ending epoch 239: loss 0.0123867\n",
      "Ending epoch 240: loss 0.017216\n",
      "Ending epoch 241: loss 0.0163234\n",
      "Ending epoch 242: loss 0.0155027\n",
      "Ending epoch 243: loss 0.012659\n",
      "Ending epoch 244: loss 0.0131847\n",
      "Ending epoch 245: loss 0.0100707\n",
      "Ending epoch 246: loss 0.0175701\n",
      "Ending epoch 247: loss 0.0142043\n",
      "Ending epoch 248: loss 0.0142429\n",
      "Ending epoch 249: loss 0.0133229\n",
      "Ending epoch 250: loss 0.0120223\n",
      "Ending epoch 251: loss 0.0115366\n",
      "Ending epoch 252: loss 0.0144467\n",
      "Ending epoch 253: loss 0.0126751\n",
      "Ending epoch 254: loss 0.0147356\n",
      "Ending epoch 255: loss 0.0129619\n",
      "Ending epoch 256: loss 0.0184\n",
      "Ending epoch 257: loss 0.0139923\n",
      "Ending epoch 258: loss 0.0192095\n",
      "Ending epoch 259: loss 0.0183413\n",
      "Ending epoch 260: loss 0.012765\n",
      "Ending epoch 261: loss 0.0137406\n",
      "Ending epoch 262: loss 0.0112915\n",
      "Ending epoch 263: loss 0.014702\n",
      "Ending epoch 264: loss 0.010878\n",
      "Ending epoch 265: loss 0.0124531\n",
      "Ending epoch 266: loss 0.0113886\n",
      "Ending epoch 267: loss 0.0145184\n",
      "Ending epoch 268: loss 0.014222\n",
      "Ending epoch 269: loss 0.0119169\n",
      "Ending epoch 270: loss 0.010151\n",
      "Ending epoch 271: loss 0.0106391\n",
      "Ending epoch 272: loss 0.0156318\n",
      "Ending epoch 273: loss 0.013759\n",
      "Ending epoch 274: loss 0.0122331\n",
      "Ending epoch 275: loss 0.0176963\n",
      "Ending epoch 276: loss 0.0160364\n",
      "Ending epoch 277: loss 0.0133526\n",
      "Ending epoch 278: loss 0.0104161\n",
      "Ending epoch 279: loss 0.00896801\n",
      "Ending epoch 280: loss 0.0130205\n",
      "Ending epoch 281: loss 0.0168174\n",
      "Ending epoch 282: loss 0.020819\n",
      "Ending epoch 283: loss 0.0121138\n",
      "Ending epoch 284: loss 0.0125386\n",
      "Ending epoch 285: loss 0.0136669\n",
      "Ending epoch 286: loss 0.0137101\n",
      "Ending epoch 287: loss 0.0100874\n",
      "Ending epoch 288: loss 0.0140437\n",
      "Ending epoch 289: loss 0.0138863\n",
      "Ending epoch 290: loss 0.0132608\n",
      "Ending epoch 291: loss 0.0119658\n",
      "Ending epoch 292: loss 0.0103237\n",
      "Ending epoch 293: loss 0.014474\n",
      "Ending epoch 294: loss 0.0122897\n",
      "Ending epoch 295: loss 0.0144766\n",
      "Ending epoch 296: loss 0.0120212\n",
      "Ending epoch 297: loss 0.0142073\n",
      "Ending epoch 298: loss 0.00976039\n",
      "Ending epoch 299: loss 0.00934573\n",
      "Ending epoch 300: loss 0.0115279\n",
      "Ending epoch 301: loss 0.0118354\n",
      "Ending epoch 302: loss 0.0156911\n",
      "Ending epoch 303: loss 0.0124194\n",
      "Ending epoch 304: loss 0.0112334\n",
      "Ending epoch 305: loss 0.0169604\n",
      "Ending epoch 306: loss 0.00958339\n",
      "Ending epoch 307: loss 0.0121684\n",
      "Ending epoch 308: loss 0.0116319\n",
      "Ending epoch 309: loss 0.0106395\n",
      "Ending epoch 310: loss 0.0191675\n",
      "Ending epoch 311: loss 0.0117861\n",
      "Ending epoch 312: loss 0.0187915\n",
      "Ending epoch 313: loss 0.0162298\n",
      "Ending epoch 314: loss 0.0132032\n",
      "Ending epoch 315: loss 0.0102536\n",
      "Ending epoch 316: loss 0.0162066\n",
      "Ending epoch 317: loss 0.00987537\n",
      "Ending epoch 318: loss 0.017754\n",
      "Ending epoch 319: loss 0.012291\n",
      "Ending epoch 320: loss 0.00997488\n",
      "Ending epoch 321: loss 0.0162402\n",
      "Ending epoch 322: loss 0.0127884\n",
      "Ending epoch 323: loss 0.0138234\n",
      "Ending epoch 324: loss 0.0125555\n",
      "Ending epoch 325: loss 0.0114286\n",
      "Ending epoch 326: loss 0.0114462\n",
      "Ending epoch 327: loss 0.0139409\n",
      "Ending epoch 328: loss 0.0100475\n",
      "Ending epoch 329: loss 0.0128139\n",
      "Ending epoch 330: loss 0.0124873\n",
      "Ending epoch 331: loss 0.012627\n",
      "Ending epoch 332: loss 0.0102518\n",
      "Ending epoch 333: loss 0.0142843\n",
      "Ending epoch 334: loss 0.0128394\n",
      "Ending epoch 335: loss 0.0164707\n",
      "Ending epoch 336: loss 0.0111835\n",
      "Ending epoch 337: loss 0.0118789\n",
      "Ending epoch 338: loss 0.0140167\n",
      "Ending epoch 339: loss 0.0117883\n",
      "Ending epoch 340: loss 0.0117273\n",
      "Ending epoch 341: loss 0.00991868\n",
      "Ending epoch 342: loss 0.0129132\n",
      "Ending epoch 343: loss 0.00981099\n",
      "Ending epoch 344: loss 0.0134192\n",
      "Ending epoch 345: loss 0.00944684\n",
      "Ending epoch 346: loss 0.0101669\n",
      "Ending epoch 347: loss 0.0102044\n",
      "Ending epoch 348: loss 0.0111189\n",
      "Ending epoch 349: loss 0.0110109\n",
      "Ending epoch 350: loss 0.0136146\n",
      "Ending epoch 351: loss 0.00980574\n",
      "Ending epoch 352: loss 0.0128627\n",
      "Ending epoch 353: loss 0.0117371\n",
      "Ending epoch 354: loss 0.0149209\n",
      "Ending epoch 355: loss 0.01269\n",
      "Ending epoch 356: loss 0.0148634\n",
      "Ending epoch 357: loss 0.0115132\n",
      "Ending epoch 358: loss 0.011454\n",
      "Ending epoch 359: loss 0.0111056\n",
      "Ending epoch 360: loss 0.010375\n",
      "Ending epoch 361: loss 0.0137895\n",
      "Ending epoch 362: loss 0.0131692\n",
      "Ending epoch 363: loss 0.0103503\n",
      "Ending epoch 364: loss 0.0115078\n",
      "Ending epoch 365: loss 0.0122488\n",
      "Ending epoch 366: loss 0.0103292\n",
      "Ending epoch 367: loss 0.0114153\n",
      "Ending epoch 368: loss 0.0141624\n",
      "Ending epoch 369: loss 0.00871855\n",
      "Ending epoch 370: loss 0.00911782\n",
      "Ending epoch 371: loss 0.0138142\n",
      "Ending epoch 372: loss 0.00929451\n",
      "Ending epoch 373: loss 0.0159984\n",
      "Ending epoch 374: loss 0.0138102\n",
      "Ending epoch 375: loss 0.0123168\n",
      "Ending epoch 376: loss 0.0110655\n",
      "Ending epoch 377: loss 0.0136596\n",
      "Ending epoch 378: loss 0.0161989\n",
      "Ending epoch 379: loss 0.0146738\n",
      "Ending epoch 380: loss 0.00991777\n",
      "Ending epoch 381: loss 0.00731442\n",
      "Ending epoch 382: loss 0.0154422\n",
      "Ending epoch 383: loss 0.0130813\n",
      "Ending epoch 384: loss 0.0103157\n",
      "Ending epoch 385: loss 0.0105061\n",
      "Ending epoch 386: loss 0.0114306\n",
      "Ending epoch 387: loss 0.0104885\n",
      "Ending epoch 388: loss 0.0104838\n",
      "Ending epoch 389: loss 0.0120823\n",
      "Ending epoch 390: loss 0.0112973\n",
      "Ending epoch 391: loss 0.0133703\n",
      "Ending epoch 392: loss 0.0112411\n",
      "Ending epoch 393: loss 0.0117291\n",
      "Ending epoch 394: loss 0.011735\n",
      "Ending epoch 395: loss 0.0142747\n",
      "Ending epoch 396: loss 0.0122315\n",
      "Ending epoch 397: loss 0.013371\n",
      "Ending epoch 398: loss 0.0151849\n",
      "Ending epoch 399: loss 0.00936977\n",
      "Ending epoch 400: loss 0.0186411\n",
      "Ending epoch 401: loss 0.0100016\n",
      "Ending epoch 402: loss 0.0121863\n",
      "Ending epoch 403: loss 0.0115387\n",
      "Ending epoch 404: loss 0.0125872\n",
      "Ending epoch 405: loss 0.0109996\n",
      "Ending epoch 406: loss 0.0115964\n",
      "Ending epoch 407: loss 0.0125751\n",
      "Ending epoch 408: loss 0.0100365\n",
      "Ending epoch 409: loss 0.0152619\n",
      "Ending epoch 410: loss 0.010323\n",
      "Ending epoch 411: loss 0.0100626\n",
      "Ending epoch 412: loss 0.015075\n",
      "Ending epoch 413: loss 0.0120132\n",
      "Ending epoch 414: loss 0.0109049\n",
      "Ending epoch 415: loss 0.00895801\n",
      "Ending epoch 416: loss 0.00992222\n",
      "Ending epoch 417: loss 0.0137235\n",
      "Ending epoch 418: loss 0.00958224\n",
      "Ending epoch 419: loss 0.0102213\n",
      "Ending epoch 420: loss 0.0112576\n",
      "Ending epoch 421: loss 0.0140619\n",
      "Ending epoch 422: loss 0.0132617\n",
      "Ending epoch 423: loss 0.0122533\n",
      "Ending epoch 424: loss 0.0104607\n",
      "Ending epoch 425: loss 0.0132221\n",
      "Ending epoch 426: loss 0.00865713\n",
      "Ending epoch 427: loss 0.0133641\n",
      "Ending epoch 428: loss 0.0123715\n",
      "Ending epoch 429: loss 0.0115852\n",
      "Ending epoch 430: loss 0.0106014\n",
      "Ending epoch 431: loss 0.0126373\n",
      "Ending epoch 432: loss 0.0096258\n",
      "Ending epoch 433: loss 0.0131973\n",
      "Ending epoch 434: loss 0.0112583\n",
      "Ending epoch 435: loss 0.0126369\n",
      "Ending epoch 436: loss 0.0093579\n",
      "Ending epoch 437: loss 0.0105665\n",
      "Ending epoch 438: loss 0.0183991\n",
      "Ending epoch 439: loss 0.01476\n",
      "Ending epoch 440: loss 0.0149405\n",
      "Ending epoch 441: loss 0.0134776\n",
      "Ending epoch 442: loss 0.0104318\n",
      "Ending epoch 443: loss 0.0129136\n",
      "Ending epoch 444: loss 0.010291\n",
      "Ending epoch 445: loss 0.0181278\n",
      "Ending epoch 446: loss 0.0146645\n",
      "Ending epoch 447: loss 0.0071332\n",
      "Ending epoch 448: loss 0.0112746\n",
      "Ending epoch 449: loss 0.0114763\n",
      "Ending epoch 450: loss 0.0182182\n",
      "Ending epoch 451: loss 0.0136266\n",
      "Ending epoch 452: loss 0.010465\n",
      "Ending epoch 453: loss 0.0106753\n",
      "Ending epoch 454: loss 0.0149112\n",
      "Ending epoch 455: loss 0.0149487\n",
      "Ending epoch 456: loss 0.012075\n",
      "Ending epoch 457: loss 0.0138645\n",
      "Ending epoch 458: loss 0.0152542\n",
      "Ending epoch 459: loss 0.0148183\n",
      "Ending epoch 460: loss 0.00930083\n",
      "Ending epoch 461: loss 0.0118958\n",
      "Ending epoch 462: loss 0.0093545\n",
      "Ending epoch 463: loss 0.0141129\n",
      "Ending epoch 464: loss 0.0126712\n",
      "Ending epoch 465: loss 0.0104065\n",
      "Ending epoch 466: loss 0.0134456\n",
      "Ending epoch 467: loss 0.00912282\n",
      "Ending epoch 468: loss 0.0105387\n",
      "Ending epoch 469: loss 0.0113587\n",
      "Ending epoch 470: loss 0.0104295\n",
      "Ending epoch 471: loss 0.00975544\n",
      "Ending epoch 472: loss 0.0118342\n",
      "Ending epoch 473: loss 0.011416\n",
      "Ending epoch 474: loss 0.0162766\n",
      "Ending epoch 475: loss 0.00949501\n",
      "Ending epoch 476: loss 0.0088043\n",
      "Ending epoch 477: loss 0.0129728\n",
      "Ending epoch 478: loss 0.0100355\n",
      "Ending epoch 479: loss 0.0138231\n",
      "Ending epoch 480: loss 0.0163234\n",
      "Ending epoch 481: loss 0.0108262\n",
      "Ending epoch 482: loss 0.00965548\n",
      "Ending epoch 483: loss 0.0134472\n",
      "Ending epoch 484: loss 0.00918051\n",
      "Ending epoch 485: loss 0.0102152\n",
      "Ending epoch 486: loss 0.0125283\n",
      "Ending epoch 487: loss 0.0124164\n",
      "Ending epoch 488: loss 0.0146393\n",
      "Ending epoch 489: loss 0.0107961\n",
      "Ending epoch 490: loss 0.0155212\n",
      "Ending epoch 491: loss 0.0118627\n",
      "Ending epoch 492: loss 0.0107183\n",
      "Ending epoch 493: loss 0.0111872\n",
      "Ending epoch 494: loss 0.0129036\n",
      "Ending epoch 495: loss 0.0109636\n",
      "Ending epoch 496: loss 0.0109941\n",
      "Ending epoch 497: loss 0.0106029\n",
      "Ending epoch 498: loss 0.00981679\n",
      "Ending epoch 499: loss 0.0101234\n",
      "Model 1/8, Metric mean_absolute_error, Validation set 0: 29.728272\n",
      "\tbest_validation_score so far: 29.728272\n",
      "Fitting model 2/8\n",
      "hyperparameters: {u'optimizer': u'rmsprop', u'layer_sizes': [1000, 1000, 50], u'data_shape': (23,), u'learning_rate': 0.0001, u'batch_size': 100, u'penalty': 0.0, u'bias_init_consts': [1.0, 1.0, 1.0], u'weight_init_stddevs': [0.077459666924148338, 0.077459666924148338, 0.077459666924148338], u'num_regression_tasks': 1, u'dropouts': [0.1, 0.1, 0.1], u'nb_epoch': 500, u'momentum': 0.9}\n",
      "Training for 500 epochs\n",
      "Ending epoch 0: loss 1.45318\n",
      "Ending epoch 1: loss 1.14847\n",
      "Ending epoch 2: loss 1.07289\n",
      "Ending epoch 3: loss 0.819117\n",
      "Ending epoch 4: loss 0.713238\n",
      "Ending epoch 5: loss 0.704838\n",
      "Ending epoch 6: loss 0.517199\n",
      "Ending epoch 7: loss 0.368434\n",
      "Ending epoch 8: loss 0.461701\n",
      "Ending epoch 9: loss 0.300106\n",
      "Ending epoch 10: loss 0.201147\n",
      "Ending epoch 11: loss 0.183958\n",
      "Ending epoch 12: loss 0.155989\n",
      "Ending epoch 13: loss 0.137694\n",
      "Ending epoch 14: loss 0.109914\n",
      "Ending epoch 15: loss 0.0703143\n",
      "Ending epoch 16: loss 0.0659588\n",
      "Ending epoch 17: loss 0.118173\n",
      "Ending epoch 18: loss 0.0920533\n",
      "Ending epoch 19: loss 0.0691732\n",
      "Ending epoch 20: loss 0.0975035\n",
      "Ending epoch 21: loss 0.0908102\n",
      "Ending epoch 22: loss 0.0565876\n",
      "Ending epoch 23: loss 0.0472339\n",
      "Ending epoch 24: loss 0.0663922\n",
      "Ending epoch 25: loss 0.0653694\n",
      "Ending epoch 26: loss 0.0429387\n",
      "Ending epoch 27: loss 0.0750517\n",
      "Ending epoch 28: loss 0.0465841\n",
      "Ending epoch 29: loss 0.0597147\n",
      "Ending epoch 30: loss 0.0437091\n",
      "Ending epoch 31: loss 0.0713656\n",
      "Ending epoch 32: loss 0.0566503\n",
      "Ending epoch 33: loss 0.0458928\n",
      "Ending epoch 34: loss 0.0504527\n",
      "Ending epoch 35: loss 0.0356177\n",
      "Ending epoch 36: loss 0.0409344\n",
      "Ending epoch 37: loss 0.0346624\n",
      "Ending epoch 38: loss 0.048678\n",
      "Ending epoch 39: loss 0.0441516\n",
      "Ending epoch 40: loss 0.0527222\n",
      "Ending epoch 41: loss 0.029915\n",
      "Ending epoch 42: loss 0.035322\n",
      "Ending epoch 43: loss 0.0444015\n",
      "Ending epoch 44: loss 0.0349204\n",
      "Ending epoch 45: loss 0.0454073\n",
      "Ending epoch 46: loss 0.0439533\n",
      "Ending epoch 47: loss 0.0367455\n",
      "Ending epoch 48: loss 0.0343142\n",
      "Ending epoch 49: loss 0.0241443\n",
      "Ending epoch 50: loss 0.0274564\n",
      "Ending epoch 51: loss 0.0332416\n",
      "Ending epoch 52: loss 0.0294874\n",
      "Ending epoch 53: loss 0.0508908\n",
      "Ending epoch 54: loss 0.0426219\n",
      "Ending epoch 55: loss 0.037969\n",
      "Ending epoch 56: loss 0.0461278\n",
      "Ending epoch 57: loss 0.0297394\n",
      "Ending epoch 58: loss 0.0460813\n",
      "Ending epoch 59: loss 0.035703\n",
      "Ending epoch 60: loss 0.0249538\n",
      "Ending epoch 61: loss 0.0371915\n",
      "Ending epoch 62: loss 0.030681\n",
      "Ending epoch 63: loss 0.0278156\n",
      "Ending epoch 64: loss 0.0298433\n",
      "Ending epoch 65: loss 0.0244476\n",
      "Ending epoch 66: loss 0.0554294\n",
      "Ending epoch 67: loss 0.0251307\n",
      "Ending epoch 68: loss 0.0335416\n",
      "Ending epoch 69: loss 0.0347002\n",
      "Ending epoch 70: loss 0.0327137\n",
      "Ending epoch 71: loss 0.0444393\n",
      "Ending epoch 72: loss 0.0456139\n",
      "Ending epoch 73: loss 0.041808\n",
      "Ending epoch 74: loss 0.0396017\n",
      "Ending epoch 75: loss 0.0330096\n",
      "Ending epoch 76: loss 0.0377337\n",
      "Ending epoch 77: loss 0.0221219\n",
      "Ending epoch 78: loss 0.0428033\n",
      "Ending epoch 79: loss 0.0309141\n",
      "Ending epoch 80: loss 0.039516\n",
      "Ending epoch 81: loss 0.0260162\n",
      "Ending epoch 82: loss 0.024508\n",
      "Ending epoch 83: loss 0.028177\n",
      "Ending epoch 84: loss 0.0321361\n",
      "Ending epoch 85: loss 0.0390609\n",
      "Ending epoch 86: loss 0.0250335\n",
      "Ending epoch 87: loss 0.0226112\n",
      "Ending epoch 88: loss 0.0343553\n",
      "Ending epoch 89: loss 0.0318904\n",
      "Ending epoch 90: loss 0.0310153\n",
      "Ending epoch 91: loss 0.0438004\n",
      "Ending epoch 92: loss 0.0265714\n",
      "Ending epoch 93: loss 0.0264213\n",
      "Ending epoch 94: loss 0.02282\n",
      "Ending epoch 95: loss 0.0349345\n",
      "Ending epoch 96: loss 0.0185912\n",
      "Ending epoch 97: loss 0.0295158\n",
      "Ending epoch 98: loss 0.0267312\n",
      "Ending epoch 99: loss 0.0247556\n",
      "Ending epoch 100: loss 0.0253464\n",
      "Ending epoch 101: loss 0.0370329\n",
      "Ending epoch 102: loss 0.0189255\n",
      "Ending epoch 103: loss 0.0211972\n",
      "Ending epoch 104: loss 0.0304517\n",
      "Ending epoch 105: loss 0.0270457\n",
      "Ending epoch 106: loss 0.0263036\n",
      "Ending epoch 107: loss 0.023918\n",
      "Ending epoch 108: loss 0.0233348\n",
      "Ending epoch 109: loss 0.0173554\n",
      "Ending epoch 110: loss 0.0278503\n",
      "Ending epoch 111: loss 0.0270989\n",
      "Ending epoch 112: loss 0.0180305\n",
      "Ending epoch 113: loss 0.023872\n",
      "Ending epoch 114: loss 0.0242822\n",
      "Ending epoch 115: loss 0.0268243\n",
      "Ending epoch 116: loss 0.0268401\n",
      "Ending epoch 117: loss 0.0168186\n",
      "Ending epoch 118: loss 0.0212581\n",
      "Ending epoch 119: loss 0.0178908\n",
      "Ending epoch 120: loss 0.0286693\n",
      "Ending epoch 121: loss 0.020625\n",
      "Ending epoch 122: loss 0.0347863\n",
      "Ending epoch 123: loss 0.0275197\n",
      "Ending epoch 124: loss 0.021581\n",
      "Ending epoch 125: loss 0.032565\n",
      "Ending epoch 126: loss 0.0183863\n",
      "Ending epoch 127: loss 0.0342897\n",
      "Ending epoch 128: loss 0.0266093\n",
      "Ending epoch 129: loss 0.0239528\n",
      "Ending epoch 130: loss 0.0361325\n",
      "Ending epoch 131: loss 0.0158355\n",
      "Ending epoch 132: loss 0.0254013\n",
      "Ending epoch 133: loss 0.0301783\n",
      "Ending epoch 134: loss 0.0327886\n",
      "Ending epoch 135: loss 0.0248894\n",
      "Ending epoch 136: loss 0.0229627\n",
      "Ending epoch 137: loss 0.0283574\n",
      "Ending epoch 138: loss 0.0233503\n",
      "Ending epoch 139: loss 0.0244259\n",
      "Ending epoch 140: loss 0.0258837\n",
      "Ending epoch 141: loss 0.0316639\n",
      "Ending epoch 142: loss 0.0217972\n",
      "Ending epoch 143: loss 0.0246628\n",
      "Ending epoch 144: loss 0.0214289\n",
      "Ending epoch 145: loss 0.0213088\n",
      "Ending epoch 146: loss 0.0278811\n",
      "Ending epoch 147: loss 0.0229323\n",
      "Ending epoch 148: loss 0.0208886\n",
      "Ending epoch 149: loss 0.0228515\n",
      "Ending epoch 150: loss 0.0182051\n",
      "Ending epoch 151: loss 0.0168121\n",
      "Ending epoch 152: loss 0.0233922\n",
      "Ending epoch 153: loss 0.0260656\n",
      "Ending epoch 154: loss 0.0305814\n",
      "Ending epoch 155: loss 0.0235981\n",
      "Ending epoch 156: loss 0.0233859\n",
      "Ending epoch 157: loss 0.0250744\n",
      "Ending epoch 158: loss 0.0302138\n",
      "Ending epoch 159: loss 0.0163346\n",
      "Ending epoch 160: loss 0.0162183\n",
      "Ending epoch 161: loss 0.0351701\n",
      "Ending epoch 162: loss 0.0300646\n",
      "Ending epoch 163: loss 0.026868\n",
      "Ending epoch 164: loss 0.0228136\n",
      "Ending epoch 165: loss 0.0219357\n",
      "Ending epoch 166: loss 0.0307354\n",
      "Ending epoch 167: loss 0.0228566\n",
      "Ending epoch 168: loss 0.0216149\n",
      "Ending epoch 169: loss 0.0190177\n",
      "Ending epoch 170: loss 0.0234866\n",
      "Ending epoch 171: loss 0.0303261\n",
      "Ending epoch 172: loss 0.0196213\n",
      "Ending epoch 173: loss 0.0217317\n",
      "Ending epoch 174: loss 0.0229332\n",
      "Ending epoch 175: loss 0.0266536\n",
      "Ending epoch 176: loss 0.0230664\n",
      "Ending epoch 177: loss 0.0179553\n",
      "Ending epoch 178: loss 0.0163953\n",
      "Ending epoch 179: loss 0.0230746\n",
      "Ending epoch 180: loss 0.0221245\n",
      "Ending epoch 181: loss 0.0228152\n",
      "Ending epoch 182: loss 0.0144693\n",
      "Ending epoch 183: loss 0.01832\n",
      "Ending epoch 184: loss 0.0223724\n",
      "Ending epoch 185: loss 0.0189139\n",
      "Ending epoch 186: loss 0.0162746\n",
      "Ending epoch 187: loss 0.0157191\n",
      "Ending epoch 188: loss 0.0192869\n",
      "Ending epoch 189: loss 0.0125988\n",
      "Ending epoch 190: loss 0.0249615\n",
      "Ending epoch 191: loss 0.0246926\n",
      "Ending epoch 192: loss 0.0257095\n",
      "Ending epoch 193: loss 0.0281192\n",
      "Ending epoch 194: loss 0.0204846\n",
      "Ending epoch 195: loss 0.0195309\n",
      "Ending epoch 196: loss 0.0273661\n",
      "Ending epoch 197: loss 0.0195591\n",
      "Ending epoch 198: loss 0.0249222\n",
      "Ending epoch 199: loss 0.0175443\n",
      "Ending epoch 200: loss 0.0212006\n",
      "Ending epoch 201: loss 0.0203757\n",
      "Ending epoch 202: loss 0.0255082\n",
      "Ending epoch 203: loss 0.0177656\n",
      "Ending epoch 204: loss 0.0186134\n",
      "Ending epoch 205: loss 0.0341311\n",
      "Ending epoch 206: loss 0.0197579\n",
      "Ending epoch 207: loss 0.0195565\n",
      "Ending epoch 208: loss 0.0176064\n",
      "Ending epoch 209: loss 0.0149023\n",
      "Ending epoch 210: loss 0.021111\n",
      "Ending epoch 211: loss 0.0162021\n",
      "Ending epoch 212: loss 0.0200006\n",
      "Ending epoch 213: loss 0.0249861\n",
      "Ending epoch 214: loss 0.025159\n",
      "Ending epoch 215: loss 0.0173675\n",
      "Ending epoch 216: loss 0.0153366\n",
      "Ending epoch 217: loss 0.0174414\n",
      "Ending epoch 218: loss 0.023619\n",
      "Ending epoch 219: loss 0.0154206\n",
      "Ending epoch 220: loss 0.0269074\n",
      "Ending epoch 221: loss 0.0203755\n",
      "Ending epoch 222: loss 0.0183644\n",
      "Ending epoch 223: loss 0.024851\n",
      "Ending epoch 224: loss 0.018656\n",
      "Ending epoch 225: loss 0.0212755\n",
      "Ending epoch 226: loss 0.020277\n",
      "Ending epoch 227: loss 0.0246992\n",
      "Ending epoch 228: loss 0.0183958\n",
      "Ending epoch 229: loss 0.0158433\n",
      "Ending epoch 230: loss 0.023615\n",
      "Ending epoch 231: loss 0.0197756\n",
      "Ending epoch 232: loss 0.01844\n",
      "Ending epoch 233: loss 0.0295826\n",
      "Ending epoch 234: loss 0.0187509\n",
      "Ending epoch 235: loss 0.020391\n",
      "Ending epoch 236: loss 0.0304997\n",
      "Ending epoch 237: loss 0.024583\n",
      "Ending epoch 238: loss 0.0205241\n",
      "Ending epoch 239: loss 0.0274167\n",
      "Ending epoch 240: loss 0.0186695\n",
      "Ending epoch 241: loss 0.0249851\n",
      "Ending epoch 242: loss 0.0199975\n",
      "Ending epoch 243: loss 0.0155613\n",
      "Ending epoch 244: loss 0.0164837\n",
      "Ending epoch 245: loss 0.0214719\n",
      "Ending epoch 246: loss 0.0250641\n",
      "Ending epoch 247: loss 0.0226489\n",
      "Ending epoch 248: loss 0.024561\n",
      "Ending epoch 249: loss 0.0201719\n",
      "Ending epoch 250: loss 0.0180676\n",
      "Ending epoch 251: loss 0.0226623\n",
      "Ending epoch 252: loss 0.0217533\n",
      "Ending epoch 253: loss 0.0135278\n",
      "Ending epoch 254: loss 0.0248696\n",
      "Ending epoch 255: loss 0.0206664\n",
      "Ending epoch 256: loss 0.024447\n",
      "Ending epoch 257: loss 0.0179577\n",
      "Ending epoch 258: loss 0.0146617\n",
      "Ending epoch 259: loss 0.019521\n",
      "Ending epoch 260: loss 0.0202959\n",
      "Ending epoch 261: loss 0.0220046\n",
      "Ending epoch 262: loss 0.0273778\n",
      "Ending epoch 263: loss 0.0222301\n",
      "Ending epoch 264: loss 0.0176583\n",
      "Ending epoch 265: loss 0.0168151\n",
      "Ending epoch 266: loss 0.018875\n",
      "Ending epoch 267: loss 0.0207307\n",
      "Ending epoch 268: loss 0.0255481\n",
      "Ending epoch 269: loss 0.0142256\n",
      "Ending epoch 270: loss 0.0238415\n",
      "Ending epoch 271: loss 0.027455\n",
      "Ending epoch 272: loss 0.0160581\n",
      "Ending epoch 273: loss 0.0175562\n",
      "Ending epoch 274: loss 0.0193493\n",
      "Ending epoch 275: loss 0.0221226\n",
      "Ending epoch 276: loss 0.0223014\n",
      "Ending epoch 277: loss 0.0161625\n",
      "Ending epoch 278: loss 0.0342638\n",
      "Ending epoch 279: loss 0.0194564\n",
      "Ending epoch 280: loss 0.015109\n",
      "Ending epoch 281: loss 0.0161656\n",
      "Ending epoch 282: loss 0.015846\n",
      "Ending epoch 283: loss 0.0226776\n",
      "Ending epoch 284: loss 0.0224147\n",
      "Ending epoch 285: loss 0.017603\n",
      "Ending epoch 286: loss 0.0208409\n",
      "Ending epoch 287: loss 0.0160783\n",
      "Ending epoch 288: loss 0.0152013\n",
      "Ending epoch 289: loss 0.0158528\n",
      "Ending epoch 290: loss 0.0170878\n",
      "Ending epoch 291: loss 0.0212696\n",
      "Ending epoch 292: loss 0.0212615\n",
      "Ending epoch 293: loss 0.0167198\n",
      "Ending epoch 294: loss 0.0182457\n",
      "Ending epoch 295: loss 0.0165322\n",
      "Ending epoch 296: loss 0.016822\n",
      "Ending epoch 297: loss 0.0166345\n",
      "Ending epoch 298: loss 0.0191429\n",
      "Ending epoch 299: loss 0.0284919\n",
      "Ending epoch 300: loss 0.0205395\n",
      "Ending epoch 301: loss 0.0184027\n",
      "Ending epoch 302: loss 0.0225408\n",
      "Ending epoch 303: loss 0.0167483\n",
      "Ending epoch 304: loss 0.0169216\n",
      "Ending epoch 305: loss 0.0149195\n",
      "Ending epoch 306: loss 0.0170347\n",
      "Ending epoch 307: loss 0.0187372\n",
      "Ending epoch 308: loss 0.0187961\n",
      "Ending epoch 309: loss 0.0179567\n",
      "Ending epoch 310: loss 0.0188771\n",
      "Ending epoch 311: loss 0.0218577\n",
      "Ending epoch 312: loss 0.0218085\n",
      "Ending epoch 313: loss 0.011336\n",
      "Ending epoch 314: loss 0.0222941\n",
      "Ending epoch 315: loss 0.0183249\n",
      "Ending epoch 316: loss 0.0176021\n",
      "Ending epoch 317: loss 0.0222339\n",
      "Ending epoch 318: loss 0.0183565\n",
      "Ending epoch 319: loss 0.018499\n",
      "Ending epoch 320: loss 0.0155219\n",
      "Ending epoch 321: loss 0.0149316\n",
      "Ending epoch 322: loss 0.0187955\n",
      "Ending epoch 323: loss 0.0203051\n",
      "Ending epoch 324: loss 0.0170519\n",
      "Ending epoch 325: loss 0.0213363\n",
      "Ending epoch 326: loss 0.0171786\n",
      "Ending epoch 327: loss 0.0125836\n",
      "Ending epoch 328: loss 0.0206473\n",
      "Ending epoch 329: loss 0.0192991\n",
      "Ending epoch 330: loss 0.0154229\n",
      "Ending epoch 331: loss 0.0177487\n",
      "Ending epoch 332: loss 0.019249\n",
      "Ending epoch 333: loss 0.0164815\n",
      "Ending epoch 334: loss 0.0194669\n",
      "Ending epoch 335: loss 0.0181646\n",
      "Ending epoch 336: loss 0.0120876\n",
      "Ending epoch 337: loss 0.0147599\n",
      "Ending epoch 338: loss 0.0170927\n",
      "Ending epoch 339: loss 0.0140242\n",
      "Ending epoch 340: loss 0.0154432\n",
      "Ending epoch 341: loss 0.0180473\n",
      "Ending epoch 342: loss 0.0283718\n",
      "Ending epoch 343: loss 0.0266581\n",
      "Ending epoch 344: loss 0.0189553\n",
      "Ending epoch 345: loss 0.0236776\n",
      "Ending epoch 346: loss 0.0180095\n",
      "Ending epoch 347: loss 0.0180987\n",
      "Ending epoch 348: loss 0.0145726\n",
      "Ending epoch 349: loss 0.0213188\n",
      "Ending epoch 350: loss 0.0178928\n",
      "Ending epoch 351: loss 0.0159344\n",
      "Ending epoch 352: loss 0.0178228\n",
      "Ending epoch 353: loss 0.021472\n",
      "Ending epoch 354: loss 0.0213378\n",
      "Ending epoch 355: loss 0.0230472\n",
      "Ending epoch 356: loss 0.017366\n",
      "Ending epoch 357: loss 0.0159035\n",
      "Ending epoch 358: loss 0.0137136\n",
      "Ending epoch 359: loss 0.0170179\n",
      "Ending epoch 360: loss 0.0196808\n",
      "Ending epoch 361: loss 0.0146\n",
      "Ending epoch 362: loss 0.0159142\n",
      "Ending epoch 363: loss 0.0187818\n",
      "Ending epoch 364: loss 0.0205682\n",
      "Ending epoch 365: loss 0.0157792\n",
      "Ending epoch 366: loss 0.0229376\n",
      "Ending epoch 367: loss 0.0157979\n",
      "Ending epoch 368: loss 0.0156355\n",
      "Ending epoch 369: loss 0.0203179\n",
      "Ending epoch 370: loss 0.0146587\n",
      "Ending epoch 371: loss 0.0193225\n",
      "Ending epoch 372: loss 0.0180116\n",
      "Ending epoch 373: loss 0.0148777\n",
      "Ending epoch 374: loss 0.0160816\n",
      "Ending epoch 375: loss 0.0192513\n",
      "Ending epoch 376: loss 0.0115484\n",
      "Ending epoch 377: loss 0.0181339\n",
      "Ending epoch 378: loss 0.0170297\n",
      "Ending epoch 379: loss 0.021517\n",
      "Ending epoch 380: loss 0.0160275\n",
      "Ending epoch 381: loss 0.0158339\n",
      "Ending epoch 382: loss 0.0137085\n",
      "Ending epoch 383: loss 0.0185282\n",
      "Ending epoch 384: loss 0.0209822\n",
      "Ending epoch 385: loss 0.0211983\n",
      "Ending epoch 386: loss 0.0171113\n",
      "Ending epoch 387: loss 0.0107706\n",
      "Ending epoch 388: loss 0.0203536\n",
      "Ending epoch 389: loss 0.0147748\n",
      "Ending epoch 390: loss 0.0142724\n",
      "Ending epoch 391: loss 0.0178577\n",
      "Ending epoch 392: loss 0.0203463\n",
      "Ending epoch 393: loss 0.0197508\n",
      "Ending epoch 394: loss 0.021868\n",
      "Ending epoch 395: loss 0.0157157\n",
      "Ending epoch 396: loss 0.0160656\n",
      "Ending epoch 397: loss 0.0169053\n",
      "Ending epoch 398: loss 0.0212339\n",
      "Ending epoch 399: loss 0.0222761\n",
      "Ending epoch 400: loss 0.019111\n",
      "Ending epoch 401: loss 0.0186434\n",
      "Ending epoch 402: loss 0.0213293\n",
      "Ending epoch 403: loss 0.0204904\n",
      "Ending epoch 404: loss 0.0166794\n",
      "Ending epoch 405: loss 0.0142647\n",
      "Ending epoch 406: loss 0.0129592\n",
      "Ending epoch 407: loss 0.0167595\n",
      "Ending epoch 408: loss 0.0163382\n",
      "Ending epoch 409: loss 0.0190534\n",
      "Ending epoch 410: loss 0.017003\n",
      "Ending epoch 411: loss 0.0193305\n",
      "Ending epoch 412: loss 0.0160606\n",
      "Ending epoch 413: loss 0.018331\n",
      "Ending epoch 414: loss 0.0221954\n",
      "Ending epoch 415: loss 0.0170404\n",
      "Ending epoch 416: loss 0.0118378\n",
      "Ending epoch 417: loss 0.0179194\n",
      "Ending epoch 418: loss 0.0173843\n",
      "Ending epoch 419: loss 0.0211982\n",
      "Ending epoch 420: loss 0.0207625\n",
      "Ending epoch 421: loss 0.0129625\n",
      "Ending epoch 422: loss 0.016269\n",
      "Ending epoch 423: loss 0.0151003\n",
      "Ending epoch 424: loss 0.0157326\n",
      "Ending epoch 425: loss 0.0212538\n",
      "Ending epoch 426: loss 0.0186658\n",
      "Ending epoch 427: loss 0.0119976\n",
      "Ending epoch 428: loss 0.0146119\n",
      "Ending epoch 429: loss 0.0197899\n",
      "Ending epoch 430: loss 0.0158707\n",
      "Ending epoch 431: loss 0.0128199\n",
      "Ending epoch 432: loss 0.0156115\n",
      "Ending epoch 433: loss 0.0143063\n",
      "Ending epoch 434: loss 0.0116003\n",
      "Ending epoch 435: loss 0.0230931\n",
      "Ending epoch 436: loss 0.0168637\n",
      "Ending epoch 437: loss 0.0127209\n",
      "Ending epoch 438: loss 0.0155458\n",
      "Ending epoch 439: loss 0.0161922\n",
      "Ending epoch 440: loss 0.0145519\n",
      "Ending epoch 441: loss 0.0139774\n",
      "Ending epoch 442: loss 0.0137331\n",
      "Ending epoch 443: loss 0.0152115\n",
      "Ending epoch 444: loss 0.0173406\n",
      "Ending epoch 445: loss 0.0105173\n",
      "Ending epoch 446: loss 0.0142893\n",
      "Ending epoch 447: loss 0.0148939\n",
      "Ending epoch 448: loss 0.0137737\n",
      "Ending epoch 449: loss 0.0136652\n",
      "Ending epoch 450: loss 0.0125169\n",
      "Ending epoch 451: loss 0.016256\n",
      "Ending epoch 452: loss 0.0130119\n",
      "Ending epoch 453: loss 0.0112323\n",
      "Ending epoch 454: loss 0.0144095\n",
      "Ending epoch 455: loss 0.0182866\n",
      "Ending epoch 456: loss 0.0153045\n",
      "Ending epoch 457: loss 0.0183737\n",
      "Ending epoch 458: loss 0.0110097\n",
      "Ending epoch 459: loss 0.0208452\n",
      "Ending epoch 460: loss 0.0114592\n",
      "Ending epoch 461: loss 0.0165626\n",
      "Ending epoch 462: loss 0.00858625\n",
      "Ending epoch 463: loss 0.0123427\n",
      "Ending epoch 464: loss 0.0154411\n",
      "Ending epoch 465: loss 0.0113157\n",
      "Ending epoch 466: loss 0.0184291\n",
      "Ending epoch 467: loss 0.0118175\n",
      "Ending epoch 468: loss 0.0162867\n",
      "Ending epoch 469: loss 0.0150317\n",
      "Ending epoch 470: loss 0.0156483\n",
      "Ending epoch 471: loss 0.0115804\n",
      "Ending epoch 472: loss 0.0181996\n",
      "Ending epoch 473: loss 0.0184264\n",
      "Ending epoch 474: loss 0.0164184\n",
      "Ending epoch 475: loss 0.00892069\n",
      "Ending epoch 476: loss 0.0132328\n",
      "Ending epoch 477: loss 0.0150162\n",
      "Ending epoch 478: loss 0.020852\n",
      "Ending epoch 479: loss 0.0138558\n",
      "Ending epoch 480: loss 0.0213426\n",
      "Ending epoch 481: loss 0.0143617\n",
      "Ending epoch 482: loss 0.0200588\n",
      "Ending epoch 483: loss 0.014564\n",
      "Ending epoch 484: loss 0.0147364\n",
      "Ending epoch 485: loss 0.0142996\n",
      "Ending epoch 486: loss 0.0164006\n",
      "Ending epoch 487: loss 0.0177424\n",
      "Ending epoch 488: loss 0.0129592\n",
      "Ending epoch 489: loss 0.0173534\n",
      "Ending epoch 490: loss 0.014002\n",
      "Ending epoch 491: loss 0.0144986\n",
      "Ending epoch 492: loss 0.0171066\n",
      "Ending epoch 493: loss 0.0153554\n",
      "Ending epoch 494: loss 0.0163666\n",
      "Ending epoch 495: loss 0.0133676\n",
      "Ending epoch 496: loss 0.0114316\n",
      "Ending epoch 497: loss 0.0182982\n",
      "Ending epoch 498: loss 0.0200411\n",
      "Ending epoch 499: loss 0.0161934\n",
      "Model 2/8, Metric mean_absolute_error, Validation set 1: 23.643418\n",
      "\tbest_validation_score so far: 23.643418\n",
      "Fitting model 3/8\n",
      "hyperparameters: {u'optimizer': u'rmsprop', u'layer_sizes': [1000, 1000, 250], u'data_shape': (23,), u'learning_rate': 0.0001, u'batch_size': 100, u'penalty': 0.0, u'bias_init_consts': [1.0, 1.0, 1.0], u'weight_init_stddevs': [0.077459666924148338, 0.077459666924148338, 0.077459666924148338], u'num_regression_tasks': 1, u'dropouts': [0.1, 0.1, 0.1], u'nb_epoch': 500, u'momentum': 0.9}\n",
      "Training for 500 epochs\n",
      "Ending epoch 0: loss 2.19534\n",
      "Ending epoch 1: loss 1.97193\n",
      "Ending epoch 2: loss 1.51494\n",
      "Ending epoch 3: loss 1.81602\n",
      "Ending epoch 4: loss 1.45905\n",
      "Ending epoch 5: loss 3.30609\n",
      "Ending epoch 6: loss 2.82969\n",
      "Ending epoch 7: loss 1.53469\n",
      "Ending epoch 8: loss 2.23461\n",
      "Ending epoch 9: loss 1.22773\n",
      "Ending epoch 10: loss 0.837931\n",
      "Ending epoch 11: loss 1.13517\n",
      "Ending epoch 12: loss 0.721288\n",
      "Ending epoch 13: loss 1.37482\n",
      "Ending epoch 14: loss 0.75278\n",
      "Ending epoch 15: loss 0.506344\n",
      "Ending epoch 16: loss 0.676254\n",
      "Ending epoch 17: loss 0.35518\n",
      "Ending epoch 18: loss 0.498344\n",
      "Ending epoch 19: loss 0.29732\n",
      "Ending epoch 20: loss 0.281112\n",
      "Ending epoch 21: loss 0.185639\n",
      "Ending epoch 22: loss 0.252621\n",
      "Ending epoch 23: loss 0.228176\n",
      "Ending epoch 24: loss 0.160037\n",
      "Ending epoch 25: loss 0.115116\n",
      "Ending epoch 26: loss 0.223616\n",
      "Ending epoch 27: loss 0.118058\n",
      "Ending epoch 28: loss 0.182879\n",
      "Ending epoch 29: loss 0.0745343\n",
      "Ending epoch 30: loss 0.0720203\n",
      "Ending epoch 31: loss 0.0827641\n",
      "Ending epoch 32: loss 0.0674521\n",
      "Ending epoch 33: loss 0.0658043\n",
      "Ending epoch 34: loss 0.0660321\n",
      "Ending epoch 35: loss 0.089919\n",
      "Ending epoch 36: loss 0.0458024\n",
      "Ending epoch 37: loss 0.0577042\n",
      "Ending epoch 38: loss 0.0274438\n",
      "Ending epoch 39: loss 0.0411\n",
      "Ending epoch 40: loss 0.045127\n",
      "Ending epoch 41: loss 0.0413163\n",
      "Ending epoch 42: loss 0.0734239\n",
      "Ending epoch 43: loss 0.0363583\n",
      "Ending epoch 44: loss 0.040501\n",
      "Ending epoch 45: loss 0.0300237\n",
      "Ending epoch 46: loss 0.0313545\n",
      "Ending epoch 47: loss 0.04574\n",
      "Ending epoch 48: loss 0.0318822\n",
      "Ending epoch 49: loss 0.0325944\n",
      "Ending epoch 50: loss 0.0339347\n",
      "Ending epoch 51: loss 0.0263655\n",
      "Ending epoch 52: loss 0.0334189\n",
      "Ending epoch 53: loss 0.0268057\n",
      "Ending epoch 54: loss 0.0307221\n",
      "Ending epoch 55: loss 0.0313124\n",
      "Ending epoch 56: loss 0.0529321\n",
      "Ending epoch 57: loss 0.0250391\n",
      "Ending epoch 58: loss 0.031778\n",
      "Ending epoch 59: loss 0.0254146\n",
      "Ending epoch 60: loss 0.0182795\n",
      "Ending epoch 61: loss 0.0250512\n",
      "Ending epoch 62: loss 0.0303766\n",
      "Ending epoch 63: loss 0.027154\n",
      "Ending epoch 64: loss 0.0371338\n",
      "Ending epoch 65: loss 0.0224072\n",
      "Ending epoch 66: loss 0.0358892\n",
      "Ending epoch 67: loss 0.0256705\n",
      "Ending epoch 68: loss 0.026927\n",
      "Ending epoch 69: loss 0.0220384\n",
      "Ending epoch 70: loss 0.0241326\n",
      "Ending epoch 71: loss 0.0348848\n",
      "Ending epoch 72: loss 0.0285588\n",
      "Ending epoch 73: loss 0.0260769\n",
      "Ending epoch 74: loss 0.0186806\n",
      "Ending epoch 75: loss 0.0246007\n",
      "Ending epoch 76: loss 0.0264048\n",
      "Ending epoch 77: loss 0.0224424\n",
      "Ending epoch 78: loss 0.029006\n",
      "Ending epoch 79: loss 0.0210361\n",
      "Ending epoch 80: loss 0.0152964\n",
      "Ending epoch 81: loss 0.0224345\n",
      "Ending epoch 82: loss 0.020445\n",
      "Ending epoch 83: loss 0.02002\n",
      "Ending epoch 84: loss 0.0284069\n",
      "Ending epoch 85: loss 0.0193368\n",
      "Ending epoch 86: loss 0.0224367\n",
      "Ending epoch 87: loss 0.018516\n",
      "Ending epoch 88: loss 0.0326116\n",
      "Ending epoch 89: loss 0.0230387\n",
      "Ending epoch 90: loss 0.0178697\n",
      "Ending epoch 91: loss 0.0205596\n",
      "Ending epoch 92: loss 0.0252587\n",
      "Ending epoch 93: loss 0.0235294\n",
      "Ending epoch 94: loss 0.0211152\n",
      "Ending epoch 95: loss 0.0237464\n",
      "Ending epoch 96: loss 0.020621\n",
      "Ending epoch 97: loss 0.0189417\n",
      "Ending epoch 98: loss 0.0230194\n",
      "Ending epoch 99: loss 0.0232781\n",
      "Ending epoch 100: loss 0.0154603\n",
      "Ending epoch 101: loss 0.0136131\n",
      "Ending epoch 102: loss 0.0231612\n",
      "Ending epoch 103: loss 0.0175675\n",
      "Ending epoch 104: loss 0.0173062\n",
      "Ending epoch 105: loss 0.0205995\n",
      "Ending epoch 106: loss 0.0216976\n",
      "Ending epoch 107: loss 0.0150276\n",
      "Ending epoch 108: loss 0.0165196\n",
      "Ending epoch 109: loss 0.023244\n",
      "Ending epoch 110: loss 0.0240635\n",
      "Ending epoch 111: loss 0.0148058\n",
      "Ending epoch 112: loss 0.0154218\n",
      "Ending epoch 113: loss 0.0171112\n",
      "Ending epoch 114: loss 0.0193788\n",
      "Ending epoch 115: loss 0.0166521\n",
      "Ending epoch 116: loss 0.018371\n",
      "Ending epoch 117: loss 0.0189223\n",
      "Ending epoch 118: loss 0.0109005\n",
      "Ending epoch 119: loss 0.0134718\n",
      "Ending epoch 120: loss 0.0126753\n",
      "Ending epoch 121: loss 0.0253363\n",
      "Ending epoch 122: loss 0.0183661\n",
      "Ending epoch 123: loss 0.014734\n",
      "Ending epoch 124: loss 0.0178784\n",
      "Ending epoch 125: loss 0.0151211\n",
      "Ending epoch 126: loss 0.0177573\n",
      "Ending epoch 127: loss 0.0144315\n",
      "Ending epoch 128: loss 0.0198454\n",
      "Ending epoch 129: loss 0.0145869\n",
      "Ending epoch 130: loss 0.0161794\n",
      "Ending epoch 131: loss 0.0143149\n",
      "Ending epoch 132: loss 0.014234\n",
      "Ending epoch 133: loss 0.0123199\n",
      "Ending epoch 134: loss 0.0246981\n",
      "Ending epoch 135: loss 0.0139154\n",
      "Ending epoch 136: loss 0.0132986\n",
      "Ending epoch 137: loss 0.0131682\n",
      "Ending epoch 138: loss 0.0144169\n",
      "Ending epoch 139: loss 0.0156711\n",
      "Ending epoch 140: loss 0.0142036\n",
      "Ending epoch 141: loss 0.0140914\n",
      "Ending epoch 142: loss 0.0210414\n",
      "Ending epoch 143: loss 0.0172488\n",
      "Ending epoch 144: loss 0.0170453\n",
      "Ending epoch 145: loss 0.0157178\n",
      "Ending epoch 146: loss 0.0143141\n",
      "Ending epoch 147: loss 0.020339\n",
      "Ending epoch 148: loss 0.0123822\n",
      "Ending epoch 149: loss 0.0151644\n",
      "Ending epoch 150: loss 0.0103387\n",
      "Ending epoch 151: loss 0.0249802\n",
      "Ending epoch 152: loss 0.0253272\n",
      "Ending epoch 153: loss 0.0151241\n",
      "Ending epoch 154: loss 0.0165973\n",
      "Ending epoch 155: loss 0.0118485\n",
      "Ending epoch 156: loss 0.010809\n",
      "Ending epoch 157: loss 0.0150341\n",
      "Ending epoch 158: loss 0.0157661\n",
      "Ending epoch 159: loss 0.0127686\n",
      "Ending epoch 160: loss 0.0126241\n",
      "Ending epoch 161: loss 0.0229358\n",
      "Ending epoch 162: loss 0.0186394\n",
      "Ending epoch 163: loss 0.0126094\n",
      "Ending epoch 164: loss 0.0108588\n",
      "Ending epoch 165: loss 0.0174523\n",
      "Ending epoch 166: loss 0.0177477\n",
      "Ending epoch 167: loss 0.0170521\n",
      "Ending epoch 168: loss 0.0168654\n",
      "Ending epoch 169: loss 0.010299\n",
      "Ending epoch 170: loss 0.0142534\n",
      "Ending epoch 171: loss 0.0160085\n",
      "Ending epoch 172: loss 0.0148983\n",
      "Ending epoch 173: loss 0.011314\n",
      "Ending epoch 174: loss 0.0108919\n",
      "Ending epoch 175: loss 0.0181793\n",
      "Ending epoch 176: loss 0.0150416\n",
      "Ending epoch 177: loss 0.0118588\n",
      "Ending epoch 178: loss 0.0124299\n",
      "Ending epoch 179: loss 0.00825141\n",
      "Ending epoch 180: loss 0.0129463\n",
      "Ending epoch 181: loss 0.0145719\n",
      "Ending epoch 182: loss 0.0145728\n",
      "Ending epoch 183: loss 0.0135081\n",
      "Ending epoch 184: loss 0.0135264\n",
      "Ending epoch 185: loss 0.020136\n",
      "Ending epoch 186: loss 0.0145007\n",
      "Ending epoch 187: loss 0.0172546\n",
      "Ending epoch 188: loss 0.00937667\n",
      "Ending epoch 189: loss 0.0110137\n",
      "Ending epoch 190: loss 0.0153853\n",
      "Ending epoch 191: loss 0.0126766\n",
      "Ending epoch 192: loss 0.0152535\n",
      "Ending epoch 193: loss 0.0118338\n",
      "Ending epoch 194: loss 0.0117081\n",
      "Ending epoch 195: loss 0.0113785\n",
      "Ending epoch 196: loss 0.012646\n",
      "Ending epoch 197: loss 0.0123228\n",
      "Ending epoch 198: loss 0.0136585\n",
      "Ending epoch 199: loss 0.0153853\n",
      "Ending epoch 200: loss 0.0121613\n",
      "Ending epoch 201: loss 0.0123028\n",
      "Ending epoch 202: loss 0.0145808\n",
      "Ending epoch 203: loss 0.0167059\n",
      "Ending epoch 204: loss 0.0121649\n",
      "Ending epoch 205: loss 0.0183812\n",
      "Ending epoch 206: loss 0.0142972\n",
      "Ending epoch 207: loss 0.0144781\n",
      "Ending epoch 208: loss 0.0125849\n",
      "Ending epoch 209: loss 0.0103835\n",
      "Ending epoch 210: loss 0.0114175\n",
      "Ending epoch 211: loss 0.0110187\n",
      "Ending epoch 212: loss 0.012269\n",
      "Ending epoch 213: loss 0.0165486\n",
      "Ending epoch 214: loss 0.0131255\n",
      "Ending epoch 215: loss 0.0144711\n",
      "Ending epoch 216: loss 0.0133803\n",
      "Ending epoch 217: loss 0.0145227\n",
      "Ending epoch 218: loss 0.0137584\n",
      "Ending epoch 219: loss 0.0153989\n",
      "Ending epoch 220: loss 0.0129303\n",
      "Ending epoch 221: loss 0.0109244\n",
      "Ending epoch 222: loss 0.00949388\n",
      "Ending epoch 223: loss 0.0144168\n",
      "Ending epoch 224: loss 0.0136512\n",
      "Ending epoch 225: loss 0.0143256\n",
      "Ending epoch 226: loss 0.0112651\n",
      "Ending epoch 227: loss 0.0126935\n",
      "Ending epoch 228: loss 0.0153287\n",
      "Ending epoch 229: loss 0.0146547\n",
      "Ending epoch 230: loss 0.0131062\n",
      "Ending epoch 231: loss 0.00848165\n",
      "Ending epoch 232: loss 0.0125537\n",
      "Ending epoch 233: loss 0.01481\n",
      "Ending epoch 234: loss 0.0121878\n",
      "Ending epoch 235: loss 0.0103961\n",
      "Ending epoch 236: loss 0.0150848\n",
      "Ending epoch 237: loss 0.0121365\n",
      "Ending epoch 238: loss 0.0107011\n",
      "Ending epoch 239: loss 0.0168146\n",
      "Ending epoch 240: loss 0.012267\n",
      "Ending epoch 241: loss 0.017894\n",
      "Ending epoch 242: loss 0.0142921\n",
      "Ending epoch 243: loss 0.0116324\n",
      "Ending epoch 244: loss 0.0136378\n",
      "Ending epoch 245: loss 0.0126303\n",
      "Ending epoch 246: loss 0.0102844\n",
      "Ending epoch 247: loss 0.0127027\n",
      "Ending epoch 248: loss 0.010597\n",
      "Ending epoch 249: loss 0.0101083\n",
      "Ending epoch 250: loss 0.00927741\n",
      "Ending epoch 251: loss 0.0131015\n",
      "Ending epoch 252: loss 0.0124328\n",
      "Ending epoch 253: loss 0.00746179\n",
      "Ending epoch 254: loss 0.0111855\n",
      "Ending epoch 255: loss 0.0150747\n",
      "Ending epoch 256: loss 0.0112771\n",
      "Ending epoch 257: loss 0.0141751\n",
      "Ending epoch 258: loss 0.0120458\n",
      "Ending epoch 259: loss 0.0105128\n",
      "Ending epoch 260: loss 0.0104153\n",
      "Ending epoch 261: loss 0.0105298\n",
      "Ending epoch 262: loss 0.0128748\n",
      "Ending epoch 263: loss 0.010524\n",
      "Ending epoch 264: loss 0.0125101\n",
      "Ending epoch 265: loss 0.00801697\n",
      "Ending epoch 266: loss 0.00954043\n",
      "Ending epoch 267: loss 0.0155115\n",
      "Ending epoch 268: loss 0.0156466\n",
      "Ending epoch 269: loss 0.0227152\n",
      "Ending epoch 270: loss 0.0133895\n",
      "Ending epoch 271: loss 0.0132867\n",
      "Ending epoch 272: loss 0.0133554\n",
      "Ending epoch 273: loss 0.0119064\n",
      "Ending epoch 274: loss 0.0128609\n",
      "Ending epoch 275: loss 0.0137627\n",
      "Ending epoch 276: loss 0.0141786\n",
      "Ending epoch 277: loss 0.0142707\n",
      "Ending epoch 278: loss 0.0123187\n",
      "Ending epoch 279: loss 0.0116387\n",
      "Ending epoch 280: loss 0.0113285\n",
      "Ending epoch 281: loss 0.0105435\n",
      "Ending epoch 282: loss 0.0122514\n",
      "Ending epoch 283: loss 0.0112942\n",
      "Ending epoch 284: loss 0.00944797\n",
      "Ending epoch 285: loss 0.0126097\n",
      "Ending epoch 286: loss 0.0101588\n",
      "Ending epoch 287: loss 0.00924508\n",
      "Ending epoch 288: loss 0.0188283\n",
      "Ending epoch 289: loss 0.00635446\n",
      "Ending epoch 290: loss 0.0119478\n",
      "Ending epoch 291: loss 0.0134526\n",
      "Ending epoch 292: loss 0.0123183\n",
      "Ending epoch 293: loss 0.0198367\n",
      "Ending epoch 294: loss 0.010454\n",
      "Ending epoch 295: loss 0.011181\n",
      "Ending epoch 296: loss 0.0105067\n",
      "Ending epoch 297: loss 0.0122211\n",
      "Ending epoch 298: loss 0.0088317\n",
      "Ending epoch 299: loss 0.0121354\n",
      "Ending epoch 300: loss 0.010445\n",
      "Ending epoch 301: loss 0.0140087\n",
      "Ending epoch 302: loss 0.0112305\n",
      "Ending epoch 303: loss 0.00991646\n",
      "Ending epoch 304: loss 0.0112549\n",
      "Ending epoch 305: loss 0.0121194\n",
      "Ending epoch 306: loss 0.0140779\n",
      "Ending epoch 307: loss 0.0184175\n",
      "Ending epoch 308: loss 0.0095265\n",
      "Ending epoch 309: loss 0.0080513\n",
      "Ending epoch 310: loss 0.0138806\n",
      "Ending epoch 311: loss 0.0103044\n",
      "Ending epoch 312: loss 0.0113487\n",
      "Ending epoch 313: loss 0.0120407\n",
      "Ending epoch 314: loss 0.0101386\n",
      "Ending epoch 315: loss 0.0103754\n",
      "Ending epoch 316: loss 0.0134582\n",
      "Ending epoch 317: loss 0.00836537\n",
      "Ending epoch 318: loss 0.0133572\n",
      "Ending epoch 319: loss 0.0112452\n",
      "Ending epoch 320: loss 0.0104649\n",
      "Ending epoch 321: loss 0.0111137\n",
      "Ending epoch 322: loss 0.0100523\n",
      "Ending epoch 323: loss 0.0130988\n",
      "Ending epoch 324: loss 0.0119419\n",
      "Ending epoch 325: loss 0.0108111\n",
      "Ending epoch 326: loss 0.00901857\n",
      "Ending epoch 327: loss 0.0111892\n",
      "Ending epoch 328: loss 0.0157349\n",
      "Ending epoch 329: loss 0.0107783\n",
      "Ending epoch 330: loss 0.0106317\n",
      "Ending epoch 331: loss 0.0151443\n",
      "Ending epoch 332: loss 0.0173123\n",
      "Ending epoch 333: loss 0.0117574\n",
      "Ending epoch 334: loss 0.0102605\n",
      "Ending epoch 335: loss 0.0119871\n",
      "Ending epoch 336: loss 0.00951712\n",
      "Ending epoch 337: loss 0.00956683\n",
      "Ending epoch 338: loss 0.0115736\n",
      "Ending epoch 339: loss 0.0112692\n",
      "Ending epoch 340: loss 0.0107825\n",
      "Ending epoch 341: loss 0.0103549\n",
      "Ending epoch 342: loss 0.0130035\n",
      "Ending epoch 343: loss 0.011052\n",
      "Ending epoch 344: loss 0.0101849\n",
      "Ending epoch 345: loss 0.0109146\n",
      "Ending epoch 346: loss 0.010501\n",
      "Ending epoch 347: loss 0.0126236\n",
      "Ending epoch 348: loss 0.00922375\n",
      "Ending epoch 349: loss 0.0111247\n",
      "Ending epoch 350: loss 0.00960103\n",
      "Ending epoch 351: loss 0.0133869\n",
      "Ending epoch 352: loss 0.0109686\n",
      "Ending epoch 353: loss 0.0112918\n",
      "Ending epoch 354: loss 0.0110394\n",
      "Ending epoch 355: loss 0.0102035\n",
      "Ending epoch 356: loss 0.0117837\n",
      "Ending epoch 357: loss 0.00932337\n",
      "Ending epoch 358: loss 0.0105401\n",
      "Ending epoch 359: loss 0.0101107\n",
      "Ending epoch 360: loss 0.0128169\n",
      "Ending epoch 361: loss 0.00803481\n",
      "Ending epoch 362: loss 0.0109422\n",
      "Ending epoch 363: loss 0.010511\n",
      "Ending epoch 364: loss 0.00943758\n",
      "Ending epoch 365: loss 0.0138709\n",
      "Ending epoch 366: loss 0.011272\n",
      "Ending epoch 367: loss 0.0102649\n",
      "Ending epoch 368: loss 0.012747\n",
      "Ending epoch 369: loss 0.00927187\n",
      "Ending epoch 370: loss 0.01106\n",
      "Ending epoch 371: loss 0.0133067\n",
      "Ending epoch 372: loss 0.00872355\n",
      "Ending epoch 373: loss 0.00842304\n",
      "Ending epoch 374: loss 0.0121205\n",
      "Ending epoch 375: loss 0.0122893\n",
      "Ending epoch 376: loss 0.00676947\n",
      "Ending epoch 377: loss 0.0147998\n",
      "Ending epoch 378: loss 0.00809919\n",
      "Ending epoch 379: loss 0.0117321\n",
      "Ending epoch 380: loss 0.0100353\n",
      "Ending epoch 381: loss 0.00948258\n",
      "Ending epoch 382: loss 0.0114741\n",
      "Ending epoch 383: loss 0.00946195\n",
      "Ending epoch 384: loss 0.0103106\n",
      "Ending epoch 385: loss 0.0113279\n",
      "Ending epoch 386: loss 0.00951757\n",
      "Ending epoch 387: loss 0.0099542\n",
      "Ending epoch 388: loss 0.0113384\n",
      "Ending epoch 389: loss 0.00740744\n",
      "Ending epoch 390: loss 0.00971106\n",
      "Ending epoch 391: loss 0.0138253\n",
      "Ending epoch 392: loss 0.0110948\n",
      "Ending epoch 393: loss 0.011171\n",
      "Ending epoch 394: loss 0.0111205\n",
      "Ending epoch 395: loss 0.00911305\n",
      "Ending epoch 396: loss 0.0114991\n",
      "Ending epoch 397: loss 0.0125004\n",
      "Ending epoch 398: loss 0.0106624\n",
      "Ending epoch 399: loss 0.0140137\n",
      "Ending epoch 400: loss 0.0140319\n",
      "Ending epoch 401: loss 0.0103285\n",
      "Ending epoch 402: loss 0.00953717\n",
      "Ending epoch 403: loss 0.0106677\n",
      "Ending epoch 404: loss 0.00843832\n",
      "Ending epoch 405: loss 0.0117394\n",
      "Ending epoch 406: loss 0.010183\n",
      "Ending epoch 407: loss 0.010781\n",
      "Ending epoch 408: loss 0.00844262\n",
      "Ending epoch 409: loss 0.00803506\n",
      "Ending epoch 410: loss 0.00808619\n",
      "Ending epoch 411: loss 0.0130111\n",
      "Ending epoch 412: loss 0.0113005\n",
      "Ending epoch 413: loss 0.00971255\n",
      "Ending epoch 414: loss 0.0121938\n",
      "Ending epoch 415: loss 0.00938177\n",
      "Ending epoch 416: loss 0.00934218\n",
      "Ending epoch 417: loss 0.0149922\n",
      "Ending epoch 418: loss 0.00959487\n",
      "Ending epoch 419: loss 0.00958015\n",
      "Ending epoch 420: loss 0.0101758\n",
      "Ending epoch 421: loss 0.00989795\n",
      "Ending epoch 422: loss 0.0108365\n",
      "Ending epoch 423: loss 0.00918529\n",
      "Ending epoch 424: loss 0.0102095\n",
      "Ending epoch 425: loss 0.00991312\n",
      "Ending epoch 426: loss 0.00791325\n",
      "Ending epoch 427: loss 0.00967546\n",
      "Ending epoch 428: loss 0.0113379\n",
      "Ending epoch 429: loss 0.00924607\n",
      "Ending epoch 430: loss 0.00858721\n",
      "Ending epoch 431: loss 0.0134121\n",
      "Ending epoch 432: loss 0.0121329\n",
      "Ending epoch 433: loss 0.0114848\n",
      "Ending epoch 434: loss 0.0117157\n",
      "Ending epoch 435: loss 0.0105786\n",
      "Ending epoch 436: loss 0.0109466\n",
      "Ending epoch 437: loss 0.00861327\n",
      "Ending epoch 438: loss 0.0106226\n",
      "Ending epoch 439: loss 0.00969329\n",
      "Ending epoch 440: loss 0.0110722\n",
      "Ending epoch 441: loss 0.00825124\n",
      "Ending epoch 442: loss 0.0102631\n",
      "Ending epoch 443: loss 0.00954442\n",
      "Ending epoch 444: loss 0.00919072\n",
      "Ending epoch 445: loss 0.0094363\n",
      "Ending epoch 446: loss 0.00976214\n",
      "Ending epoch 447: loss 0.0108315\n",
      "Ending epoch 448: loss 0.0116421\n",
      "Ending epoch 449: loss 0.00975675\n",
      "Ending epoch 450: loss 0.00683312\n",
      "Ending epoch 451: loss 0.00948024\n",
      "Ending epoch 452: loss 0.0109982\n",
      "Ending epoch 453: loss 0.0112015\n",
      "Ending epoch 454: loss 0.00913882\n",
      "Ending epoch 455: loss 0.00686086\n",
      "Ending epoch 456: loss 0.00798212\n",
      "Ending epoch 457: loss 0.0122974\n",
      "Ending epoch 458: loss 0.00900995\n",
      "Ending epoch 459: loss 0.010677\n",
      "Ending epoch 460: loss 0.00966827\n",
      "Ending epoch 461: loss 0.0101236\n",
      "Ending epoch 462: loss 0.00974741\n",
      "Ending epoch 463: loss 0.0103266\n",
      "Ending epoch 464: loss 0.00788789\n",
      "Ending epoch 465: loss 0.0129975\n",
      "Ending epoch 466: loss 0.00920849\n",
      "Ending epoch 467: loss 0.0122673\n",
      "Ending epoch 468: loss 0.0103673\n",
      "Ending epoch 469: loss 0.00853869\n",
      "Ending epoch 470: loss 0.00896839\n",
      "Ending epoch 471: loss 0.0112665\n",
      "Ending epoch 472: loss 0.0101205\n",
      "Ending epoch 473: loss 0.00887259\n",
      "Ending epoch 474: loss 0.0165257\n",
      "Ending epoch 475: loss 0.0131135\n",
      "Ending epoch 476: loss 0.00860365\n",
      "Ending epoch 477: loss 0.00915376\n",
      "Ending epoch 478: loss 0.0122088\n",
      "Ending epoch 479: loss 0.0119178\n",
      "Ending epoch 480: loss 0.0102826\n",
      "Ending epoch 481: loss 0.00977732\n",
      "Ending epoch 482: loss 0.00971101\n",
      "Ending epoch 483: loss 0.0140602\n",
      "Ending epoch 484: loss 0.0097825\n",
      "Ending epoch 485: loss 0.00911761\n",
      "Ending epoch 486: loss 0.0107023\n",
      "Ending epoch 487: loss 0.0117246\n",
      "Ending epoch 488: loss 0.00806882\n",
      "Ending epoch 489: loss 0.00980132\n",
      "Ending epoch 490: loss 0.0102613\n",
      "Ending epoch 491: loss 0.0104429\n",
      "Ending epoch 492: loss 0.00845823\n",
      "Ending epoch 493: loss 0.00977944\n",
      "Ending epoch 494: loss 0.00736645\n",
      "Ending epoch 495: loss 0.00841617\n",
      "Ending epoch 496: loss 0.0107186\n",
      "Ending epoch 497: loss 0.0126211\n",
      "Ending epoch 498: loss 0.01188\n",
      "Ending epoch 499: loss 0.0115437\n",
      "Model 3/8, Metric mean_absolute_error, Validation set 2: 27.870429\n",
      "\tbest_validation_score so far: 23.643418\n",
      "Fitting model 4/8\n",
      "hyperparameters: {u'optimizer': u'rmsprop', u'layer_sizes': [1000, 1000, 500], u'data_shape': (23,), u'learning_rate': 0.0001, u'batch_size': 100, u'penalty': 0.0, u'bias_init_consts': [1.0, 1.0, 1.0], u'weight_init_stddevs': [0.077459666924148338, 0.077459666924148338, 0.077459666924148338], u'num_regression_tasks': 1, u'dropouts': [0.1, 0.1, 0.1], u'nb_epoch': 500, u'momentum': 0.9}\n",
      "Training for 500 epochs\n",
      "Ending epoch 0: loss 4.97838\n",
      "Ending epoch 1: loss 5.00045\n",
      "Ending epoch 2: loss 5.26364\n",
      "Ending epoch 3: loss 4.86402\n",
      "Ending epoch 4: loss 5.76727\n",
      "Ending epoch 5: loss 6.63938\n",
      "Ending epoch 6: loss 4.44205\n",
      "Ending epoch 7: loss 7.22573\n",
      "Ending epoch 8: loss 2.56653\n",
      "Ending epoch 9: loss 7.99354\n",
      "Ending epoch 10: loss 3.11656\n",
      "Ending epoch 11: loss 3.4504\n",
      "Ending epoch 12: loss 3.12088\n",
      "Ending epoch 13: loss 2.61362\n",
      "Ending epoch 14: loss 3.54844\n",
      "Ending epoch 15: loss 1.92187\n",
      "Ending epoch 16: loss 1.33174\n",
      "Ending epoch 17: loss 2.49459\n",
      "Ending epoch 18: loss 1.23192\n",
      "Ending epoch 19: loss 1.10551\n",
      "Ending epoch 20: loss 1.38294\n",
      "Ending epoch 21: loss 0.939677\n",
      "Ending epoch 22: loss 0.850494\n",
      "Ending epoch 23: loss 0.850621\n",
      "Ending epoch 24: loss 0.517466\n",
      "Ending epoch 25: loss 0.4296\n",
      "Ending epoch 26: loss 0.868875\n",
      "Ending epoch 27: loss 0.280314\n",
      "Ending epoch 28: loss 0.963627\n",
      "Ending epoch 29: loss 0.326194\n",
      "Ending epoch 30: loss 0.360884\n",
      "Ending epoch 31: loss 0.444972\n",
      "Ending epoch 32: loss 0.267385\n",
      "Ending epoch 33: loss 0.223576\n",
      "Ending epoch 34: loss 0.215819\n",
      "Ending epoch 35: loss 0.28584\n",
      "Ending epoch 36: loss 0.299881\n",
      "Ending epoch 37: loss 0.299787\n",
      "Ending epoch 38: loss 0.243921\n",
      "Ending epoch 39: loss 0.206476\n",
      "Ending epoch 40: loss 0.189167\n",
      "Ending epoch 41: loss 0.251837\n",
      "Ending epoch 42: loss 0.110555\n",
      "Ending epoch 43: loss 0.189089\n",
      "Ending epoch 44: loss 0.127561\n",
      "Ending epoch 45: loss 0.127269\n",
      "Ending epoch 46: loss 0.101262\n",
      "Ending epoch 47: loss 0.131275\n",
      "Ending epoch 48: loss 0.116042\n",
      "Ending epoch 49: loss 0.073423\n",
      "Ending epoch 50: loss 0.0759497\n",
      "Ending epoch 51: loss 0.0565728\n",
      "Ending epoch 52: loss 0.137794\n",
      "Ending epoch 53: loss 0.0616357\n",
      "Ending epoch 54: loss 0.0669079\n",
      "Ending epoch 55: loss 0.107177\n",
      "Ending epoch 56: loss 0.0754398\n",
      "Ending epoch 57: loss 0.0564023\n",
      "Ending epoch 58: loss 0.0576539\n",
      "Ending epoch 59: loss 0.0418788\n",
      "Ending epoch 60: loss 0.0428866\n",
      "Ending epoch 61: loss 0.0414669\n",
      "Ending epoch 62: loss 0.041437\n",
      "Ending epoch 63: loss 0.0807494\n",
      "Ending epoch 64: loss 0.0328553\n",
      "Ending epoch 65: loss 0.0828911\n",
      "Ending epoch 66: loss 0.0486198\n",
      "Ending epoch 67: loss 0.0289354\n",
      "Ending epoch 68: loss 0.0310374\n",
      "Ending epoch 69: loss 0.0445099\n",
      "Ending epoch 70: loss 0.0277236\n",
      "Ending epoch 71: loss 0.0310383\n",
      "Ending epoch 72: loss 0.0305416\n",
      "Ending epoch 73: loss 0.0334442\n",
      "Ending epoch 74: loss 0.0366168\n",
      "Ending epoch 75: loss 0.0202941\n",
      "Ending epoch 76: loss 0.0226277\n",
      "Ending epoch 77: loss 0.0317546\n",
      "Ending epoch 78: loss 0.0286251\n",
      "Ending epoch 79: loss 0.0313854\n",
      "Ending epoch 80: loss 0.0228178\n",
      "Ending epoch 81: loss 0.0335634\n",
      "Ending epoch 82: loss 0.0209077\n",
      "Ending epoch 83: loss 0.0291229\n",
      "Ending epoch 84: loss 0.0250746\n",
      "Ending epoch 85: loss 0.0238316\n",
      "Ending epoch 86: loss 0.0279624\n",
      "Ending epoch 87: loss 0.0374032\n",
      "Ending epoch 88: loss 0.0236386\n",
      "Ending epoch 89: loss 0.0164282\n",
      "Ending epoch 90: loss 0.0252095\n",
      "Ending epoch 91: loss 0.0190426\n",
      "Ending epoch 92: loss 0.018638\n",
      "Ending epoch 93: loss 0.0262091\n",
      "Ending epoch 94: loss 0.0301999\n",
      "Ending epoch 95: loss 0.0217488\n",
      "Ending epoch 96: loss 0.0244949\n",
      "Ending epoch 97: loss 0.0154574\n",
      "Ending epoch 98: loss 0.0172221\n",
      "Ending epoch 99: loss 0.0236144\n",
      "Ending epoch 100: loss 0.0211116\n",
      "Ending epoch 101: loss 0.0203947\n",
      "Ending epoch 102: loss 0.0195831\n",
      "Ending epoch 103: loss 0.0222688\n",
      "Ending epoch 104: loss 0.0160446\n",
      "Ending epoch 105: loss 0.0310165\n",
      "Ending epoch 106: loss 0.0154679\n",
      "Ending epoch 107: loss 0.0203713\n",
      "Ending epoch 108: loss 0.0158616\n",
      "Ending epoch 109: loss 0.0297785\n",
      "Ending epoch 110: loss 0.0147372\n",
      "Ending epoch 111: loss 0.018053\n",
      "Ending epoch 112: loss 0.013687\n",
      "Ending epoch 113: loss 0.017895\n",
      "Ending epoch 114: loss 0.0141775\n",
      "Ending epoch 115: loss 0.023632\n",
      "Ending epoch 116: loss 0.0208378\n",
      "Ending epoch 117: loss 0.0162896\n",
      "Ending epoch 118: loss 0.0141398\n",
      "Ending epoch 119: loss 0.0148369\n",
      "Ending epoch 120: loss 0.0163291\n",
      "Ending epoch 121: loss 0.0205323\n",
      "Ending epoch 122: loss 0.0131234\n",
      "Ending epoch 123: loss 0.019764\n",
      "Ending epoch 124: loss 0.0141433\n",
      "Ending epoch 125: loss 0.0142959\n",
      "Ending epoch 126: loss 0.017748\n",
      "Ending epoch 127: loss 0.0198569\n",
      "Ending epoch 128: loss 0.013703\n",
      "Ending epoch 129: loss 0.0179037\n",
      "Ending epoch 130: loss 0.015392\n",
      "Ending epoch 131: loss 0.0199459\n",
      "Ending epoch 132: loss 0.0148222\n",
      "Ending epoch 133: loss 0.0183875\n",
      "Ending epoch 134: loss 0.0141472\n",
      "Ending epoch 135: loss 0.0121853\n",
      "Ending epoch 136: loss 0.0139967\n",
      "Ending epoch 137: loss 0.0183062\n",
      "Ending epoch 138: loss 0.0137915\n",
      "Ending epoch 139: loss 0.0112389\n",
      "Ending epoch 140: loss 0.0142596\n",
      "Ending epoch 141: loss 0.0142195\n",
      "Ending epoch 142: loss 0.0128841\n",
      "Ending epoch 143: loss 0.0148551\n",
      "Ending epoch 144: loss 0.0100229\n",
      "Ending epoch 145: loss 0.0132691\n",
      "Ending epoch 146: loss 0.0289084\n",
      "Ending epoch 147: loss 0.0102266\n",
      "Ending epoch 148: loss 0.0117186\n",
      "Ending epoch 149: loss 0.0130942\n",
      "Ending epoch 150: loss 0.0250638\n",
      "Ending epoch 151: loss 0.0146486\n",
      "Ending epoch 152: loss 0.0148933\n",
      "Ending epoch 153: loss 0.0124991\n",
      "Ending epoch 154: loss 0.0117073\n",
      "Ending epoch 155: loss 0.0143868\n",
      "Ending epoch 156: loss 0.0134641\n",
      "Ending epoch 157: loss 0.0176731\n",
      "Ending epoch 158: loss 0.0133963\n",
      "Ending epoch 159: loss 0.0133242\n",
      "Ending epoch 160: loss 0.0144615\n",
      "Ending epoch 161: loss 0.0140342\n",
      "Ending epoch 162: loss 0.0170567\n",
      "Ending epoch 163: loss 0.0135973\n",
      "Ending epoch 164: loss 0.017812\n",
      "Ending epoch 165: loss 0.0189007\n",
      "Ending epoch 166: loss 0.0198765\n",
      "Ending epoch 167: loss 0.0252101\n",
      "Ending epoch 168: loss 0.0123857\n",
      "Ending epoch 169: loss 0.0170381\n",
      "Ending epoch 170: loss 0.011174\n",
      "Ending epoch 171: loss 0.0191079\n",
      "Ending epoch 172: loss 0.012603\n",
      "Ending epoch 173: loss 0.0122047\n",
      "Ending epoch 174: loss 0.0102971\n",
      "Ending epoch 175: loss 0.0202456\n",
      "Ending epoch 176: loss 0.0109192\n",
      "Ending epoch 177: loss 0.0108945\n",
      "Ending epoch 178: loss 0.0121319\n",
      "Ending epoch 179: loss 0.0131418\n",
      "Ending epoch 180: loss 0.0113959\n",
      "Ending epoch 181: loss 0.00908606\n",
      "Ending epoch 182: loss 0.010672\n",
      "Ending epoch 183: loss 0.0115838\n",
      "Ending epoch 184: loss 0.0109901\n",
      "Ending epoch 185: loss 0.0124102\n",
      "Ending epoch 186: loss 0.0116135\n",
      "Ending epoch 187: loss 0.00946576\n",
      "Ending epoch 188: loss 0.0128033\n",
      "Ending epoch 189: loss 0.0113848\n",
      "Ending epoch 190: loss 0.0107173\n",
      "Ending epoch 191: loss 0.015896\n",
      "Ending epoch 192: loss 0.0132724\n",
      "Ending epoch 193: loss 0.00997087\n",
      "Ending epoch 194: loss 0.00823347\n",
      "Ending epoch 195: loss 0.0163531\n",
      "Ending epoch 196: loss 0.0116882\n",
      "Ending epoch 197: loss 0.0169791\n",
      "Ending epoch 198: loss 0.0157478\n",
      "Ending epoch 199: loss 0.0124192\n",
      "Ending epoch 200: loss 0.0132099\n",
      "Ending epoch 201: loss 0.011896\n",
      "Ending epoch 202: loss 0.0129162\n",
      "Ending epoch 203: loss 0.0121757\n",
      "Ending epoch 204: loss 0.0110784\n",
      "Ending epoch 205: loss 0.0161036\n",
      "Ending epoch 206: loss 0.0104708\n",
      "Ending epoch 207: loss 0.0151891\n",
      "Ending epoch 208: loss 0.0137067\n",
      "Ending epoch 209: loss 0.0150726\n",
      "Ending epoch 210: loss 0.0103225\n",
      "Ending epoch 211: loss 0.0099619\n",
      "Ending epoch 212: loss 0.0123826\n",
      "Ending epoch 213: loss 0.0122279\n",
      "Ending epoch 214: loss 0.0171977\n",
      "Ending epoch 215: loss 0.0130987\n",
      "Ending epoch 216: loss 0.0120144\n",
      "Ending epoch 217: loss 0.0141084\n",
      "Ending epoch 218: loss 0.0128953\n",
      "Ending epoch 219: loss 0.00879832\n",
      "Ending epoch 220: loss 0.0113591\n",
      "Ending epoch 221: loss 0.00877768\n",
      "Ending epoch 222: loss 0.0129819\n",
      "Ending epoch 223: loss 0.0112061\n",
      "Ending epoch 224: loss 0.0163016\n",
      "Ending epoch 225: loss 0.0122925\n",
      "Ending epoch 226: loss 0.00867923\n",
      "Ending epoch 227: loss 0.0133174\n",
      "Ending epoch 228: loss 0.010043\n",
      "Ending epoch 229: loss 0.00860208\n",
      "Ending epoch 230: loss 0.012483\n",
      "Ending epoch 231: loss 0.0120327\n",
      "Ending epoch 232: loss 0.0119434\n",
      "Ending epoch 233: loss 0.0120993\n",
      "Ending epoch 234: loss 0.011115\n",
      "Ending epoch 235: loss 0.0134222\n",
      "Ending epoch 236: loss 0.015005\n",
      "Ending epoch 237: loss 0.00894539\n",
      "Ending epoch 238: loss 0.00959189\n",
      "Ending epoch 239: loss 0.00835526\n",
      "Ending epoch 240: loss 0.0132321\n",
      "Ending epoch 241: loss 0.0110123\n",
      "Ending epoch 242: loss 0.0131541\n",
      "Ending epoch 243: loss 0.0125495\n",
      "Ending epoch 244: loss 0.0106943\n",
      "Ending epoch 245: loss 0.00952864\n",
      "Ending epoch 246: loss 0.0104989\n",
      "Ending epoch 247: loss 0.00914345\n",
      "Ending epoch 248: loss 0.0104793\n",
      "Ending epoch 249: loss 0.00899382\n",
      "Ending epoch 250: loss 0.0127506\n",
      "Ending epoch 251: loss 0.0109192\n",
      "Ending epoch 252: loss 0.0109291\n",
      "Ending epoch 253: loss 0.0132337\n",
      "Ending epoch 254: loss 0.0115381\n",
      "Ending epoch 255: loss 0.0133768\n",
      "Ending epoch 256: loss 0.00841702\n",
      "Ending epoch 257: loss 0.0158066\n",
      "Ending epoch 258: loss 0.00974868\n",
      "Ending epoch 259: loss 0.00879712\n",
      "Ending epoch 260: loss 0.0207859\n",
      "Ending epoch 261: loss 0.0107686\n",
      "Ending epoch 262: loss 0.0106866\n",
      "Ending epoch 263: loss 0.00936327\n",
      "Ending epoch 264: loss 0.00734345\n",
      "Ending epoch 265: loss 0.00837667\n",
      "Ending epoch 266: loss 0.0130851\n",
      "Ending epoch 267: loss 0.00990578\n",
      "Ending epoch 268: loss 0.0110134\n",
      "Ending epoch 269: loss 0.00896639\n",
      "Ending epoch 270: loss 0.00851279\n",
      "Ending epoch 271: loss 0.0102033\n",
      "Ending epoch 272: loss 0.0134501\n",
      "Ending epoch 273: loss 0.00897629\n",
      "Ending epoch 274: loss 0.00946758\n",
      "Ending epoch 275: loss 0.00929914\n",
      "Ending epoch 276: loss 0.00656738\n",
      "Ending epoch 277: loss 0.0105618\n",
      "Ending epoch 278: loss 0.0145831\n",
      "Ending epoch 279: loss 0.00851641\n",
      "Ending epoch 280: loss 0.0116642\n",
      "Ending epoch 281: loss 0.0115206\n",
      "Ending epoch 282: loss 0.0113034\n",
      "Ending epoch 283: loss 0.0085202\n",
      "Ending epoch 284: loss 0.00922697\n",
      "Ending epoch 285: loss 0.00760366\n",
      "Ending epoch 286: loss 0.00965096\n",
      "Ending epoch 287: loss 0.00942569\n",
      "Ending epoch 288: loss 0.0161084\n",
      "Ending epoch 289: loss 0.0095963\n",
      "Ending epoch 290: loss 0.0101882\n",
      "Ending epoch 291: loss 0.00991725\n",
      "Ending epoch 292: loss 0.00884429\n",
      "Ending epoch 293: loss 0.0088882\n",
      "Ending epoch 294: loss 0.0104731\n",
      "Ending epoch 295: loss 0.00840393\n",
      "Ending epoch 296: loss 0.00905988\n",
      "Ending epoch 297: loss 0.00937304\n",
      "Ending epoch 298: loss 0.011346\n",
      "Ending epoch 299: loss 0.00747606\n",
      "Ending epoch 300: loss 0.00932636\n",
      "Ending epoch 301: loss 0.0102241\n",
      "Ending epoch 302: loss 0.00817903\n",
      "Ending epoch 303: loss 0.00857425\n",
      "Ending epoch 304: loss 0.0103839\n",
      "Ending epoch 305: loss 0.00888859\n",
      "Ending epoch 306: loss 0.0133783\n",
      "Ending epoch 307: loss 0.00791453\n",
      "Ending epoch 308: loss 0.0110479\n",
      "Ending epoch 309: loss 0.00805603\n",
      "Ending epoch 310: loss 0.00723996\n",
      "Ending epoch 311: loss 0.0100867\n",
      "Ending epoch 312: loss 0.00987247\n",
      "Ending epoch 313: loss 0.0071035\n",
      "Ending epoch 314: loss 0.00981781\n",
      "Ending epoch 315: loss 0.0107219\n",
      "Ending epoch 316: loss 0.00907489\n",
      "Ending epoch 317: loss 0.00709736\n",
      "Ending epoch 318: loss 0.00986454\n",
      "Ending epoch 319: loss 0.0108416\n",
      "Ending epoch 320: loss 0.00872319\n",
      "Ending epoch 321: loss 0.0103709\n",
      "Ending epoch 322: loss 0.00984444\n",
      "Ending epoch 323: loss 0.00829597\n",
      "Ending epoch 324: loss 0.011671\n",
      "Ending epoch 325: loss 0.00991442\n",
      "Ending epoch 326: loss 0.00818225\n",
      "Ending epoch 327: loss 0.0119267\n",
      "Ending epoch 328: loss 0.00884764\n",
      "Ending epoch 329: loss 0.0101232\n",
      "Ending epoch 330: loss 0.00899812\n",
      "Ending epoch 331: loss 0.00655479\n",
      "Ending epoch 332: loss 0.00962671\n",
      "Ending epoch 333: loss 0.00968026\n",
      "Ending epoch 334: loss 0.00917037\n",
      "Ending epoch 335: loss 0.00951378\n",
      "Ending epoch 336: loss 0.00649069\n",
      "Ending epoch 337: loss 0.0129011\n",
      "Ending epoch 338: loss 0.00874088\n",
      "Ending epoch 339: loss 0.00741929\n",
      "Ending epoch 340: loss 0.00771572\n",
      "Ending epoch 341: loss 0.00895051\n",
      "Ending epoch 342: loss 0.00840954\n",
      "Ending epoch 343: loss 0.0133045\n",
      "Ending epoch 344: loss 0.0095467\n",
      "Ending epoch 345: loss 0.0139485\n",
      "Ending epoch 346: loss 0.00761285\n",
      "Ending epoch 347: loss 0.00974891\n",
      "Ending epoch 348: loss 0.00788586\n",
      "Ending epoch 349: loss 0.0124654\n",
      "Ending epoch 350: loss 0.0102328\n",
      "Ending epoch 351: loss 0.00745078\n",
      "Ending epoch 352: loss 0.00928616\n",
      "Ending epoch 353: loss 0.0117587\n",
      "Ending epoch 354: loss 0.0106382\n",
      "Ending epoch 355: loss 0.0104362\n",
      "Ending epoch 356: loss 0.00606845\n",
      "Ending epoch 357: loss 0.00906837\n",
      "Ending epoch 358: loss 0.00960355\n",
      "Ending epoch 359: loss 0.0103674\n",
      "Ending epoch 360: loss 0.00809148\n",
      "Ending epoch 361: loss 0.00772772\n",
      "Ending epoch 362: loss 0.0136834\n",
      "Ending epoch 363: loss 0.00830553\n",
      "Ending epoch 364: loss 0.00707647\n",
      "Ending epoch 365: loss 0.00898569\n",
      "Ending epoch 366: loss 0.0105861\n",
      "Ending epoch 367: loss 0.00841315\n",
      "Ending epoch 368: loss 0.00708186\n",
      "Ending epoch 369: loss 0.00735448\n",
      "Ending epoch 370: loss 0.0102509\n",
      "Ending epoch 371: loss 0.00904101\n",
      "Ending epoch 372: loss 0.00768341\n",
      "Ending epoch 373: loss 0.0085427\n",
      "Ending epoch 374: loss 0.0102918\n",
      "Ending epoch 375: loss 0.00782408\n",
      "Ending epoch 376: loss 0.0105134\n",
      "Ending epoch 377: loss 0.00717541\n",
      "Ending epoch 378: loss 0.0120262\n",
      "Ending epoch 379: loss 0.00905899\n",
      "Ending epoch 380: loss 0.00784113\n",
      "Ending epoch 381: loss 0.0122971\n",
      "Ending epoch 382: loss 0.00832842\n",
      "Ending epoch 383: loss 0.0151995\n",
      "Ending epoch 384: loss 0.0078003\n",
      "Ending epoch 385: loss 0.0074035\n",
      "Ending epoch 386: loss 0.0108584\n",
      "Ending epoch 387: loss 0.0112713\n",
      "Ending epoch 388: loss 0.011741\n",
      "Ending epoch 389: loss 0.00951323\n",
      "Ending epoch 390: loss 0.00857094\n",
      "Ending epoch 391: loss 0.00863762\n",
      "Ending epoch 392: loss 0.00863992\n",
      "Ending epoch 393: loss 0.0107262\n",
      "Ending epoch 394: loss 0.00964885\n",
      "Ending epoch 395: loss 0.00727913\n",
      "Ending epoch 396: loss 0.00720911\n",
      "Ending epoch 397: loss 0.00829101\n",
      "Ending epoch 398: loss 0.00694686\n",
      "Ending epoch 399: loss 0.00848268\n",
      "Ending epoch 400: loss 0.00947783\n",
      "Ending epoch 401: loss 0.0110273\n",
      "Ending epoch 402: loss 0.00767017\n",
      "Ending epoch 403: loss 0.00878855\n",
      "Ending epoch 404: loss 0.00835571\n",
      "Ending epoch 405: loss 0.0100464\n",
      "Ending epoch 406: loss 0.00776776\n",
      "Ending epoch 407: loss 0.00888452\n",
      "Ending epoch 408: loss 0.0111384\n",
      "Ending epoch 409: loss 0.00860029\n",
      "Ending epoch 410: loss 0.0119349\n",
      "Ending epoch 411: loss 0.00712514\n",
      "Ending epoch 412: loss 0.00887197\n",
      "Ending epoch 413: loss 0.00776435\n",
      "Ending epoch 414: loss 0.0113873\n",
      "Ending epoch 415: loss 0.0084788\n",
      "Ending epoch 416: loss 0.0102758\n",
      "Ending epoch 417: loss 0.0134191\n",
      "Ending epoch 418: loss 0.0109076\n",
      "Ending epoch 419: loss 0.00751036\n",
      "Ending epoch 420: loss 0.0136818\n",
      "Ending epoch 421: loss 0.00689193\n",
      "Ending epoch 422: loss 0.0102782\n",
      "Ending epoch 423: loss 0.00721747\n",
      "Ending epoch 424: loss 0.0089843\n",
      "Ending epoch 425: loss 0.01137\n",
      "Ending epoch 426: loss 0.00785592\n",
      "Ending epoch 427: loss 0.00677294\n",
      "Ending epoch 428: loss 0.00919951\n",
      "Ending epoch 429: loss 0.00610538\n",
      "Ending epoch 430: loss 0.0117858\n",
      "Ending epoch 431: loss 0.0109156\n",
      "Ending epoch 432: loss 0.00642623\n",
      "Ending epoch 433: loss 0.00904899\n",
      "Ending epoch 434: loss 0.00850495\n",
      "Ending epoch 435: loss 0.00815043\n",
      "Ending epoch 436: loss 0.00858541\n",
      "Ending epoch 437: loss 0.00975085\n",
      "Ending epoch 438: loss 0.011239\n",
      "Ending epoch 439: loss 0.00864325\n",
      "Ending epoch 440: loss 0.00902543\n",
      "Ending epoch 441: loss 0.00834186\n",
      "Ending epoch 442: loss 0.00801098\n",
      "Ending epoch 443: loss 0.0101488\n",
      "Ending epoch 444: loss 0.00970538\n",
      "Ending epoch 445: loss 0.00853232\n",
      "Ending epoch 446: loss 0.00989461\n",
      "Ending epoch 447: loss 0.00740339\n",
      "Ending epoch 448: loss 0.00757468\n",
      "Ending epoch 449: loss 0.00783225\n",
      "Ending epoch 450: loss 0.00752038\n",
      "Ending epoch 451: loss 0.00740604\n",
      "Ending epoch 452: loss 0.00863948\n",
      "Ending epoch 453: loss 0.00817985\n",
      "Ending epoch 454: loss 0.00821786\n",
      "Ending epoch 455: loss 0.00892029\n",
      "Ending epoch 456: loss 0.00901411\n",
      "Ending epoch 457: loss 0.00772307\n",
      "Ending epoch 458: loss 0.0118318\n",
      "Ending epoch 459: loss 0.00785581\n",
      "Ending epoch 460: loss 0.00998119\n",
      "Ending epoch 461: loss 0.00925126\n",
      "Ending epoch 462: loss 0.00954714\n",
      "Ending epoch 463: loss 0.00701687\n",
      "Ending epoch 464: loss 0.00826517\n",
      "Ending epoch 465: loss 0.00611093\n",
      "Ending epoch 466: loss 0.00619171\n",
      "Ending epoch 467: loss 0.00777818\n",
      "Ending epoch 468: loss 0.00879444\n",
      "Ending epoch 469: loss 0.00626603\n",
      "Ending epoch 470: loss 0.00693513\n",
      "Ending epoch 471: loss 0.00821101\n",
      "Ending epoch 472: loss 0.00784885\n",
      "Ending epoch 473: loss 0.00811762\n",
      "Ending epoch 474: loss 0.00869422\n",
      "Ending epoch 475: loss 0.0100072\n",
      "Ending epoch 476: loss 0.00624849\n",
      "Ending epoch 477: loss 0.00564473\n",
      "Ending epoch 478: loss 0.00779073\n",
      "Ending epoch 479: loss 0.00936685\n",
      "Ending epoch 480: loss 0.00893989\n",
      "Ending epoch 481: loss 0.00840589\n",
      "Ending epoch 482: loss 0.010025\n",
      "Ending epoch 483: loss 0.00934241\n",
      "Ending epoch 484: loss 0.0112773\n",
      "Ending epoch 485: loss 0.00755883\n",
      "Ending epoch 486: loss 0.0097291\n",
      "Ending epoch 487: loss 0.00870864\n",
      "Ending epoch 488: loss 0.00678739\n",
      "Ending epoch 489: loss 0.0125718\n",
      "Ending epoch 490: loss 0.00635581\n",
      "Ending epoch 491: loss 0.00884659\n",
      "Ending epoch 492: loss 0.00878129\n",
      "Ending epoch 493: loss 0.010042\n",
      "Ending epoch 494: loss 0.00914729\n",
      "Ending epoch 495: loss 0.00667864\n",
      "Ending epoch 496: loss 0.00805445\n",
      "Ending epoch 497: loss 0.00599826\n",
      "Ending epoch 498: loss 0.00605635\n",
      "Ending epoch 499: loss 0.00826354\n",
      "Model 4/8, Metric mean_absolute_error, Validation set 3: 21.384058\n",
      "\tbest_validation_score so far: 21.384058\n",
      "Fitting model 5/8\n",
      "hyperparameters: {u'optimizer': u'momentum', u'layer_sizes': [1000, 1000, 100], u'data_shape': (23,), u'learning_rate': 0.0001, u'batch_size': 100, u'penalty': 0.0, u'bias_init_consts': [1.0, 1.0, 1.0], u'weight_init_stddevs': [0.077459666924148338, 0.077459666924148338, 0.077459666924148338], u'num_regression_tasks': 1, u'dropouts': [0.1, 0.1, 0.1], u'nb_epoch': 500, u'momentum': 0.9}\n",
      "Training for 500 epochs\n",
      "Ending epoch 0: loss 1.19022\n",
      "Ending epoch 1: loss 0.917989\n",
      "Ending epoch 2: loss 0.748712\n",
      "Ending epoch 3: loss 0.63612\n",
      "Ending epoch 4: loss 0.527647\n",
      "Ending epoch 5: loss 0.408179\n",
      "Ending epoch 6: loss 0.401478\n",
      "Ending epoch 7: loss 0.360798\n",
      "Ending epoch 8: loss 0.251538\n",
      "Ending epoch 9: loss 0.272963\n",
      "Ending epoch 10: loss 0.249176\n",
      "Ending epoch 11: loss 0.209689\n",
      "Ending epoch 12: loss 0.216792\n",
      "Ending epoch 13: loss 0.198304\n",
      "Ending epoch 14: loss 0.215834\n",
      "Ending epoch 15: loss 0.207271\n",
      "Ending epoch 16: loss 0.192121\n",
      "Ending epoch 17: loss 0.125771\n",
      "Ending epoch 18: loss 0.192078\n",
      "Ending epoch 19: loss 0.136642\n",
      "Ending epoch 20: loss 0.126943\n",
      "Ending epoch 21: loss 0.11464\n",
      "Ending epoch 22: loss 0.105031\n",
      "Ending epoch 23: loss 0.103778\n",
      "Ending epoch 24: loss 0.10703\n",
      "Ending epoch 25: loss 0.13708\n",
      "Ending epoch 26: loss 0.1179\n",
      "Ending epoch 27: loss 0.098156\n",
      "Ending epoch 28: loss 0.0900832\n",
      "Ending epoch 29: loss 0.103602\n",
      "Ending epoch 30: loss 0.137265\n",
      "Ending epoch 31: loss 0.106829\n",
      "Ending epoch 32: loss 0.095586\n",
      "Ending epoch 33: loss 0.106937\n",
      "Ending epoch 34: loss 0.0960419\n",
      "Ending epoch 35: loss 0.106512\n",
      "Ending epoch 36: loss 0.0747193\n",
      "Ending epoch 37: loss 0.0836249\n",
      "Ending epoch 38: loss 0.0767632\n",
      "Ending epoch 39: loss 0.0713009\n",
      "Ending epoch 40: loss 0.080399\n",
      "Ending epoch 41: loss 0.0865726\n",
      "Ending epoch 42: loss 0.0748736\n",
      "Ending epoch 43: loss 0.0728442\n",
      "Ending epoch 44: loss 0.0938328\n",
      "Ending epoch 45: loss 0.0795109\n",
      "Ending epoch 46: loss 0.0681525\n",
      "Ending epoch 47: loss 0.0771834\n",
      "Ending epoch 48: loss 0.0845631\n",
      "Ending epoch 49: loss 0.0817591\n",
      "Ending epoch 50: loss 0.0695381\n",
      "Ending epoch 51: loss 0.0902107\n",
      "Ending epoch 52: loss 0.0617201\n",
      "Ending epoch 53: loss 0.0806112\n",
      "Ending epoch 54: loss 0.0654794\n",
      "Ending epoch 55: loss 0.0676313\n",
      "Ending epoch 56: loss 0.0607645\n",
      "Ending epoch 57: loss 0.0768245\n",
      "Ending epoch 58: loss 0.0586836\n",
      "Ending epoch 59: loss 0.0849529\n",
      "Ending epoch 60: loss 0.0605322\n",
      "Ending epoch 61: loss 0.0670828\n",
      "Ending epoch 62: loss 0.075483\n",
      "Ending epoch 63: loss 0.0702442\n",
      "Ending epoch 64: loss 0.0766108\n",
      "Ending epoch 65: loss 0.073672\n",
      "Ending epoch 66: loss 0.0744978\n",
      "Ending epoch 67: loss 0.088952\n",
      "Ending epoch 68: loss 0.0551393\n",
      "Ending epoch 69: loss 0.0595576\n",
      "Ending epoch 70: loss 0.0625686\n",
      "Ending epoch 71: loss 0.0635877\n",
      "Ending epoch 72: loss 0.0903906\n",
      "Ending epoch 73: loss 0.0772333\n",
      "Ending epoch 74: loss 0.0461668\n",
      "Ending epoch 75: loss 0.0490078\n",
      "Ending epoch 76: loss 0.0624182\n",
      "Ending epoch 77: loss 0.0593195\n",
      "Ending epoch 78: loss 0.0771728\n",
      "Ending epoch 79: loss 0.0654065\n",
      "Ending epoch 80: loss 0.0682918\n",
      "Ending epoch 81: loss 0.0655337\n",
      "Ending epoch 82: loss 0.0657404\n",
      "Ending epoch 83: loss 0.0581583\n",
      "Ending epoch 84: loss 0.0473864\n",
      "Ending epoch 85: loss 0.0609547\n",
      "Ending epoch 86: loss 0.0734235\n",
      "Ending epoch 87: loss 0.0621347\n",
      "Ending epoch 88: loss 0.0597074\n",
      "Ending epoch 89: loss 0.063652\n",
      "Ending epoch 90: loss 0.0395664\n",
      "Ending epoch 91: loss 0.0549079\n",
      "Ending epoch 92: loss 0.0796824\n",
      "Ending epoch 93: loss 0.0578738\n",
      "Ending epoch 94: loss 0.0557237\n",
      "Ending epoch 95: loss 0.0648274\n",
      "Ending epoch 96: loss 0.0617093\n",
      "Ending epoch 97: loss 0.0765327\n",
      "Ending epoch 98: loss 0.0694868\n",
      "Ending epoch 99: loss 0.052432\n",
      "Ending epoch 100: loss 0.0728756\n",
      "Ending epoch 101: loss 0.0558118\n",
      "Ending epoch 102: loss 0.0401419\n",
      "Ending epoch 103: loss 0.0638702\n",
      "Ending epoch 104: loss 0.0611791\n",
      "Ending epoch 105: loss 0.0523264\n",
      "Ending epoch 106: loss 0.0545761\n",
      "Ending epoch 107: loss 0.0502897\n",
      "Ending epoch 108: loss 0.0551397\n",
      "Ending epoch 109: loss 0.0533423\n",
      "Ending epoch 110: loss 0.0575051\n",
      "Ending epoch 111: loss 0.0573757\n",
      "Ending epoch 112: loss 0.0401721\n",
      "Ending epoch 113: loss 0.0495295\n",
      "Ending epoch 114: loss 0.048958\n",
      "Ending epoch 115: loss 0.0573517\n",
      "Ending epoch 116: loss 0.0630251\n",
      "Ending epoch 117: loss 0.07342\n",
      "Ending epoch 118: loss 0.0460592\n",
      "Ending epoch 119: loss 0.0454202\n",
      "Ending epoch 120: loss 0.0452857\n",
      "Ending epoch 121: loss 0.0520456\n",
      "Ending epoch 122: loss 0.0518376\n",
      "Ending epoch 123: loss 0.0590504\n",
      "Ending epoch 124: loss 0.0425136\n",
      "Ending epoch 125: loss 0.0380271\n",
      "Ending epoch 126: loss 0.0590964\n",
      "Ending epoch 127: loss 0.0535276\n",
      "Ending epoch 128: loss 0.0460574\n",
      "Ending epoch 129: loss 0.0634173\n",
      "Ending epoch 130: loss 0.0515194\n",
      "Ending epoch 131: loss 0.0523487\n",
      "Ending epoch 132: loss 0.0464936\n",
      "Ending epoch 133: loss 0.054601\n",
      "Ending epoch 134: loss 0.0545442\n",
      "Ending epoch 135: loss 0.0548177\n",
      "Ending epoch 136: loss 0.0551449\n",
      "Ending epoch 137: loss 0.0559657\n",
      "Ending epoch 138: loss 0.0678043\n",
      "Ending epoch 139: loss 0.0504138\n",
      "Ending epoch 140: loss 0.0418111\n",
      "Ending epoch 141: loss 0.0459957\n",
      "Ending epoch 142: loss 0.0562491\n",
      "Ending epoch 143: loss 0.0533079\n",
      "Ending epoch 144: loss 0.0419115\n",
      "Ending epoch 145: loss 0.0425798\n",
      "Ending epoch 146: loss 0.0575824\n",
      "Ending epoch 147: loss 0.0528517\n",
      "Ending epoch 148: loss 0.0578306\n",
      "Ending epoch 149: loss 0.0541678\n",
      "Ending epoch 150: loss 0.043548\n",
      "Ending epoch 151: loss 0.0362684\n",
      "Ending epoch 152: loss 0.0345655\n",
      "Ending epoch 153: loss 0.0409489\n",
      "Ending epoch 154: loss 0.0396528\n",
      "Ending epoch 155: loss 0.0539775\n",
      "Ending epoch 156: loss 0.0438012\n",
      "Ending epoch 157: loss 0.0415054\n",
      "Ending epoch 158: loss 0.0449319\n",
      "Ending epoch 159: loss 0.0519659\n",
      "Ending epoch 160: loss 0.0462692\n",
      "Ending epoch 161: loss 0.0655695\n",
      "Ending epoch 162: loss 0.0421672\n",
      "Ending epoch 163: loss 0.0420682\n",
      "Ending epoch 164: loss 0.050886\n",
      "Ending epoch 165: loss 0.0465966\n",
      "Ending epoch 166: loss 0.0471977\n",
      "Ending epoch 167: loss 0.0483375\n",
      "Ending epoch 168: loss 0.0525354\n",
      "Ending epoch 169: loss 0.0425125\n",
      "Ending epoch 170: loss 0.037072\n",
      "Ending epoch 171: loss 0.0501087\n",
      "Ending epoch 172: loss 0.0406644\n",
      "Ending epoch 173: loss 0.0372047\n",
      "Ending epoch 174: loss 0.0474155\n",
      "Ending epoch 175: loss 0.0416791\n",
      "Ending epoch 176: loss 0.0513785\n",
      "Ending epoch 177: loss 0.0514151\n",
      "Ending epoch 178: loss 0.0415906\n",
      "Ending epoch 179: loss 0.04228\n",
      "Ending epoch 180: loss 0.0372225\n",
      "Ending epoch 181: loss 0.0501078\n",
      "Ending epoch 182: loss 0.0452603\n",
      "Ending epoch 183: loss 0.0463433\n",
      "Ending epoch 184: loss 0.0452332\n",
      "Ending epoch 185: loss 0.0429257\n",
      "Ending epoch 186: loss 0.0343902\n",
      "Ending epoch 187: loss 0.0663448\n",
      "Ending epoch 188: loss 0.0413785\n",
      "Ending epoch 189: loss 0.0472332\n",
      "Ending epoch 190: loss 0.0387578\n",
      "Ending epoch 191: loss 0.0524995\n",
      "Ending epoch 192: loss 0.0485036\n",
      "Ending epoch 193: loss 0.03822\n",
      "Ending epoch 194: loss 0.0420166\n",
      "Ending epoch 195: loss 0.046733\n",
      "Ending epoch 196: loss 0.0479018\n",
      "Ending epoch 197: loss 0.0366914\n",
      "Ending epoch 198: loss 0.0400941\n",
      "Ending epoch 199: loss 0.0515586\n",
      "Ending epoch 200: loss 0.0371418\n",
      "Ending epoch 201: loss 0.0438321\n",
      "Ending epoch 202: loss 0.046777\n",
      "Ending epoch 203: loss 0.0393512\n",
      "Ending epoch 204: loss 0.0432915\n",
      "Ending epoch 205: loss 0.0459009\n",
      "Ending epoch 206: loss 0.0356462\n",
      "Ending epoch 207: loss 0.034204\n",
      "Ending epoch 208: loss 0.0551511\n",
      "Ending epoch 209: loss 0.0479534\n",
      "Ending epoch 210: loss 0.0368204\n",
      "Ending epoch 211: loss 0.0358795\n",
      "Ending epoch 212: loss 0.0458515\n",
      "Ending epoch 213: loss 0.0398882\n",
      "Ending epoch 214: loss 0.0532945\n",
      "Ending epoch 215: loss 0.0505518\n",
      "Ending epoch 216: loss 0.0348114\n",
      "Ending epoch 217: loss 0.0406633\n",
      "Ending epoch 218: loss 0.0592449\n",
      "Ending epoch 219: loss 0.0391142\n",
      "Ending epoch 220: loss 0.0416971\n",
      "Ending epoch 221: loss 0.0331694\n",
      "Ending epoch 222: loss 0.0546096\n",
      "Ending epoch 223: loss 0.0507474\n",
      "Ending epoch 224: loss 0.0314982\n",
      "Ending epoch 225: loss 0.0476898\n",
      "Ending epoch 226: loss 0.046775\n",
      "Ending epoch 227: loss 0.0424293\n",
      "Ending epoch 228: loss 0.0379388\n",
      "Ending epoch 229: loss 0.0452484\n",
      "Ending epoch 230: loss 0.0433283\n",
      "Ending epoch 231: loss 0.0585326\n",
      "Ending epoch 232: loss 0.0507477\n",
      "Ending epoch 233: loss 0.0336078\n",
      "Ending epoch 234: loss 0.0471121\n",
      "Ending epoch 235: loss 0.037702\n",
      "Ending epoch 236: loss 0.0387787\n",
      "Ending epoch 237: loss 0.0438697\n",
      "Ending epoch 238: loss 0.043937\n",
      "Ending epoch 239: loss 0.0408257\n",
      "Ending epoch 240: loss 0.0457117\n",
      "Ending epoch 241: loss 0.0428256\n",
      "Ending epoch 242: loss 0.0396965\n",
      "Ending epoch 243: loss 0.0379057\n",
      "Ending epoch 244: loss 0.0348526\n",
      "Ending epoch 245: loss 0.0404292\n",
      "Ending epoch 246: loss 0.0435989\n",
      "Ending epoch 247: loss 0.029429\n",
      "Ending epoch 248: loss 0.0378808\n",
      "Ending epoch 249: loss 0.0476707\n",
      "Ending epoch 250: loss 0.036228\n",
      "Ending epoch 251: loss 0.0439295\n",
      "Ending epoch 252: loss 0.0367864\n",
      "Ending epoch 253: loss 0.0315732\n",
      "Ending epoch 254: loss 0.0445929\n",
      "Ending epoch 255: loss 0.039362\n",
      "Ending epoch 256: loss 0.0400403\n",
      "Ending epoch 257: loss 0.0335782\n",
      "Ending epoch 258: loss 0.0436504\n",
      "Ending epoch 259: loss 0.0396075\n",
      "Ending epoch 260: loss 0.0389024\n",
      "Ending epoch 261: loss 0.0478375\n",
      "Ending epoch 262: loss 0.0334434\n",
      "Ending epoch 263: loss 0.04808\n",
      "Ending epoch 264: loss 0.0374311\n",
      "Ending epoch 265: loss 0.0500491\n",
      "Ending epoch 266: loss 0.0343184\n",
      "Ending epoch 267: loss 0.0413118\n",
      "Ending epoch 268: loss 0.0401772\n",
      "Ending epoch 269: loss 0.0365347\n",
      "Ending epoch 270: loss 0.0266701\n",
      "Ending epoch 271: loss 0.0494463\n",
      "Ending epoch 272: loss 0.0356541\n",
      "Ending epoch 273: loss 0.0377685\n",
      "Ending epoch 274: loss 0.0422932\n",
      "Ending epoch 275: loss 0.0314935\n",
      "Ending epoch 276: loss 0.0388476\n",
      "Ending epoch 277: loss 0.0256025\n",
      "Ending epoch 278: loss 0.0387767\n",
      "Ending epoch 279: loss 0.0372719\n",
      "Ending epoch 280: loss 0.0383079\n",
      "Ending epoch 281: loss 0.0410104\n",
      "Ending epoch 282: loss 0.0341257\n",
      "Ending epoch 283: loss 0.0320316\n",
      "Ending epoch 284: loss 0.0344595\n",
      "Ending epoch 285: loss 0.042484\n",
      "Ending epoch 286: loss 0.0358377\n",
      "Ending epoch 287: loss 0.0334593\n",
      "Ending epoch 288: loss 0.0451686\n",
      "Ending epoch 289: loss 0.0350942\n",
      "Ending epoch 290: loss 0.0301654\n",
      "Ending epoch 291: loss 0.0370074\n",
      "Ending epoch 292: loss 0.0321247\n",
      "Ending epoch 293: loss 0.0347926\n",
      "Ending epoch 294: loss 0.0446731\n",
      "Ending epoch 295: loss 0.0409746\n",
      "Ending epoch 296: loss 0.0316429\n",
      "Ending epoch 297: loss 0.0377825\n",
      "Ending epoch 298: loss 0.0322893\n",
      "Ending epoch 299: loss 0.0352234\n",
      "Ending epoch 300: loss 0.0387486\n",
      "Ending epoch 301: loss 0.0315132\n",
      "Ending epoch 302: loss 0.0414901\n",
      "Ending epoch 303: loss 0.0348239\n",
      "Ending epoch 304: loss 0.0273398\n",
      "Ending epoch 305: loss 0.0377251\n",
      "Ending epoch 306: loss 0.0275826\n",
      "Ending epoch 307: loss 0.0402736\n",
      "Ending epoch 308: loss 0.038264\n",
      "Ending epoch 309: loss 0.0438128\n",
      "Ending epoch 310: loss 0.0321755\n",
      "Ending epoch 311: loss 0.0436188\n",
      "Ending epoch 312: loss 0.0413384\n",
      "Ending epoch 313: loss 0.0355299\n",
      "Ending epoch 314: loss 0.0332566\n",
      "Ending epoch 315: loss 0.0364413\n",
      "Ending epoch 316: loss 0.0324338\n",
      "Ending epoch 317: loss 0.059841\n",
      "Ending epoch 318: loss 0.0357745\n",
      "Ending epoch 319: loss 0.0374815\n",
      "Ending epoch 320: loss 0.0389049\n",
      "Ending epoch 321: loss 0.0229658\n",
      "Ending epoch 322: loss 0.0269034\n",
      "Ending epoch 323: loss 0.0322923\n",
      "Ending epoch 324: loss 0.0281587\n",
      "Ending epoch 325: loss 0.0398616\n",
      "Ending epoch 326: loss 0.0336961\n",
      "Ending epoch 327: loss 0.0421045\n",
      "Ending epoch 328: loss 0.042236\n",
      "Ending epoch 329: loss 0.0437371\n",
      "Ending epoch 330: loss 0.0323027\n",
      "Ending epoch 331: loss 0.035249\n",
      "Ending epoch 332: loss 0.0376388\n",
      "Ending epoch 333: loss 0.02908\n",
      "Ending epoch 334: loss 0.0297916\n",
      "Ending epoch 335: loss 0.033126\n",
      "Ending epoch 336: loss 0.039579\n",
      "Ending epoch 337: loss 0.0310621\n",
      "Ending epoch 338: loss 0.0340869\n",
      "Ending epoch 339: loss 0.0413569\n",
      "Ending epoch 340: loss 0.0365622\n",
      "Ending epoch 341: loss 0.0421426\n",
      "Ending epoch 342: loss 0.0392209\n",
      "Ending epoch 343: loss 0.0296593\n",
      "Ending epoch 344: loss 0.0386271\n",
      "Ending epoch 345: loss 0.0409444\n",
      "Ending epoch 346: loss 0.0259251\n",
      "Ending epoch 347: loss 0.0335191\n",
      "Ending epoch 348: loss 0.0354263\n",
      "Ending epoch 349: loss 0.029153\n",
      "Ending epoch 350: loss 0.0381192\n",
      "Ending epoch 351: loss 0.0288705\n",
      "Ending epoch 352: loss 0.0290483\n",
      "Ending epoch 353: loss 0.0270454\n",
      "Ending epoch 354: loss 0.0354678\n",
      "Ending epoch 355: loss 0.0277977\n",
      "Ending epoch 356: loss 0.037553\n",
      "Ending epoch 357: loss 0.0329777\n",
      "Ending epoch 358: loss 0.0400074\n",
      "Ending epoch 359: loss 0.028547\n",
      "Ending epoch 360: loss 0.0306796\n",
      "Ending epoch 361: loss 0.0295993\n",
      "Ending epoch 362: loss 0.0354126\n",
      "Ending epoch 363: loss 0.0344253\n",
      "Ending epoch 364: loss 0.0332959\n",
      "Ending epoch 365: loss 0.0466849\n",
      "Ending epoch 366: loss 0.0284657\n",
      "Ending epoch 367: loss 0.0421208\n",
      "Ending epoch 368: loss 0.0290701\n",
      "Ending epoch 369: loss 0.0314948\n",
      "Ending epoch 370: loss 0.036432\n",
      "Ending epoch 371: loss 0.0265264\n",
      "Ending epoch 372: loss 0.0279497\n",
      "Ending epoch 373: loss 0.0323802\n",
      "Ending epoch 374: loss 0.0437343\n",
      "Ending epoch 375: loss 0.0351064\n",
      "Ending epoch 376: loss 0.0270742\n",
      "Ending epoch 377: loss 0.0331204\n",
      "Ending epoch 378: loss 0.033037\n",
      "Ending epoch 379: loss 0.0382524\n",
      "Ending epoch 380: loss 0.0297955\n",
      "Ending epoch 381: loss 0.0263078\n",
      "Ending epoch 382: loss 0.0351422\n",
      "Ending epoch 383: loss 0.0379974\n",
      "Ending epoch 384: loss 0.0366305\n",
      "Ending epoch 385: loss 0.0262954\n",
      "Ending epoch 386: loss 0.0303133\n",
      "Ending epoch 387: loss 0.0437145\n",
      "Ending epoch 388: loss 0.0358273\n",
      "Ending epoch 389: loss 0.0356827\n",
      "Ending epoch 390: loss 0.0351299\n",
      "Ending epoch 391: loss 0.0347888\n",
      "Ending epoch 392: loss 0.0350848\n",
      "Ending epoch 393: loss 0.0358459\n",
      "Ending epoch 394: loss 0.0364912\n",
      "Ending epoch 395: loss 0.0343673\n",
      "Ending epoch 396: loss 0.0314672\n",
      "Ending epoch 397: loss 0.0431223\n",
      "Ending epoch 398: loss 0.0287362\n",
      "Ending epoch 399: loss 0.0324277\n",
      "Ending epoch 400: loss 0.0264245\n",
      "Ending epoch 401: loss 0.0408869\n",
      "Ending epoch 402: loss 0.0317406\n",
      "Ending epoch 403: loss 0.0405444\n",
      "Ending epoch 404: loss 0.0310987\n",
      "Ending epoch 405: loss 0.0290926\n",
      "Ending epoch 406: loss 0.032312\n",
      "Ending epoch 407: loss 0.0361513\n",
      "Ending epoch 408: loss 0.0312449\n",
      "Ending epoch 409: loss 0.0318117\n",
      "Ending epoch 410: loss 0.031404\n",
      "Ending epoch 411: loss 0.0243693\n",
      "Ending epoch 412: loss 0.0423753\n",
      "Ending epoch 413: loss 0.0401114\n",
      "Ending epoch 414: loss 0.0402288\n",
      "Ending epoch 415: loss 0.0261939\n",
      "Ending epoch 416: loss 0.0339725\n",
      "Ending epoch 417: loss 0.027863\n",
      "Ending epoch 418: loss 0.0365846\n",
      "Ending epoch 419: loss 0.0336198\n",
      "Ending epoch 420: loss 0.0349137\n",
      "Ending epoch 421: loss 0.0372572\n",
      "Ending epoch 422: loss 0.0330426\n",
      "Ending epoch 423: loss 0.0368698\n",
      "Ending epoch 424: loss 0.0296568\n",
      "Ending epoch 425: loss 0.039417\n",
      "Ending epoch 426: loss 0.0380599\n",
      "Ending epoch 427: loss 0.0405037\n",
      "Ending epoch 428: loss 0.0385037\n",
      "Ending epoch 429: loss 0.0266214\n",
      "Ending epoch 430: loss 0.0347014\n",
      "Ending epoch 431: loss 0.0389761\n",
      "Ending epoch 432: loss 0.0333498\n",
      "Ending epoch 433: loss 0.0418399\n",
      "Ending epoch 434: loss 0.0408174\n",
      "Ending epoch 435: loss 0.0328917\n",
      "Ending epoch 436: loss 0.0298793\n",
      "Ending epoch 437: loss 0.0299964\n",
      "Ending epoch 438: loss 0.0331247\n",
      "Ending epoch 439: loss 0.0276045\n",
      "Ending epoch 440: loss 0.0235601\n",
      "Ending epoch 441: loss 0.0287006\n",
      "Ending epoch 442: loss 0.0274277\n",
      "Ending epoch 443: loss 0.0329847\n",
      "Ending epoch 444: loss 0.0255804\n",
      "Ending epoch 445: loss 0.0347106\n",
      "Ending epoch 446: loss 0.032716\n",
      "Ending epoch 447: loss 0.0330058\n",
      "Ending epoch 448: loss 0.0339677\n",
      "Ending epoch 449: loss 0.0258764\n",
      "Ending epoch 450: loss 0.0311007\n",
      "Ending epoch 451: loss 0.0343257\n",
      "Ending epoch 452: loss 0.0436528\n",
      "Ending epoch 453: loss 0.0353548\n",
      "Ending epoch 454: loss 0.0310317\n",
      "Ending epoch 455: loss 0.029842\n",
      "Ending epoch 456: loss 0.035093\n",
      "Ending epoch 457: loss 0.0362607\n",
      "Ending epoch 458: loss 0.0300316\n",
      "Ending epoch 459: loss 0.0260346\n",
      "Ending epoch 460: loss 0.035393\n",
      "Ending epoch 461: loss 0.0288959\n",
      "Ending epoch 462: loss 0.0378214\n",
      "Ending epoch 463: loss 0.0290954\n",
      "Ending epoch 464: loss 0.0323166\n",
      "Ending epoch 465: loss 0.0233109\n",
      "Ending epoch 466: loss 0.039014\n",
      "Ending epoch 467: loss 0.0357161\n",
      "Ending epoch 468: loss 0.0334973\n",
      "Ending epoch 469: loss 0.0309893\n",
      "Ending epoch 470: loss 0.0322536\n",
      "Ending epoch 471: loss 0.0256629\n",
      "Ending epoch 472: loss 0.0324694\n",
      "Ending epoch 473: loss 0.0355636\n",
      "Ending epoch 474: loss 0.0386172\n",
      "Ending epoch 475: loss 0.0365422\n",
      "Ending epoch 476: loss 0.0297377\n",
      "Ending epoch 477: loss 0.0229319\n",
      "Ending epoch 478: loss 0.0308265\n",
      "Ending epoch 479: loss 0.0257027\n",
      "Ending epoch 480: loss 0.0224547\n",
      "Ending epoch 481: loss 0.0283735\n",
      "Ending epoch 482: loss 0.0258057\n",
      "Ending epoch 483: loss 0.0327743\n",
      "Ending epoch 484: loss 0.0309522\n",
      "Ending epoch 485: loss 0.032299\n",
      "Ending epoch 486: loss 0.0244497\n",
      "Ending epoch 487: loss 0.0312264\n",
      "Ending epoch 488: loss 0.0280673\n",
      "Ending epoch 489: loss 0.0267077\n",
      "Ending epoch 490: loss 0.0332666\n",
      "Ending epoch 491: loss 0.0264666\n",
      "Ending epoch 492: loss 0.0294979\n",
      "Ending epoch 493: loss 0.0242519\n",
      "Ending epoch 494: loss 0.0331714\n",
      "Ending epoch 495: loss 0.0382067\n",
      "Ending epoch 496: loss 0.031255\n",
      "Ending epoch 497: loss 0.0296234\n",
      "Ending epoch 498: loss 0.0356167\n",
      "Ending epoch 499: loss 0.0304782\n",
      "Model 5/8, Metric mean_absolute_error, Validation set 4: 34.267239\n",
      "\tbest_validation_score so far: 21.384058\n",
      "Fitting model 6/8\n",
      "hyperparameters: {u'optimizer': u'momentum', u'layer_sizes': [1000, 1000, 50], u'data_shape': (23,), u'learning_rate': 0.0001, u'batch_size': 100, u'penalty': 0.0, u'bias_init_consts': [1.0, 1.0, 1.0], u'weight_init_stddevs': [0.077459666924148338, 0.077459666924148338, 0.077459666924148338], u'num_regression_tasks': 1, u'dropouts': [0.1, 0.1, 0.1], u'nb_epoch': 500, u'momentum': 0.9}\n",
      "Training for 500 epochs\n",
      "Ending epoch 0: loss 0.921702\n",
      "Ending epoch 1: loss 0.790883\n",
      "Ending epoch 2: loss 0.392573\n",
      "Ending epoch 3: loss 0.322508\n",
      "Ending epoch 4: loss 0.282075\n",
      "Ending epoch 5: loss 0.244842\n",
      "Ending epoch 6: loss 0.197728\n",
      "Ending epoch 7: loss 0.235048\n",
      "Ending epoch 8: loss 0.153304\n",
      "Ending epoch 9: loss 0.202248\n",
      "Ending epoch 10: loss 0.200762\n",
      "Ending epoch 11: loss 0.17548\n",
      "Ending epoch 12: loss 0.182224\n",
      "Ending epoch 13: loss 0.15659\n",
      "Ending epoch 14: loss 0.153469\n",
      "Ending epoch 15: loss 0.156904\n",
      "Ending epoch 16: loss 0.17414\n",
      "Ending epoch 17: loss 0.135294\n",
      "Ending epoch 18: loss 0.176346\n",
      "Ending epoch 19: loss 0.123581\n",
      "Ending epoch 20: loss 0.144466\n",
      "Ending epoch 21: loss 0.128092\n",
      "Ending epoch 22: loss 0.137113\n",
      "Ending epoch 23: loss 0.0979702\n",
      "Ending epoch 24: loss 0.109706\n",
      "Ending epoch 25: loss 0.132757\n",
      "Ending epoch 26: loss 0.144749\n",
      "Ending epoch 27: loss 0.142907\n",
      "Ending epoch 28: loss 0.103496\n",
      "Ending epoch 29: loss 0.094084\n",
      "Ending epoch 30: loss 0.0806937\n",
      "Ending epoch 31: loss 0.0918742\n",
      "Ending epoch 32: loss 0.0723104\n",
      "Ending epoch 33: loss 0.0822516\n",
      "Ending epoch 34: loss 0.100021\n",
      "Ending epoch 35: loss 0.0974356\n",
      "Ending epoch 36: loss 0.101042\n",
      "Ending epoch 37: loss 0.112588\n",
      "Ending epoch 38: loss 0.104181\n",
      "Ending epoch 39: loss 0.11273\n",
      "Ending epoch 40: loss 0.0902463\n",
      "Ending epoch 41: loss 0.105125\n",
      "Ending epoch 42: loss 0.0937799\n",
      "Ending epoch 43: loss 0.103118\n",
      "Ending epoch 44: loss 0.0860525\n",
      "Ending epoch 45: loss 0.0876645\n",
      "Ending epoch 46: loss 0.0738041\n",
      "Ending epoch 47: loss 0.133227\n",
      "Ending epoch 48: loss 0.0888068\n",
      "Ending epoch 49: loss 0.0935307\n",
      "Ending epoch 50: loss 0.10545\n",
      "Ending epoch 51: loss 0.0874959\n",
      "Ending epoch 52: loss 0.116784\n",
      "Ending epoch 53: loss 0.0829375\n",
      "Ending epoch 54: loss 0.101335\n",
      "Ending epoch 55: loss 0.0682644\n",
      "Ending epoch 56: loss 0.0916208\n",
      "Ending epoch 57: loss 0.0784857\n",
      "Ending epoch 58: loss 0.0728797\n",
      "Ending epoch 59: loss 0.0744888\n",
      "Ending epoch 60: loss 0.0814182\n",
      "Ending epoch 61: loss 0.0802248\n",
      "Ending epoch 62: loss 0.0666611\n",
      "Ending epoch 63: loss 0.0795349\n",
      "Ending epoch 64: loss 0.0811969\n",
      "Ending epoch 65: loss 0.0787122\n",
      "Ending epoch 66: loss 0.0637409\n",
      "Ending epoch 67: loss 0.0872213\n",
      "Ending epoch 68: loss 0.0790517\n",
      "Ending epoch 69: loss 0.0717284\n",
      "Ending epoch 70: loss 0.0824212\n",
      "Ending epoch 71: loss 0.0799382\n",
      "Ending epoch 72: loss 0.0726885\n",
      "Ending epoch 73: loss 0.0590534\n",
      "Ending epoch 74: loss 0.0795558\n",
      "Ending epoch 75: loss 0.0778019\n",
      "Ending epoch 76: loss 0.0653038\n",
      "Ending epoch 77: loss 0.0796357\n",
      "Ending epoch 78: loss 0.0755784\n",
      "Ending epoch 79: loss 0.0580019\n",
      "Ending epoch 80: loss 0.0946012\n",
      "Ending epoch 81: loss 0.0631996\n",
      "Ending epoch 82: loss 0.0675086\n",
      "Ending epoch 83: loss 0.0795646\n",
      "Ending epoch 84: loss 0.0630008\n",
      "Ending epoch 85: loss 0.0650923\n",
      "Ending epoch 86: loss 0.0655372\n",
      "Ending epoch 87: loss 0.0754524\n",
      "Ending epoch 88: loss 0.0802408\n",
      "Ending epoch 89: loss 0.0767351\n",
      "Ending epoch 90: loss 0.0735302\n",
      "Ending epoch 91: loss 0.0626189\n",
      "Ending epoch 92: loss 0.0798353\n",
      "Ending epoch 93: loss 0.0639912\n",
      "Ending epoch 94: loss 0.0664855\n",
      "Ending epoch 95: loss 0.0731532\n",
      "Ending epoch 96: loss 0.0590889\n",
      "Ending epoch 97: loss 0.0582061\n",
      "Ending epoch 98: loss 0.0725357\n",
      "Ending epoch 99: loss 0.065751\n",
      "Ending epoch 100: loss 0.057666\n",
      "Ending epoch 101: loss 0.0544071\n",
      "Ending epoch 102: loss 0.0740797\n",
      "Ending epoch 103: loss 0.0618974\n",
      "Ending epoch 104: loss 0.064965\n",
      "Ending epoch 105: loss 0.0706651\n",
      "Ending epoch 106: loss 0.0716842\n",
      "Ending epoch 107: loss 0.0523911\n",
      "Ending epoch 108: loss 0.0609502\n",
      "Ending epoch 109: loss 0.0669478\n",
      "Ending epoch 110: loss 0.0549359\n",
      "Ending epoch 111: loss 0.0577634\n",
      "Ending epoch 112: loss 0.0607099\n",
      "Ending epoch 113: loss 0.0588547\n",
      "Ending epoch 114: loss 0.0721563\n",
      "Ending epoch 115: loss 0.0524846\n",
      "Ending epoch 116: loss 0.0678348\n",
      "Ending epoch 117: loss 0.0668975\n",
      "Ending epoch 118: loss 0.0793408\n",
      "Ending epoch 119: loss 0.0549186\n",
      "Ending epoch 120: loss 0.0501466\n",
      "Ending epoch 121: loss 0.0535097\n",
      "Ending epoch 122: loss 0.0658579\n",
      "Ending epoch 123: loss 0.0435706\n",
      "Ending epoch 124: loss 0.0615748\n",
      "Ending epoch 125: loss 0.0544363\n",
      "Ending epoch 126: loss 0.0774091\n",
      "Ending epoch 127: loss 0.0629022\n",
      "Ending epoch 128: loss 0.0437586\n",
      "Ending epoch 129: loss 0.0677193\n",
      "Ending epoch 130: loss 0.0580079\n",
      "Ending epoch 131: loss 0.0558334\n",
      "Ending epoch 132: loss 0.0557845\n",
      "Ending epoch 133: loss 0.0441915\n",
      "Ending epoch 134: loss 0.0478927\n",
      "Ending epoch 135: loss 0.0625625\n",
      "Ending epoch 136: loss 0.0556347\n",
      "Ending epoch 137: loss 0.0685508\n",
      "Ending epoch 138: loss 0.0451058\n",
      "Ending epoch 139: loss 0.0724689\n",
      "Ending epoch 140: loss 0.0470262\n",
      "Ending epoch 141: loss 0.0641086\n",
      "Ending epoch 142: loss 0.057916\n",
      "Ending epoch 143: loss 0.0500363\n",
      "Ending epoch 144: loss 0.0642885\n",
      "Ending epoch 145: loss 0.0630388\n",
      "Ending epoch 146: loss 0.0558796\n",
      "Ending epoch 147: loss 0.0509072\n",
      "Ending epoch 148: loss 0.0582682\n",
      "Ending epoch 149: loss 0.0427782\n",
      "Ending epoch 150: loss 0.0503242\n",
      "Ending epoch 151: loss 0.0522589\n",
      "Ending epoch 152: loss 0.0521692\n",
      "Ending epoch 153: loss 0.0441091\n",
      "Ending epoch 154: loss 0.067415\n",
      "Ending epoch 155: loss 0.0405745\n",
      "Ending epoch 156: loss 0.0504156\n",
      "Ending epoch 157: loss 0.0538207\n",
      "Ending epoch 158: loss 0.0586896\n",
      "Ending epoch 159: loss 0.05268\n",
      "Ending epoch 160: loss 0.0451935\n",
      "Ending epoch 161: loss 0.0444388\n",
      "Ending epoch 162: loss 0.0593681\n",
      "Ending epoch 163: loss 0.0451775\n",
      "Ending epoch 164: loss 0.0592195\n",
      "Ending epoch 165: loss 0.0533395\n",
      "Ending epoch 166: loss 0.046089\n",
      "Ending epoch 167: loss 0.0502316\n",
      "Ending epoch 168: loss 0.0463581\n",
      "Ending epoch 169: loss 0.0540724\n",
      "Ending epoch 170: loss 0.0472643\n",
      "Ending epoch 171: loss 0.0508425\n",
      "Ending epoch 172: loss 0.0465651\n",
      "Ending epoch 173: loss 0.0490528\n",
      "Ending epoch 174: loss 0.0629471\n",
      "Ending epoch 175: loss 0.0524813\n",
      "Ending epoch 176: loss 0.049813\n",
      "Ending epoch 177: loss 0.054631\n",
      "Ending epoch 178: loss 0.0491401\n",
      "Ending epoch 179: loss 0.0469804\n",
      "Ending epoch 180: loss 0.0518717\n",
      "Ending epoch 181: loss 0.0617409\n",
      "Ending epoch 182: loss 0.0543283\n",
      "Ending epoch 183: loss 0.0375172\n",
      "Ending epoch 184: loss 0.0641729\n",
      "Ending epoch 185: loss 0.0511156\n",
      "Ending epoch 186: loss 0.0421842\n",
      "Ending epoch 187: loss 0.069805\n",
      "Ending epoch 188: loss 0.0511631\n",
      "Ending epoch 189: loss 0.0401424\n",
      "Ending epoch 190: loss 0.0610961\n",
      "Ending epoch 191: loss 0.0433505\n",
      "Ending epoch 192: loss 0.0419145\n",
      "Ending epoch 193: loss 0.0374315\n",
      "Ending epoch 194: loss 0.0488048\n",
      "Ending epoch 195: loss 0.048819\n",
      "Ending epoch 196: loss 0.0559972\n",
      "Ending epoch 197: loss 0.042853\n",
      "Ending epoch 198: loss 0.0627898\n",
      "Ending epoch 199: loss 0.0403677\n",
      "Ending epoch 200: loss 0.0674714\n",
      "Ending epoch 201: loss 0.0469424\n",
      "Ending epoch 202: loss 0.0511375\n",
      "Ending epoch 203: loss 0.0487951\n",
      "Ending epoch 204: loss 0.0468914\n",
      "Ending epoch 205: loss 0.0626945\n",
      "Ending epoch 206: loss 0.0391938\n",
      "Ending epoch 207: loss 0.0508233\n",
      "Ending epoch 208: loss 0.0572381\n",
      "Ending epoch 209: loss 0.0363394\n",
      "Ending epoch 210: loss 0.0499372\n",
      "Ending epoch 211: loss 0.0465566\n",
      "Ending epoch 212: loss 0.0496639\n",
      "Ending epoch 213: loss 0.0356882\n",
      "Ending epoch 214: loss 0.0539118\n",
      "Ending epoch 215: loss 0.0530368\n",
      "Ending epoch 216: loss 0.0425109\n",
      "Ending epoch 217: loss 0.0520021\n",
      "Ending epoch 218: loss 0.0508394\n",
      "Ending epoch 219: loss 0.0382583\n",
      "Ending epoch 220: loss 0.0535062\n",
      "Ending epoch 221: loss 0.0458128\n",
      "Ending epoch 222: loss 0.0473687\n",
      "Ending epoch 223: loss 0.0517884\n",
      "Ending epoch 224: loss 0.0575506\n",
      "Ending epoch 225: loss 0.0530157\n",
      "Ending epoch 226: loss 0.0547081\n",
      "Ending epoch 227: loss 0.0425732\n",
      "Ending epoch 228: loss 0.029361\n",
      "Ending epoch 229: loss 0.0413117\n",
      "Ending epoch 230: loss 0.0391811\n",
      "Ending epoch 231: loss 0.0522594\n",
      "Ending epoch 232: loss 0.0551553\n",
      "Ending epoch 233: loss 0.0403669\n",
      "Ending epoch 234: loss 0.0501768\n",
      "Ending epoch 235: loss 0.04351\n",
      "Ending epoch 236: loss 0.0446634\n",
      "Ending epoch 237: loss 0.0578532\n",
      "Ending epoch 238: loss 0.0418911\n",
      "Ending epoch 239: loss 0.0427388\n",
      "Ending epoch 240: loss 0.0712264\n",
      "Ending epoch 241: loss 0.0427649\n",
      "Ending epoch 242: loss 0.0497545\n",
      "Ending epoch 243: loss 0.0424695\n",
      "Ending epoch 244: loss 0.0505888\n",
      "Ending epoch 245: loss 0.0628732\n",
      "Ending epoch 246: loss 0.049671\n",
      "Ending epoch 247: loss 0.0495534\n",
      "Ending epoch 248: loss 0.0469388\n",
      "Ending epoch 249: loss 0.0293528\n",
      "Ending epoch 250: loss 0.0611312\n",
      "Ending epoch 251: loss 0.0425079\n",
      "Ending epoch 252: loss 0.0407291\n",
      "Ending epoch 253: loss 0.0337274\n",
      "Ending epoch 254: loss 0.046293\n",
      "Ending epoch 255: loss 0.0322964\n",
      "Ending epoch 256: loss 0.0364391\n",
      "Ending epoch 257: loss 0.0425228\n",
      "Ending epoch 258: loss 0.0431939\n",
      "Ending epoch 259: loss 0.0519949\n",
      "Ending epoch 260: loss 0.0386741\n",
      "Ending epoch 261: loss 0.0307355\n",
      "Ending epoch 262: loss 0.0378307\n",
      "Ending epoch 263: loss 0.0336914\n",
      "Ending epoch 264: loss 0.044564\n",
      "Ending epoch 265: loss 0.0424664\n",
      "Ending epoch 266: loss 0.0455996\n",
      "Ending epoch 267: loss 0.0567034\n",
      "Ending epoch 268: loss 0.0474693\n",
      "Ending epoch 269: loss 0.0472281\n",
      "Ending epoch 270: loss 0.0515046\n",
      "Ending epoch 271: loss 0.0315424\n",
      "Ending epoch 272: loss 0.0441473\n",
      "Ending epoch 273: loss 0.0407732\n",
      "Ending epoch 274: loss 0.0430207\n",
      "Ending epoch 275: loss 0.0408071\n",
      "Ending epoch 276: loss 0.0443605\n",
      "Ending epoch 277: loss 0.0461956\n",
      "Ending epoch 278: loss 0.047264\n",
      "Ending epoch 279: loss 0.0458704\n",
      "Ending epoch 280: loss 0.036958\n",
      "Ending epoch 281: loss 0.0459497\n",
      "Ending epoch 282: loss 0.0439043\n",
      "Ending epoch 283: loss 0.0441474\n",
      "Ending epoch 284: loss 0.0517466\n",
      "Ending epoch 285: loss 0.0392454\n",
      "Ending epoch 286: loss 0.042343\n",
      "Ending epoch 287: loss 0.0373974\n",
      "Ending epoch 288: loss 0.0580203\n",
      "Ending epoch 289: loss 0.0403679\n",
      "Ending epoch 290: loss 0.0321332\n",
      "Ending epoch 291: loss 0.0405158\n",
      "Ending epoch 292: loss 0.0381065\n",
      "Ending epoch 293: loss 0.0439309\n",
      "Ending epoch 294: loss 0.0472285\n",
      "Ending epoch 295: loss 0.0385692\n",
      "Ending epoch 296: loss 0.0390562\n",
      "Ending epoch 297: loss 0.0600442\n",
      "Ending epoch 298: loss 0.0512265\n",
      "Ending epoch 299: loss 0.0389966\n",
      "Ending epoch 300: loss 0.0376742\n",
      "Ending epoch 301: loss 0.0436159\n",
      "Ending epoch 302: loss 0.0407777\n",
      "Ending epoch 303: loss 0.04195\n",
      "Ending epoch 304: loss 0.0242779\n",
      "Ending epoch 305: loss 0.0428136\n",
      "Ending epoch 306: loss 0.042667\n",
      "Ending epoch 307: loss 0.0378565\n",
      "Ending epoch 308: loss 0.0436295\n",
      "Ending epoch 309: loss 0.0399232\n",
      "Ending epoch 310: loss 0.0405762\n",
      "Ending epoch 311: loss 0.0452301\n",
      "Ending epoch 312: loss 0.0454086\n",
      "Ending epoch 313: loss 0.0402443\n",
      "Ending epoch 314: loss 0.0415739\n",
      "Ending epoch 315: loss 0.0461686\n",
      "Ending epoch 316: loss 0.0457111\n",
      "Ending epoch 317: loss 0.0401514\n",
      "Ending epoch 318: loss 0.0519758\n",
      "Ending epoch 319: loss 0.0457853\n",
      "Ending epoch 320: loss 0.0448858\n",
      "Ending epoch 321: loss 0.0507817\n",
      "Ending epoch 322: loss 0.0457351\n",
      "Ending epoch 323: loss 0.0343028\n",
      "Ending epoch 324: loss 0.035702\n",
      "Ending epoch 325: loss 0.0387314\n",
      "Ending epoch 326: loss 0.0337735\n",
      "Ending epoch 327: loss 0.0480968\n",
      "Ending epoch 328: loss 0.0361261\n",
      "Ending epoch 329: loss 0.046954\n",
      "Ending epoch 330: loss 0.0437147\n",
      "Ending epoch 331: loss 0.0553833\n",
      "Ending epoch 332: loss 0.0354942\n",
      "Ending epoch 333: loss 0.0438057\n",
      "Ending epoch 334: loss 0.0417166\n",
      "Ending epoch 335: loss 0.0326823\n",
      "Ending epoch 336: loss 0.0390581\n",
      "Ending epoch 337: loss 0.0455395\n",
      "Ending epoch 338: loss 0.0380127\n",
      "Ending epoch 339: loss 0.0424356\n",
      "Ending epoch 340: loss 0.0472096\n",
      "Ending epoch 341: loss 0.047436\n",
      "Ending epoch 342: loss 0.0272384\n",
      "Ending epoch 343: loss 0.0565934\n",
      "Ending epoch 344: loss 0.0446314\n",
      "Ending epoch 345: loss 0.0501399\n",
      "Ending epoch 346: loss 0.0474567\n",
      "Ending epoch 347: loss 0.035419\n",
      "Ending epoch 348: loss 0.0480742\n",
      "Ending epoch 349: loss 0.0443761\n",
      "Ending epoch 350: loss 0.0398912\n",
      "Ending epoch 351: loss 0.0388581\n",
      "Ending epoch 352: loss 0.0340893\n",
      "Ending epoch 353: loss 0.0418188\n",
      "Ending epoch 354: loss 0.042938\n",
      "Ending epoch 355: loss 0.0342737\n",
      "Ending epoch 356: loss 0.0341213\n",
      "Ending epoch 357: loss 0.0339729\n",
      "Ending epoch 358: loss 0.0446079\n",
      "Ending epoch 359: loss 0.0307268\n",
      "Ending epoch 360: loss 0.0321965\n",
      "Ending epoch 361: loss 0.0417265\n",
      "Ending epoch 362: loss 0.0443299\n",
      "Ending epoch 363: loss 0.049194\n",
      "Ending epoch 364: loss 0.0319856\n",
      "Ending epoch 365: loss 0.0359175\n",
      "Ending epoch 366: loss 0.0319028\n",
      "Ending epoch 367: loss 0.0430311\n",
      "Ending epoch 368: loss 0.0346973\n",
      "Ending epoch 369: loss 0.0371248\n",
      "Ending epoch 370: loss 0.0314529\n",
      "Ending epoch 371: loss 0.040802\n",
      "Ending epoch 372: loss 0.0373917\n",
      "Ending epoch 373: loss 0.0465135\n",
      "Ending epoch 374: loss 0.0376911\n",
      "Ending epoch 375: loss 0.0388708\n",
      "Ending epoch 376: loss 0.0324806\n",
      "Ending epoch 377: loss 0.0374213\n",
      "Ending epoch 378: loss 0.0415828\n",
      "Ending epoch 379: loss 0.0304244\n",
      "Ending epoch 380: loss 0.0445521\n",
      "Ending epoch 381: loss 0.0408772\n",
      "Ending epoch 382: loss 0.0346739\n",
      "Ending epoch 383: loss 0.0362397\n",
      "Ending epoch 384: loss 0.0331844\n",
      "Ending epoch 385: loss 0.0421657\n",
      "Ending epoch 386: loss 0.0395771\n",
      "Ending epoch 387: loss 0.0371866\n",
      "Ending epoch 388: loss 0.0468161\n",
      "Ending epoch 389: loss 0.0308895\n",
      "Ending epoch 390: loss 0.0320644\n",
      "Ending epoch 391: loss 0.0288615\n",
      "Ending epoch 392: loss 0.0434049\n",
      "Ending epoch 393: loss 0.0396434\n",
      "Ending epoch 394: loss 0.042066\n",
      "Ending epoch 395: loss 0.050276\n",
      "Ending epoch 396: loss 0.0397055\n",
      "Ending epoch 397: loss 0.0255819\n",
      "Ending epoch 398: loss 0.0434996\n",
      "Ending epoch 399: loss 0.038699\n",
      "Ending epoch 400: loss 0.0367493\n",
      "Ending epoch 401: loss 0.0343459\n",
      "Ending epoch 402: loss 0.0363628\n",
      "Ending epoch 403: loss 0.0311561\n",
      "Ending epoch 404: loss 0.0348243\n",
      "Ending epoch 405: loss 0.0418348\n",
      "Ending epoch 406: loss 0.0314346\n",
      "Ending epoch 407: loss 0.0370218\n",
      "Ending epoch 408: loss 0.0314029\n",
      "Ending epoch 409: loss 0.0347567\n",
      "Ending epoch 410: loss 0.0273456\n",
      "Ending epoch 411: loss 0.0349218\n",
      "Ending epoch 412: loss 0.0326214\n",
      "Ending epoch 413: loss 0.0336876\n",
      "Ending epoch 414: loss 0.0379952\n",
      "Ending epoch 415: loss 0.0378841\n",
      "Ending epoch 416: loss 0.0400854\n",
      "Ending epoch 417: loss 0.028951\n",
      "Ending epoch 418: loss 0.0309992\n",
      "Ending epoch 419: loss 0.0338506\n",
      "Ending epoch 420: loss 0.034869\n",
      "Ending epoch 421: loss 0.0327737\n",
      "Ending epoch 422: loss 0.0388356\n",
      "Ending epoch 423: loss 0.0391592\n",
      "Ending epoch 424: loss 0.0415139\n",
      "Ending epoch 425: loss 0.0284981\n",
      "Ending epoch 426: loss 0.0392804\n",
      "Ending epoch 427: loss 0.0425387\n",
      "Ending epoch 428: loss 0.0424002\n",
      "Ending epoch 429: loss 0.038599\n",
      "Ending epoch 430: loss 0.0502345\n",
      "Ending epoch 431: loss 0.0358781\n",
      "Ending epoch 432: loss 0.034272\n",
      "Ending epoch 433: loss 0.0319867\n",
      "Ending epoch 434: loss 0.0232934\n",
      "Ending epoch 435: loss 0.0369351\n",
      "Ending epoch 436: loss 0.0427047\n",
      "Ending epoch 437: loss 0.0449613\n",
      "Ending epoch 438: loss 0.0354401\n",
      "Ending epoch 439: loss 0.0381343\n",
      "Ending epoch 440: loss 0.0401274\n",
      "Ending epoch 441: loss 0.0326003\n",
      "Ending epoch 442: loss 0.032783\n",
      "Ending epoch 443: loss 0.0411202\n",
      "Ending epoch 444: loss 0.0348884\n",
      "Ending epoch 445: loss 0.0349478\n",
      "Ending epoch 446: loss 0.0426275\n",
      "Ending epoch 447: loss 0.0522781\n",
      "Ending epoch 448: loss 0.0348916\n",
      "Ending epoch 449: loss 0.0343329\n",
      "Ending epoch 450: loss 0.0287926\n",
      "Ending epoch 451: loss 0.0337836\n",
      "Ending epoch 452: loss 0.030522\n",
      "Ending epoch 453: loss 0.0285175\n",
      "Ending epoch 454: loss 0.0359165\n",
      "Ending epoch 455: loss 0.0418899\n",
      "Ending epoch 456: loss 0.0343214\n",
      "Ending epoch 457: loss 0.0393178\n",
      "Ending epoch 458: loss 0.0301724\n",
      "Ending epoch 459: loss 0.0446225\n",
      "Ending epoch 460: loss 0.0337339\n",
      "Ending epoch 461: loss 0.0345822\n",
      "Ending epoch 462: loss 0.044559\n",
      "Ending epoch 463: loss 0.0412122\n",
      "Ending epoch 464: loss 0.0313643\n",
      "Ending epoch 465: loss 0.0359012\n",
      "Ending epoch 466: loss 0.0323237\n",
      "Ending epoch 467: loss 0.0335873\n",
      "Ending epoch 468: loss 0.0364484\n",
      "Ending epoch 469: loss 0.039079\n",
      "Ending epoch 470: loss 0.0320906\n",
      "Ending epoch 471: loss 0.0309767\n",
      "Ending epoch 472: loss 0.0307608\n",
      "Ending epoch 473: loss 0.0315386\n",
      "Ending epoch 474: loss 0.0362888\n",
      "Ending epoch 475: loss 0.0432131\n",
      "Ending epoch 476: loss 0.0402122\n",
      "Ending epoch 477: loss 0.0303272\n",
      "Ending epoch 478: loss 0.0357563\n",
      "Ending epoch 479: loss 0.0379027\n",
      "Ending epoch 480: loss 0.0347763\n",
      "Ending epoch 481: loss 0.0440127\n",
      "Ending epoch 482: loss 0.0308795\n",
      "Ending epoch 483: loss 0.032466\n",
      "Ending epoch 484: loss 0.0367999\n",
      "Ending epoch 485: loss 0.0363477\n",
      "Ending epoch 486: loss 0.0329861\n",
      "Ending epoch 487: loss 0.0335839\n",
      "Ending epoch 488: loss 0.0395588\n",
      "Ending epoch 489: loss 0.0345057\n",
      "Ending epoch 490: loss 0.0323201\n",
      "Ending epoch 491: loss 0.026109\n",
      "Ending epoch 492: loss 0.0361516\n",
      "Ending epoch 493: loss 0.029927\n",
      "Ending epoch 494: loss 0.0372034\n",
      "Ending epoch 495: loss 0.03892\n",
      "Ending epoch 496: loss 0.034457\n",
      "Ending epoch 497: loss 0.0367666\n",
      "Ending epoch 498: loss 0.0350301\n",
      "Ending epoch 499: loss 0.0359984\n",
      "Model 6/8, Metric mean_absolute_error, Validation set 5: 30.073604\n",
      "\tbest_validation_score so far: 21.384058\n",
      "Fitting model 7/8\n",
      "hyperparameters: {u'optimizer': u'momentum', u'layer_sizes': [1000, 1000, 250], u'data_shape': (23,), u'learning_rate': 0.0001, u'batch_size': 100, u'penalty': 0.0, u'bias_init_consts': [1.0, 1.0, 1.0], u'weight_init_stddevs': [0.077459666924148338, 0.077459666924148338, 0.077459666924148338], u'num_regression_tasks': 1, u'dropouts': [0.1, 0.1, 0.1], u'nb_epoch': 500, u'momentum': 0.9}\n",
      "Training for 500 epochs\n",
      "Ending epoch 0: loss 7.96943\n",
      "Ending epoch 1: loss 2.33424\n",
      "Ending epoch 2: loss 1.62594\n",
      "Ending epoch 3: loss 1.25873\n",
      "Ending epoch 4: loss 0.635865\n",
      "Ending epoch 5: loss 0.51009\n",
      "Ending epoch 6: loss 0.465296\n",
      "Ending epoch 7: loss 0.311792\n",
      "Ending epoch 8: loss 0.450703\n",
      "Ending epoch 9: loss 0.274049\n",
      "Ending epoch 10: loss 0.401229\n",
      "Ending epoch 11: loss 0.295929\n",
      "Ending epoch 12: loss 0.221973\n",
      "Ending epoch 13: loss 0.225822\n",
      "Ending epoch 14: loss 0.209106\n",
      "Ending epoch 15: loss 0.228702\n",
      "Ending epoch 16: loss 0.18182\n",
      "Ending epoch 17: loss 0.224088\n",
      "Ending epoch 18: loss 0.183244\n",
      "Ending epoch 19: loss 0.177944\n",
      "Ending epoch 20: loss 0.263887\n",
      "Ending epoch 21: loss 0.191294\n",
      "Ending epoch 22: loss 0.151415\n",
      "Ending epoch 23: loss 0.168311\n",
      "Ending epoch 24: loss 0.148423\n",
      "Ending epoch 25: loss 0.164549\n",
      "Ending epoch 26: loss 0.153591\n",
      "Ending epoch 27: loss 0.113871\n",
      "Ending epoch 28: loss 0.173397\n",
      "Ending epoch 29: loss 0.147176\n",
      "Ending epoch 30: loss 0.152379\n",
      "Ending epoch 31: loss 0.139299\n",
      "Ending epoch 32: loss 0.111493\n",
      "Ending epoch 33: loss 0.128719\n",
      "Ending epoch 34: loss 0.120155\n",
      "Ending epoch 35: loss 0.120689\n",
      "Ending epoch 36: loss 0.0896214\n",
      "Ending epoch 37: loss 0.108619\n",
      "Ending epoch 38: loss 0.135038\n",
      "Ending epoch 39: loss 0.114631\n",
      "Ending epoch 40: loss 0.0993405\n",
      "Ending epoch 41: loss 0.119835\n",
      "Ending epoch 42: loss 0.090796\n",
      "Ending epoch 43: loss 0.0917347\n",
      "Ending epoch 44: loss 0.0995936\n",
      "Ending epoch 45: loss 0.0774452\n",
      "Ending epoch 46: loss 0.101425\n",
      "Ending epoch 47: loss 0.0858455\n",
      "Ending epoch 48: loss 0.0933815\n",
      "Ending epoch 49: loss 0.0851111\n",
      "Ending epoch 50: loss 0.0935375\n",
      "Ending epoch 51: loss 0.0745788\n",
      "Ending epoch 52: loss 0.0791467\n",
      "Ending epoch 53: loss 0.0613031\n",
      "Ending epoch 54: loss 0.0801379\n",
      "Ending epoch 55: loss 0.101958\n",
      "Ending epoch 56: loss 0.0837179\n",
      "Ending epoch 57: loss 0.05856\n",
      "Ending epoch 58: loss 0.0781242\n",
      "Ending epoch 59: loss 0.0715251\n",
      "Ending epoch 60: loss 0.0823701\n",
      "Ending epoch 61: loss 0.0715436\n",
      "Ending epoch 62: loss 0.07382\n",
      "Ending epoch 63: loss 0.0918806\n",
      "Ending epoch 64: loss 0.076471\n",
      "Ending epoch 65: loss 0.0882372\n",
      "Ending epoch 66: loss 0.0770252\n",
      "Ending epoch 67: loss 0.0512126\n",
      "Ending epoch 68: loss 0.090889\n",
      "Ending epoch 69: loss 0.0767383\n",
      "Ending epoch 70: loss 0.0664179\n",
      "Ending epoch 71: loss 0.0633909\n",
      "Ending epoch 72: loss 0.049921\n",
      "Ending epoch 73: loss 0.0644683\n",
      "Ending epoch 74: loss 0.0690164\n",
      "Ending epoch 75: loss 0.0964666\n",
      "Ending epoch 76: loss 0.06155\n",
      "Ending epoch 77: loss 0.0529815\n",
      "Ending epoch 78: loss 0.0763724\n",
      "Ending epoch 79: loss 0.0785306\n",
      "Ending epoch 80: loss 0.0814504\n",
      "Ending epoch 81: loss 0.0726364\n",
      "Ending epoch 82: loss 0.0534327\n",
      "Ending epoch 83: loss 0.065288\n",
      "Ending epoch 84: loss 0.0678028\n",
      "Ending epoch 85: loss 0.0749495\n",
      "Ending epoch 86: loss 0.0712155\n",
      "Ending epoch 87: loss 0.0651895\n",
      "Ending epoch 88: loss 0.0478368\n",
      "Ending epoch 89: loss 0.0621132\n",
      "Ending epoch 90: loss 0.0567308\n",
      "Ending epoch 91: loss 0.105226\n",
      "Ending epoch 92: loss 0.0478261\n",
      "Ending epoch 93: loss 0.0480978\n",
      "Ending epoch 94: loss 0.0443717\n",
      "Ending epoch 95: loss 0.0621292\n",
      "Ending epoch 96: loss 0.0598629\n",
      "Ending epoch 97: loss 0.0507533\n",
      "Ending epoch 98: loss 0.0608878\n",
      "Ending epoch 99: loss 0.0513108\n",
      "Ending epoch 100: loss 0.0668129\n",
      "Ending epoch 101: loss 0.0507252\n",
      "Ending epoch 102: loss 0.060395\n",
      "Ending epoch 103: loss 0.0576342\n",
      "Ending epoch 104: loss 0.0430441\n",
      "Ending epoch 105: loss 0.0464649\n",
      "Ending epoch 106: loss 0.0473342\n",
      "Ending epoch 107: loss 0.0526725\n",
      "Ending epoch 108: loss 0.0596936\n",
      "Ending epoch 109: loss 0.0502932\n",
      "Ending epoch 110: loss 0.0464431\n",
      "Ending epoch 111: loss 0.0555547\n",
      "Ending epoch 112: loss 0.0595381\n",
      "Ending epoch 113: loss 0.0507512\n",
      "Ending epoch 114: loss 0.0432185\n",
      "Ending epoch 115: loss 0.0450675\n",
      "Ending epoch 116: loss 0.0482928\n",
      "Ending epoch 117: loss 0.0562101\n",
      "Ending epoch 118: loss 0.0556389\n",
      "Ending epoch 119: loss 0.0631651\n",
      "Ending epoch 120: loss 0.0555184\n",
      "Ending epoch 121: loss 0.0603376\n",
      "Ending epoch 122: loss 0.0466054\n",
      "Ending epoch 123: loss 0.0623418\n",
      "Ending epoch 124: loss 0.0467854\n",
      "Ending epoch 125: loss 0.0481252\n",
      "Ending epoch 126: loss 0.0506528\n",
      "Ending epoch 127: loss 0.0495301\n",
      "Ending epoch 128: loss 0.0436853\n",
      "Ending epoch 129: loss 0.0589102\n",
      "Ending epoch 130: loss 0.0563289\n",
      "Ending epoch 131: loss 0.0400624\n",
      "Ending epoch 132: loss 0.0434956\n",
      "Ending epoch 133: loss 0.0537153\n",
      "Ending epoch 134: loss 0.0473239\n",
      "Ending epoch 135: loss 0.0617271\n",
      "Ending epoch 136: loss 0.042506\n",
      "Ending epoch 137: loss 0.0408287\n",
      "Ending epoch 138: loss 0.0419386\n",
      "Ending epoch 139: loss 0.0493309\n",
      "Ending epoch 140: loss 0.0413621\n",
      "Ending epoch 141: loss 0.0322251\n",
      "Ending epoch 142: loss 0.0529828\n",
      "Ending epoch 143: loss 0.0559691\n",
      "Ending epoch 144: loss 0.0413088\n",
      "Ending epoch 145: loss 0.0474438\n",
      "Ending epoch 146: loss 0.034254\n",
      "Ending epoch 147: loss 0.047523\n",
      "Ending epoch 148: loss 0.0574742\n",
      "Ending epoch 149: loss 0.0332087\n",
      "Ending epoch 150: loss 0.0405776\n",
      "Ending epoch 151: loss 0.0373128\n",
      "Ending epoch 152: loss 0.0418044\n",
      "Ending epoch 153: loss 0.0429019\n",
      "Ending epoch 154: loss 0.0499826\n",
      "Ending epoch 155: loss 0.0404431\n",
      "Ending epoch 156: loss 0.044924\n",
      "Ending epoch 157: loss 0.0455855\n",
      "Ending epoch 158: loss 0.0460685\n",
      "Ending epoch 159: loss 0.0454395\n",
      "Ending epoch 160: loss 0.0511154\n",
      "Ending epoch 161: loss 0.0474774\n",
      "Ending epoch 162: loss 0.0514905\n",
      "Ending epoch 163: loss 0.0407164\n",
      "Ending epoch 164: loss 0.0412065\n",
      "Ending epoch 165: loss 0.0395168\n",
      "Ending epoch 166: loss 0.0463751\n",
      "Ending epoch 167: loss 0.0319237\n",
      "Ending epoch 168: loss 0.0504747\n",
      "Ending epoch 169: loss 0.0428749\n",
      "Ending epoch 170: loss 0.04501\n",
      "Ending epoch 171: loss 0.0480458\n",
      "Ending epoch 172: loss 0.0379541\n",
      "Ending epoch 173: loss 0.0393304\n",
      "Ending epoch 174: loss 0.0505893\n",
      "Ending epoch 175: loss 0.0422022\n",
      "Ending epoch 176: loss 0.0395686\n",
      "Ending epoch 177: loss 0.0484156\n",
      "Ending epoch 178: loss 0.0408734\n",
      "Ending epoch 179: loss 0.0388093\n",
      "Ending epoch 180: loss 0.0428231\n",
      "Ending epoch 181: loss 0.0397061\n",
      "Ending epoch 182: loss 0.0427631\n",
      "Ending epoch 183: loss 0.0518467\n",
      "Ending epoch 184: loss 0.0429009\n",
      "Ending epoch 185: loss 0.0404384\n",
      "Ending epoch 186: loss 0.0393978\n",
      "Ending epoch 187: loss 0.0442509\n",
      "Ending epoch 188: loss 0.0440097\n",
      "Ending epoch 189: loss 0.031232\n",
      "Ending epoch 190: loss 0.034711\n",
      "Ending epoch 191: loss 0.0343488\n",
      "Ending epoch 192: loss 0.0362278\n",
      "Ending epoch 193: loss 0.0466211\n",
      "Ending epoch 194: loss 0.0483737\n",
      "Ending epoch 195: loss 0.0342057\n",
      "Ending epoch 196: loss 0.0411216\n",
      "Ending epoch 197: loss 0.0440121\n",
      "Ending epoch 198: loss 0.0429076\n",
      "Ending epoch 199: loss 0.0470169\n",
      "Ending epoch 200: loss 0.0361247\n",
      "Ending epoch 201: loss 0.0443553\n",
      "Ending epoch 202: loss 0.0342416\n",
      "Ending epoch 203: loss 0.038654\n",
      "Ending epoch 204: loss 0.0420584\n",
      "Ending epoch 205: loss 0.0379488\n",
      "Ending epoch 206: loss 0.0435653\n",
      "Ending epoch 207: loss 0.0424162\n",
      "Ending epoch 208: loss 0.0307155\n",
      "Ending epoch 209: loss 0.0357155\n",
      "Ending epoch 210: loss 0.038258\n",
      "Ending epoch 211: loss 0.0341611\n",
      "Ending epoch 212: loss 0.0416112\n",
      "Ending epoch 213: loss 0.046586\n",
      "Ending epoch 214: loss 0.0413618\n",
      "Ending epoch 215: loss 0.0449702\n",
      "Ending epoch 216: loss 0.038182\n",
      "Ending epoch 217: loss 0.0363635\n",
      "Ending epoch 218: loss 0.0391896\n",
      "Ending epoch 219: loss 0.0356688\n",
      "Ending epoch 220: loss 0.0446014\n",
      "Ending epoch 221: loss 0.044709\n",
      "Ending epoch 222: loss 0.03635\n",
      "Ending epoch 223: loss 0.0435327\n",
      "Ending epoch 224: loss 0.0399647\n",
      "Ending epoch 225: loss 0.0322299\n",
      "Ending epoch 226: loss 0.0371415\n",
      "Ending epoch 227: loss 0.0353504\n",
      "Ending epoch 228: loss 0.0333088\n",
      "Ending epoch 229: loss 0.0388506\n",
      "Ending epoch 230: loss 0.0341049\n",
      "Ending epoch 231: loss 0.0292536\n",
      "Ending epoch 232: loss 0.0460117\n",
      "Ending epoch 233: loss 0.0436394\n",
      "Ending epoch 234: loss 0.0397671\n",
      "Ending epoch 235: loss 0.037992\n",
      "Ending epoch 236: loss 0.0356997\n",
      "Ending epoch 237: loss 0.0289556\n",
      "Ending epoch 238: loss 0.0380159\n",
      "Ending epoch 239: loss 0.04166\n",
      "Ending epoch 240: loss 0.0364887\n",
      "Ending epoch 241: loss 0.0507072\n",
      "Ending epoch 242: loss 0.037309\n",
      "Ending epoch 243: loss 0.0431418\n",
      "Ending epoch 244: loss 0.0423342\n",
      "Ending epoch 245: loss 0.0413381\n",
      "Ending epoch 246: loss 0.0321727\n",
      "Ending epoch 247: loss 0.0371896\n",
      "Ending epoch 248: loss 0.03731\n",
      "Ending epoch 249: loss 0.044185\n",
      "Ending epoch 250: loss 0.0362307\n",
      "Ending epoch 251: loss 0.0515691\n",
      "Ending epoch 252: loss 0.0319374\n",
      "Ending epoch 253: loss 0.05683\n",
      "Ending epoch 254: loss 0.0500368\n",
      "Ending epoch 255: loss 0.0299201\n",
      "Ending epoch 256: loss 0.0370258\n",
      "Ending epoch 257: loss 0.0343091\n",
      "Ending epoch 258: loss 0.0536957\n",
      "Ending epoch 259: loss 0.0253928\n",
      "Ending epoch 260: loss 0.0320303\n",
      "Ending epoch 261: loss 0.03125\n",
      "Ending epoch 262: loss 0.0304351\n",
      "Ending epoch 263: loss 0.0437712\n",
      "Ending epoch 264: loss 0.0482025\n",
      "Ending epoch 265: loss 0.0334057\n",
      "Ending epoch 266: loss 0.033811\n",
      "Ending epoch 267: loss 0.0351665\n",
      "Ending epoch 268: loss 0.0355095\n",
      "Ending epoch 269: loss 0.0402921\n",
      "Ending epoch 270: loss 0.0360799\n",
      "Ending epoch 271: loss 0.0323486\n",
      "Ending epoch 272: loss 0.0298302\n",
      "Ending epoch 273: loss 0.0439616\n",
      "Ending epoch 274: loss 0.0290296\n",
      "Ending epoch 275: loss 0.0278021\n",
      "Ending epoch 276: loss 0.040129\n",
      "Ending epoch 277: loss 0.0397547\n",
      "Ending epoch 278: loss 0.0298243\n",
      "Ending epoch 279: loss 0.0292427\n",
      "Ending epoch 280: loss 0.0350166\n",
      "Ending epoch 281: loss 0.0253585\n",
      "Ending epoch 282: loss 0.0398614\n",
      "Ending epoch 283: loss 0.0374124\n",
      "Ending epoch 284: loss 0.0363272\n",
      "Ending epoch 285: loss 0.0447685\n",
      "Ending epoch 286: loss 0.0378648\n",
      "Ending epoch 287: loss 0.0367149\n",
      "Ending epoch 288: loss 0.0411406\n",
      "Ending epoch 289: loss 0.034902\n",
      "Ending epoch 290: loss 0.0420821\n",
      "Ending epoch 291: loss 0.0311783\n",
      "Ending epoch 292: loss 0.0307194\n",
      "Ending epoch 293: loss 0.030491\n",
      "Ending epoch 294: loss 0.0334206\n",
      "Ending epoch 295: loss 0.0365624\n",
      "Ending epoch 296: loss 0.0334272\n",
      "Ending epoch 297: loss 0.0331163\n",
      "Ending epoch 298: loss 0.0299813\n",
      "Ending epoch 299: loss 0.0362793\n",
      "Ending epoch 300: loss 0.0321184\n",
      "Ending epoch 301: loss 0.0475515\n",
      "Ending epoch 302: loss 0.0356298\n",
      "Ending epoch 303: loss 0.030327\n",
      "Ending epoch 304: loss 0.0294501\n",
      "Ending epoch 305: loss 0.0331003\n",
      "Ending epoch 306: loss 0.0309668\n",
      "Ending epoch 307: loss 0.0443114\n",
      "Ending epoch 308: loss 0.0372481\n",
      "Ending epoch 309: loss 0.0349037\n",
      "Ending epoch 310: loss 0.0415339\n",
      "Ending epoch 311: loss 0.027827\n",
      "Ending epoch 312: loss 0.0299151\n",
      "Ending epoch 313: loss 0.0320477\n",
      "Ending epoch 314: loss 0.0463816\n",
      "Ending epoch 315: loss 0.0295951\n",
      "Ending epoch 316: loss 0.0279369\n",
      "Ending epoch 317: loss 0.0279996\n",
      "Ending epoch 318: loss 0.046721\n",
      "Ending epoch 319: loss 0.0409956\n",
      "Ending epoch 320: loss 0.026935\n",
      "Ending epoch 321: loss 0.0364394\n",
      "Ending epoch 322: loss 0.0387042\n",
      "Ending epoch 323: loss 0.0402788\n",
      "Ending epoch 324: loss 0.0274097\n",
      "Ending epoch 325: loss 0.0380875\n",
      "Ending epoch 326: loss 0.0290104\n",
      "Ending epoch 327: loss 0.0378222\n",
      "Ending epoch 328: loss 0.0380619\n",
      "Ending epoch 329: loss 0.0382106\n",
      "Ending epoch 330: loss 0.0416987\n",
      "Ending epoch 331: loss 0.0379563\n",
      "Ending epoch 332: loss 0.025233\n",
      "Ending epoch 333: loss 0.0389625\n",
      "Ending epoch 334: loss 0.031235\n",
      "Ending epoch 335: loss 0.0266267\n",
      "Ending epoch 336: loss 0.0368204\n",
      "Ending epoch 337: loss 0.0286652\n",
      "Ending epoch 338: loss 0.0286549\n",
      "Ending epoch 339: loss 0.0245165\n",
      "Ending epoch 340: loss 0.0351039\n",
      "Ending epoch 341: loss 0.0330591\n",
      "Ending epoch 342: loss 0.0367612\n",
      "Ending epoch 343: loss 0.0381884\n",
      "Ending epoch 344: loss 0.0251521\n",
      "Ending epoch 345: loss 0.0317388\n",
      "Ending epoch 346: loss 0.0328853\n",
      "Ending epoch 347: loss 0.0320986\n",
      "Ending epoch 348: loss 0.0444819\n",
      "Ending epoch 349: loss 0.0254395\n",
      "Ending epoch 350: loss 0.0336301\n",
      "Ending epoch 351: loss 0.0317932\n",
      "Ending epoch 352: loss 0.0284886\n",
      "Ending epoch 353: loss 0.0293116\n",
      "Ending epoch 354: loss 0.037403\n",
      "Ending epoch 355: loss 0.0433184\n",
      "Ending epoch 356: loss 0.0284369\n",
      "Ending epoch 357: loss 0.0329206\n",
      "Ending epoch 358: loss 0.0295339\n",
      "Ending epoch 359: loss 0.0291867\n",
      "Ending epoch 360: loss 0.0290224\n",
      "Ending epoch 361: loss 0.0310741\n",
      "Ending epoch 362: loss 0.027923\n",
      "Ending epoch 363: loss 0.0353671\n",
      "Ending epoch 364: loss 0.0348576\n",
      "Ending epoch 365: loss 0.03027\n",
      "Ending epoch 366: loss 0.0321963\n",
      "Ending epoch 367: loss 0.0290631\n",
      "Ending epoch 368: loss 0.024652\n",
      "Ending epoch 369: loss 0.0330757\n",
      "Ending epoch 370: loss 0.0339981\n",
      "Ending epoch 371: loss 0.0391145\n",
      "Ending epoch 372: loss 0.0291041\n",
      "Ending epoch 373: loss 0.0287386\n",
      "Ending epoch 374: loss 0.0325477\n",
      "Ending epoch 375: loss 0.0394474\n",
      "Ending epoch 376: loss 0.0340207\n",
      "Ending epoch 377: loss 0.0341228\n",
      "Ending epoch 378: loss 0.0361878\n",
      "Ending epoch 379: loss 0.0388431\n",
      "Ending epoch 380: loss 0.0341787\n",
      "Ending epoch 381: loss 0.0279635\n",
      "Ending epoch 382: loss 0.0268195\n",
      "Ending epoch 383: loss 0.0234225\n",
      "Ending epoch 384: loss 0.029663\n",
      "Ending epoch 385: loss 0.0316579\n",
      "Ending epoch 386: loss 0.0248711\n",
      "Ending epoch 387: loss 0.0369025\n",
      "Ending epoch 388: loss 0.0424496\n",
      "Ending epoch 389: loss 0.0380647\n",
      "Ending epoch 390: loss 0.0282308\n",
      "Ending epoch 391: loss 0.0349166\n",
      "Ending epoch 392: loss 0.0362936\n",
      "Ending epoch 393: loss 0.0287997\n",
      "Ending epoch 394: loss 0.0392329\n",
      "Ending epoch 395: loss 0.0282724\n",
      "Ending epoch 396: loss 0.0319798\n",
      "Ending epoch 397: loss 0.0356919\n",
      "Ending epoch 398: loss 0.0291908\n",
      "Ending epoch 399: loss 0.0235226\n",
      "Ending epoch 400: loss 0.0246417\n",
      "Ending epoch 401: loss 0.0277605\n",
      "Ending epoch 402: loss 0.0321534\n",
      "Ending epoch 403: loss 0.0306535\n",
      "Ending epoch 404: loss 0.0289661\n",
      "Ending epoch 405: loss 0.0373401\n",
      "Ending epoch 406: loss 0.0330401\n",
      "Ending epoch 407: loss 0.035357\n",
      "Ending epoch 408: loss 0.0305134\n",
      "Ending epoch 409: loss 0.0288245\n",
      "Ending epoch 410: loss 0.037737\n",
      "Ending epoch 411: loss 0.0239062\n",
      "Ending epoch 412: loss 0.032884\n",
      "Ending epoch 413: loss 0.0301529\n",
      "Ending epoch 414: loss 0.0220433\n",
      "Ending epoch 415: loss 0.0386686\n",
      "Ending epoch 416: loss 0.0353318\n",
      "Ending epoch 417: loss 0.0354464\n",
      "Ending epoch 418: loss 0.0279651\n",
      "Ending epoch 419: loss 0.0391929\n",
      "Ending epoch 420: loss 0.0317207\n",
      "Ending epoch 421: loss 0.0207737\n",
      "Ending epoch 422: loss 0.0289218\n",
      "Ending epoch 423: loss 0.0219731\n",
      "Ending epoch 424: loss 0.0266799\n",
      "Ending epoch 425: loss 0.0308822\n",
      "Ending epoch 426: loss 0.030017\n",
      "Ending epoch 427: loss 0.0293376\n",
      "Ending epoch 428: loss 0.0304649\n",
      "Ending epoch 429: loss 0.0296118\n",
      "Ending epoch 430: loss 0.0299461\n",
      "Ending epoch 431: loss 0.0338988\n",
      "Ending epoch 432: loss 0.036462\n",
      "Ending epoch 433: loss 0.0316589\n",
      "Ending epoch 434: loss 0.0278491\n",
      "Ending epoch 435: loss 0.0271565\n",
      "Ending epoch 436: loss 0.0297913\n",
      "Ending epoch 437: loss 0.0304313\n",
      "Ending epoch 438: loss 0.0275024\n",
      "Ending epoch 439: loss 0.0300302\n",
      "Ending epoch 440: loss 0.0304896\n",
      "Ending epoch 441: loss 0.0304098\n",
      "Ending epoch 442: loss 0.0265867\n",
      "Ending epoch 443: loss 0.025899\n",
      "Ending epoch 444: loss 0.0303754\n",
      "Ending epoch 445: loss 0.0319546\n",
      "Ending epoch 446: loss 0.0308711\n",
      "Ending epoch 447: loss 0.0309468\n",
      "Ending epoch 448: loss 0.0355181\n",
      "Ending epoch 449: loss 0.0279126\n",
      "Ending epoch 450: loss 0.031046\n",
      "Ending epoch 451: loss 0.030543\n",
      "Ending epoch 452: loss 0.0228037\n",
      "Ending epoch 453: loss 0.0225525\n",
      "Ending epoch 454: loss 0.0325076\n",
      "Ending epoch 455: loss 0.0272957\n",
      "Ending epoch 456: loss 0.0229214\n",
      "Ending epoch 457: loss 0.0307591\n",
      "Ending epoch 458: loss 0.0280121\n",
      "Ending epoch 459: loss 0.0307574\n",
      "Ending epoch 460: loss 0.0317986\n",
      "Ending epoch 461: loss 0.0385496\n",
      "Ending epoch 462: loss 0.0234047\n",
      "Ending epoch 463: loss 0.0311169\n",
      "Ending epoch 464: loss 0.0210575\n",
      "Ending epoch 465: loss 0.0251295\n",
      "Ending epoch 466: loss 0.0301354\n",
      "Ending epoch 467: loss 0.0303121\n",
      "Ending epoch 468: loss 0.0233545\n",
      "Ending epoch 469: loss 0.0283064\n",
      "Ending epoch 470: loss 0.0261113\n",
      "Ending epoch 471: loss 0.0329811\n",
      "Ending epoch 472: loss 0.0318212\n",
      "Ending epoch 473: loss 0.026624\n",
      "Ending epoch 474: loss 0.0304151\n",
      "Ending epoch 475: loss 0.0209769\n",
      "Ending epoch 476: loss 0.0259017\n",
      "Ending epoch 477: loss 0.0288337\n",
      "Ending epoch 478: loss 0.0276147\n",
      "Ending epoch 479: loss 0.031643\n",
      "Ending epoch 480: loss 0.0275108\n",
      "Ending epoch 481: loss 0.0262102\n",
      "Ending epoch 482: loss 0.0250383\n",
      "Ending epoch 483: loss 0.0214992\n",
      "Ending epoch 484: loss 0.0257239\n",
      "Ending epoch 485: loss 0.0277417\n",
      "Ending epoch 486: loss 0.0237605\n",
      "Ending epoch 487: loss 0.0345376\n",
      "Ending epoch 488: loss 0.0299098\n",
      "Ending epoch 489: loss 0.0312964\n",
      "Ending epoch 490: loss 0.028101\n",
      "Ending epoch 491: loss 0.0288359\n",
      "Ending epoch 492: loss 0.0238997\n",
      "Ending epoch 493: loss 0.0256551\n",
      "Ending epoch 494: loss 0.0275646\n",
      "Ending epoch 495: loss 0.0287688\n",
      "Ending epoch 496: loss 0.0230305\n",
      "Ending epoch 497: loss 0.0295332\n",
      "Ending epoch 498: loss 0.0341521\n",
      "Ending epoch 499: loss 0.0248828\n",
      "Model 7/8, Metric mean_absolute_error, Validation set 6: 35.971140\n",
      "\tbest_validation_score so far: 21.384058\n",
      "Fitting model 8/8\n",
      "hyperparameters: {u'optimizer': u'momentum', u'layer_sizes': [1000, 1000, 500], u'data_shape': (23,), u'learning_rate': 0.0001, u'batch_size': 100, u'penalty': 0.0, u'bias_init_consts': [1.0, 1.0, 1.0], u'weight_init_stddevs': [0.077459666924148338, 0.077459666924148338, 0.077459666924148338], u'num_regression_tasks': 1, u'dropouts': [0.1, 0.1, 0.1], u'nb_epoch': 500, u'momentum': 0.9}\n",
      "Training for 500 epochs\n",
      "Ending epoch 0: loss 7.86427\n",
      "Ending epoch 1: loss 3.44461\n",
      "Ending epoch 2: loss 1.82791\n",
      "Ending epoch 3: loss 1.92167\n",
      "Ending epoch 4: loss 1.37144\n",
      "Ending epoch 5: loss 1.52044\n",
      "Ending epoch 6: loss 1.01519\n",
      "Ending epoch 7: loss 0.951122\n",
      "Ending epoch 8: loss 1.13485\n",
      "Ending epoch 9: loss 1.02695\n",
      "Ending epoch 10: loss 0.788006\n",
      "Ending epoch 11: loss 0.828356\n",
      "Ending epoch 12: loss 0.624518\n",
      "Ending epoch 13: loss 0.724442\n",
      "Ending epoch 14: loss 0.514025\n",
      "Ending epoch 15: loss 0.424347\n",
      "Ending epoch 16: loss 0.332242\n",
      "Ending epoch 17: loss 0.500201\n",
      "Ending epoch 18: loss 0.473081\n",
      "Ending epoch 19: loss 0.424275\n",
      "Ending epoch 20: loss 0.479657\n",
      "Ending epoch 21: loss 0.413912\n",
      "Ending epoch 22: loss 0.311864\n",
      "Ending epoch 23: loss 0.358227\n",
      "Ending epoch 24: loss 0.250556\n",
      "Ending epoch 25: loss 0.333107\n",
      "Ending epoch 26: loss 0.221395\n",
      "Ending epoch 27: loss 0.266585\n",
      "Ending epoch 28: loss 0.270487\n",
      "Ending epoch 29: loss 0.303176\n",
      "Ending epoch 30: loss 0.273355\n",
      "Ending epoch 31: loss 0.217057\n",
      "Ending epoch 32: loss 0.210118\n",
      "Ending epoch 33: loss 0.212\n",
      "Ending epoch 34: loss 0.185847\n",
      "Ending epoch 35: loss 0.173581\n",
      "Ending epoch 36: loss 0.253689\n",
      "Ending epoch 37: loss 0.2118\n",
      "Ending epoch 38: loss 0.17117\n",
      "Ending epoch 39: loss 0.17355\n",
      "Ending epoch 40: loss 0.164379\n",
      "Ending epoch 41: loss 0.193096\n",
      "Ending epoch 42: loss 0.158527\n",
      "Ending epoch 43: loss 0.15341\n",
      "Ending epoch 44: loss 0.136748\n",
      "Ending epoch 45: loss 0.147622\n",
      "Ending epoch 46: loss 0.145761\n",
      "Ending epoch 47: loss 0.142061\n",
      "Ending epoch 48: loss 0.163266\n",
      "Ending epoch 49: loss 0.142986\n",
      "Ending epoch 50: loss 0.107605\n",
      "Ending epoch 51: loss 0.137268\n",
      "Ending epoch 52: loss 0.128404\n",
      "Ending epoch 53: loss 0.142937\n",
      "Ending epoch 54: loss 0.164456\n",
      "Ending epoch 55: loss 0.10178\n",
      "Ending epoch 56: loss 0.150875\n",
      "Ending epoch 57: loss 0.130293\n",
      "Ending epoch 58: loss 0.1202\n",
      "Ending epoch 59: loss 0.115179\n",
      "Ending epoch 60: loss 0.112582\n",
      "Ending epoch 61: loss 0.0990931\n",
      "Ending epoch 62: loss 0.124209\n",
      "Ending epoch 63: loss 0.0837555\n",
      "Ending epoch 64: loss 0.0902165\n",
      "Ending epoch 65: loss 0.0959154\n",
      "Ending epoch 66: loss 0.0995988\n",
      "Ending epoch 67: loss 0.0889336\n",
      "Ending epoch 68: loss 0.112077\n",
      "Ending epoch 69: loss 0.114945\n",
      "Ending epoch 70: loss 0.108124\n",
      "Ending epoch 71: loss 0.0833776\n",
      "Ending epoch 72: loss 0.0985395\n",
      "Ending epoch 73: loss 0.0831664\n",
      "Ending epoch 74: loss 0.0904218\n",
      "Ending epoch 75: loss 0.0857039\n",
      "Ending epoch 76: loss 0.0953446\n",
      "Ending epoch 77: loss 0.0941759\n",
      "Ending epoch 78: loss 0.0792728\n",
      "Ending epoch 79: loss 0.113657\n",
      "Ending epoch 80: loss 0.10063\n",
      "Ending epoch 81: loss 0.121548\n",
      "Ending epoch 82: loss 0.106858\n",
      "Ending epoch 83: loss 0.0869412\n",
      "Ending epoch 84: loss 0.0823424\n",
      "Ending epoch 85: loss 0.103334\n",
      "Ending epoch 86: loss 0.087475\n",
      "Ending epoch 87: loss 0.110385\n",
      "Ending epoch 88: loss 0.0733398\n",
      "Ending epoch 89: loss 0.0645845\n",
      "Ending epoch 90: loss 0.0823629\n",
      "Ending epoch 91: loss 0.0836413\n",
      "Ending epoch 92: loss 0.0794475\n",
      "Ending epoch 93: loss 0.0783997\n",
      "Ending epoch 94: loss 0.0579445\n",
      "Ending epoch 95: loss 0.0718761\n",
      "Ending epoch 96: loss 0.0723969\n",
      "Ending epoch 97: loss 0.0823998\n",
      "Ending epoch 98: loss 0.0725921\n",
      "Ending epoch 99: loss 0.0556752\n",
      "Ending epoch 100: loss 0.0798948\n",
      "Ending epoch 101: loss 0.0677044\n",
      "Ending epoch 102: loss 0.0627451\n",
      "Ending epoch 103: loss 0.0688781\n",
      "Ending epoch 104: loss 0.0950347\n",
      "Ending epoch 105: loss 0.0528579\n",
      "Ending epoch 106: loss 0.0558533\n",
      "Ending epoch 107: loss 0.066406\n",
      "Ending epoch 108: loss 0.0602856\n",
      "Ending epoch 109: loss 0.0768202\n",
      "Ending epoch 110: loss 0.0565012\n",
      "Ending epoch 111: loss 0.0655492\n",
      "Ending epoch 112: loss 0.0629523\n",
      "Ending epoch 113: loss 0.0546388\n",
      "Ending epoch 114: loss 0.073333\n",
      "Ending epoch 115: loss 0.0695584\n",
      "Ending epoch 116: loss 0.0550426\n",
      "Ending epoch 117: loss 0.0618714\n",
      "Ending epoch 118: loss 0.0509619\n",
      "Ending epoch 119: loss 0.0657733\n",
      "Ending epoch 120: loss 0.0546248\n",
      "Ending epoch 121: loss 0.0625092\n",
      "Ending epoch 122: loss 0.0743073\n",
      "Ending epoch 123: loss 0.0458883\n",
      "Ending epoch 124: loss 0.0542684\n",
      "Ending epoch 125: loss 0.0749837\n",
      "Ending epoch 126: loss 0.0648025\n",
      "Ending epoch 127: loss 0.0436228\n",
      "Ending epoch 128: loss 0.0552434\n",
      "Ending epoch 129: loss 0.0749527\n",
      "Ending epoch 130: loss 0.0726212\n",
      "Ending epoch 131: loss 0.0653533\n",
      "Ending epoch 132: loss 0.0748671\n",
      "Ending epoch 133: loss 0.0605552\n",
      "Ending epoch 134: loss 0.0528465\n",
      "Ending epoch 135: loss 0.0524211\n",
      "Ending epoch 136: loss 0.0379669\n",
      "Ending epoch 137: loss 0.0673058\n",
      "Ending epoch 138: loss 0.0476412\n",
      "Ending epoch 139: loss 0.0498268\n",
      "Ending epoch 140: loss 0.0517713\n",
      "Ending epoch 141: loss 0.0637408\n",
      "Ending epoch 142: loss 0.0611013\n",
      "Ending epoch 143: loss 0.0654392\n",
      "Ending epoch 144: loss 0.0784701\n",
      "Ending epoch 145: loss 0.051705\n",
      "Ending epoch 146: loss 0.0602098\n",
      "Ending epoch 147: loss 0.0408115\n",
      "Ending epoch 148: loss 0.0478411\n",
      "Ending epoch 149: loss 0.0482048\n",
      "Ending epoch 150: loss 0.0464488\n",
      "Ending epoch 151: loss 0.0484885\n",
      "Ending epoch 152: loss 0.0353227\n",
      "Ending epoch 153: loss 0.0547592\n",
      "Ending epoch 154: loss 0.051715\n",
      "Ending epoch 155: loss 0.0592472\n",
      "Ending epoch 156: loss 0.0510577\n",
      "Ending epoch 157: loss 0.0584933\n",
      "Ending epoch 158: loss 0.0577066\n",
      "Ending epoch 159: loss 0.0450167\n",
      "Ending epoch 160: loss 0.0474495\n",
      "Ending epoch 161: loss 0.0656516\n",
      "Ending epoch 162: loss 0.0499955\n",
      "Ending epoch 163: loss 0.0460442\n",
      "Ending epoch 164: loss 0.0473999\n",
      "Ending epoch 165: loss 0.0473068\n",
      "Ending epoch 166: loss 0.0428915\n",
      "Ending epoch 167: loss 0.0459062\n",
      "Ending epoch 168: loss 0.0535748\n",
      "Ending epoch 169: loss 0.0346391\n",
      "Ending epoch 170: loss 0.0508319\n",
      "Ending epoch 171: loss 0.0440596\n",
      "Ending epoch 172: loss 0.0508616\n",
      "Ending epoch 173: loss 0.0327857\n",
      "Ending epoch 174: loss 0.0486283\n",
      "Ending epoch 175: loss 0.0394715\n",
      "Ending epoch 176: loss 0.0476849\n",
      "Ending epoch 177: loss 0.040569\n",
      "Ending epoch 178: loss 0.0542928\n",
      "Ending epoch 179: loss 0.0480327\n",
      "Ending epoch 180: loss 0.0388713\n",
      "Ending epoch 181: loss 0.0371291\n",
      "Ending epoch 182: loss 0.0346571\n",
      "Ending epoch 183: loss 0.0396392\n",
      "Ending epoch 184: loss 0.0612983\n",
      "Ending epoch 185: loss 0.0458832\n",
      "Ending epoch 186: loss 0.0440631\n",
      "Ending epoch 187: loss 0.0476453\n",
      "Ending epoch 188: loss 0.0500905\n",
      "Ending epoch 189: loss 0.0576798\n",
      "Ending epoch 190: loss 0.045812\n",
      "Ending epoch 191: loss 0.0576399\n",
      "Ending epoch 192: loss 0.053698\n",
      "Ending epoch 193: loss 0.0481434\n",
      "Ending epoch 194: loss 0.0464298\n",
      "Ending epoch 195: loss 0.0463138\n",
      "Ending epoch 196: loss 0.0485086\n",
      "Ending epoch 197: loss 0.0455561\n",
      "Ending epoch 198: loss 0.0636641\n",
      "Ending epoch 199: loss 0.0525071\n",
      "Ending epoch 200: loss 0.0300165\n",
      "Ending epoch 201: loss 0.0652407\n",
      "Ending epoch 202: loss 0.0487514\n",
      "Ending epoch 203: loss 0.0627101\n",
      "Ending epoch 204: loss 0.0465962\n",
      "Ending epoch 205: loss 0.0414752\n",
      "Ending epoch 206: loss 0.0438995\n",
      "Ending epoch 207: loss 0.0534857\n",
      "Ending epoch 208: loss 0.0455953\n",
      "Ending epoch 209: loss 0.0308208\n",
      "Ending epoch 210: loss 0.0334749\n",
      "Ending epoch 211: loss 0.0465884\n",
      "Ending epoch 212: loss 0.0462759\n",
      "Ending epoch 213: loss 0.0531159\n",
      "Ending epoch 214: loss 0.0483057\n",
      "Ending epoch 215: loss 0.0353686\n",
      "Ending epoch 216: loss 0.0588491\n",
      "Ending epoch 217: loss 0.047356\n",
      "Ending epoch 218: loss 0.0288437\n",
      "Ending epoch 219: loss 0.0399138\n",
      "Ending epoch 220: loss 0.0437285\n",
      "Ending epoch 221: loss 0.0292374\n",
      "Ending epoch 222: loss 0.0395103\n",
      "Ending epoch 223: loss 0.0401783\n",
      "Ending epoch 224: loss 0.0386999\n",
      "Ending epoch 225: loss 0.0462637\n",
      "Ending epoch 226: loss 0.0435949\n",
      "Ending epoch 227: loss 0.0459274\n",
      "Ending epoch 228: loss 0.0464837\n",
      "Ending epoch 229: loss 0.0383695\n",
      "Ending epoch 230: loss 0.0396543\n",
      "Ending epoch 231: loss 0.0414199\n",
      "Ending epoch 232: loss 0.0411036\n",
      "Ending epoch 233: loss 0.0384353\n",
      "Ending epoch 234: loss 0.042003\n",
      "Ending epoch 235: loss 0.034065\n",
      "Ending epoch 236: loss 0.0373466\n",
      "Ending epoch 237: loss 0.0373471\n",
      "Ending epoch 238: loss 0.0326777\n",
      "Ending epoch 239: loss 0.0361071\n",
      "Ending epoch 240: loss 0.0335093\n",
      "Ending epoch 241: loss 0.0319039\n",
      "Ending epoch 242: loss 0.0346644\n",
      "Ending epoch 243: loss 0.0436923\n",
      "Ending epoch 244: loss 0.0537688\n",
      "Ending epoch 245: loss 0.0408744\n",
      "Ending epoch 246: loss 0.0385737\n",
      "Ending epoch 247: loss 0.0449122\n",
      "Ending epoch 248: loss 0.0477628\n",
      "Ending epoch 249: loss 0.0268892\n",
      "Ending epoch 250: loss 0.044196\n",
      "Ending epoch 251: loss 0.0375662\n",
      "Ending epoch 252: loss 0.0501115\n",
      "Ending epoch 253: loss 0.0388038\n",
      "Ending epoch 254: loss 0.0374194\n",
      "Ending epoch 255: loss 0.0276785\n",
      "Ending epoch 256: loss 0.0270022\n",
      "Ending epoch 257: loss 0.0374215\n",
      "Ending epoch 258: loss 0.0494273\n",
      "Ending epoch 259: loss 0.0386983\n",
      "Ending epoch 260: loss 0.0331284\n",
      "Ending epoch 261: loss 0.0478166\n",
      "Ending epoch 262: loss 0.0392323\n",
      "Ending epoch 263: loss 0.0308885\n",
      "Ending epoch 264: loss 0.0339497\n",
      "Ending epoch 265: loss 0.0396705\n",
      "Ending epoch 266: loss 0.0342017\n",
      "Ending epoch 267: loss 0.0290674\n",
      "Ending epoch 268: loss 0.0437478\n",
      "Ending epoch 269: loss 0.044201\n",
      "Ending epoch 270: loss 0.0423607\n",
      "Ending epoch 271: loss 0.0301664\n",
      "Ending epoch 272: loss 0.034038\n",
      "Ending epoch 273: loss 0.0445117\n",
      "Ending epoch 274: loss 0.0349708\n",
      "Ending epoch 275: loss 0.0362243\n",
      "Ending epoch 276: loss 0.0320949\n",
      "Ending epoch 277: loss 0.0339746\n",
      "Ending epoch 278: loss 0.0380599\n",
      "Ending epoch 279: loss 0.032025\n",
      "Ending epoch 280: loss 0.0342025\n",
      "Ending epoch 281: loss 0.0455277\n",
      "Ending epoch 282: loss 0.0339424\n",
      "Ending epoch 283: loss 0.0411624\n",
      "Ending epoch 284: loss 0.0363538\n",
      "Ending epoch 285: loss 0.0479905\n",
      "Ending epoch 286: loss 0.0413998\n",
      "Ending epoch 287: loss 0.0313573\n",
      "Ending epoch 288: loss 0.0410124\n",
      "Ending epoch 289: loss 0.0346359\n",
      "Ending epoch 290: loss 0.0425075\n",
      "Ending epoch 291: loss 0.039358\n",
      "Ending epoch 292: loss 0.0315403\n",
      "Ending epoch 293: loss 0.0390963\n",
      "Ending epoch 294: loss 0.043805\n",
      "Ending epoch 295: loss 0.038683\n",
      "Ending epoch 296: loss 0.0413378\n",
      "Ending epoch 297: loss 0.040266\n",
      "Ending epoch 298: loss 0.0366916\n",
      "Ending epoch 299: loss 0.0326223\n",
      "Ending epoch 300: loss 0.0448598\n",
      "Ending epoch 301: loss 0.0342664\n",
      "Ending epoch 302: loss 0.038245\n",
      "Ending epoch 303: loss 0.0285179\n",
      "Ending epoch 304: loss 0.0323541\n",
      "Ending epoch 305: loss 0.0245739\n",
      "Ending epoch 306: loss 0.0394771\n",
      "Ending epoch 307: loss 0.032012\n",
      "Ending epoch 308: loss 0.0393906\n",
      "Ending epoch 309: loss 0.0495967\n",
      "Ending epoch 310: loss 0.0361271\n",
      "Ending epoch 311: loss 0.0347722\n",
      "Ending epoch 312: loss 0.0410835\n",
      "Ending epoch 313: loss 0.0358115\n",
      "Ending epoch 314: loss 0.031657\n",
      "Ending epoch 315: loss 0.0367995\n",
      "Ending epoch 316: loss 0.040018\n",
      "Ending epoch 317: loss 0.0275806\n",
      "Ending epoch 318: loss 0.0409349\n",
      "Ending epoch 319: loss 0.0341753\n",
      "Ending epoch 320: loss 0.0383809\n",
      "Ending epoch 321: loss 0.035618\n",
      "Ending epoch 322: loss 0.0356942\n",
      "Ending epoch 323: loss 0.032899\n",
      "Ending epoch 324: loss 0.0397155\n",
      "Ending epoch 325: loss 0.0273819\n",
      "Ending epoch 326: loss 0.036256\n",
      "Ending epoch 327: loss 0.0309928\n",
      "Ending epoch 328: loss 0.0348359\n",
      "Ending epoch 329: loss 0.0307468\n",
      "Ending epoch 330: loss 0.0349793\n",
      "Ending epoch 331: loss 0.0358001\n",
      "Ending epoch 332: loss 0.0324878\n",
      "Ending epoch 333: loss 0.0353531\n",
      "Ending epoch 334: loss 0.0328197\n",
      "Ending epoch 335: loss 0.0392669\n",
      "Ending epoch 336: loss 0.0334984\n",
      "Ending epoch 337: loss 0.0354626\n",
      "Ending epoch 338: loss 0.0522084\n",
      "Ending epoch 339: loss 0.0362104\n",
      "Ending epoch 340: loss 0.0367876\n",
      "Ending epoch 341: loss 0.0263377\n",
      "Ending epoch 342: loss 0.0260867\n",
      "Ending epoch 343: loss 0.0398016\n",
      "Ending epoch 344: loss 0.0333395\n",
      "Ending epoch 345: loss 0.0296697\n",
      "Ending epoch 346: loss 0.0258614\n",
      "Ending epoch 347: loss 0.0287347\n",
      "Ending epoch 348: loss 0.0370753\n",
      "Ending epoch 349: loss 0.0255461\n",
      "Ending epoch 350: loss 0.0374319\n",
      "Ending epoch 351: loss 0.029068\n",
      "Ending epoch 352: loss 0.0321867\n",
      "Ending epoch 353: loss 0.0256878\n",
      "Ending epoch 354: loss 0.0299035\n",
      "Ending epoch 355: loss 0.0313418\n",
      "Ending epoch 356: loss 0.0212562\n",
      "Ending epoch 357: loss 0.0348227\n",
      "Ending epoch 358: loss 0.0287568\n",
      "Ending epoch 359: loss 0.0375504\n",
      "Ending epoch 360: loss 0.027111\n",
      "Ending epoch 361: loss 0.0405266\n",
      "Ending epoch 362: loss 0.033855\n",
      "Ending epoch 363: loss 0.0295966\n",
      "Ending epoch 364: loss 0.0274563\n",
      "Ending epoch 365: loss 0.0321125\n",
      "Ending epoch 366: loss 0.035027\n",
      "Ending epoch 367: loss 0.0457708\n",
      "Ending epoch 368: loss 0.0343111\n",
      "Ending epoch 369: loss 0.029459\n",
      "Ending epoch 370: loss 0.0308224\n",
      "Ending epoch 371: loss 0.0309198\n",
      "Ending epoch 372: loss 0.0322364\n",
      "Ending epoch 373: loss 0.030286\n",
      "Ending epoch 374: loss 0.0371058\n",
      "Ending epoch 375: loss 0.0341088\n",
      "Ending epoch 376: loss 0.0274703\n",
      "Ending epoch 377: loss 0.0421417\n",
      "Ending epoch 378: loss 0.0319009\n",
      "Ending epoch 379: loss 0.0322778\n",
      "Ending epoch 380: loss 0.0386406\n",
      "Ending epoch 381: loss 0.0312035\n",
      "Ending epoch 382: loss 0.0308281\n",
      "Ending epoch 383: loss 0.0283683\n",
      "Ending epoch 384: loss 0.038907\n",
      "Ending epoch 385: loss 0.044186\n",
      "Ending epoch 386: loss 0.0377301\n",
      "Ending epoch 387: loss 0.0273527\n",
      "Ending epoch 388: loss 0.0390866\n",
      "Ending epoch 389: loss 0.0343194\n",
      "Ending epoch 390: loss 0.0291142\n",
      "Ending epoch 391: loss 0.0335453\n",
      "Ending epoch 392: loss 0.0313769\n",
      "Ending epoch 393: loss 0.0359784\n",
      "Ending epoch 394: loss 0.0257409\n",
      "Ending epoch 395: loss 0.0299471\n",
      "Ending epoch 396: loss 0.035186\n",
      "Ending epoch 397: loss 0.0348339\n",
      "Ending epoch 398: loss 0.0265374\n",
      "Ending epoch 399: loss 0.0288601\n",
      "Ending epoch 400: loss 0.0264529\n",
      "Ending epoch 401: loss 0.035339\n",
      "Ending epoch 402: loss 0.0314583\n",
      "Ending epoch 403: loss 0.0255281\n",
      "Ending epoch 404: loss 0.0365387\n",
      "Ending epoch 405: loss 0.0274061\n",
      "Ending epoch 406: loss 0.0316069\n",
      "Ending epoch 407: loss 0.0308116\n",
      "Ending epoch 408: loss 0.032583\n",
      "Ending epoch 409: loss 0.0347161\n",
      "Ending epoch 410: loss 0.041206\n",
      "Ending epoch 411: loss 0.0385049\n",
      "Ending epoch 412: loss 0.0280802\n",
      "Ending epoch 413: loss 0.0292493\n",
      "Ending epoch 414: loss 0.0357604\n",
      "Ending epoch 415: loss 0.0435306\n",
      "Ending epoch 416: loss 0.0312374\n",
      "Ending epoch 417: loss 0.0320577\n",
      "Ending epoch 418: loss 0.0390281\n",
      "Ending epoch 419: loss 0.0277268\n",
      "Ending epoch 420: loss 0.0281568\n",
      "Ending epoch 421: loss 0.0330674\n",
      "Ending epoch 422: loss 0.0253351\n",
      "Ending epoch 423: loss 0.0282489\n",
      "Ending epoch 424: loss 0.0236883\n",
      "Ending epoch 425: loss 0.0311217\n",
      "Ending epoch 426: loss 0.026727\n",
      "Ending epoch 427: loss 0.035763\n",
      "Ending epoch 428: loss 0.0278901\n",
      "Ending epoch 429: loss 0.026716\n",
      "Ending epoch 430: loss 0.0346046\n",
      "Ending epoch 431: loss 0.0304206\n",
      "Ending epoch 432: loss 0.0285851\n",
      "Ending epoch 433: loss 0.0268029\n",
      "Ending epoch 434: loss 0.0333633\n",
      "Ending epoch 435: loss 0.0322143\n",
      "Ending epoch 436: loss 0.0232126\n",
      "Ending epoch 437: loss 0.0331702\n",
      "Ending epoch 438: loss 0.023414\n",
      "Ending epoch 439: loss 0.0317755\n",
      "Ending epoch 440: loss 0.0186299\n",
      "Ending epoch 441: loss 0.0316472\n",
      "Ending epoch 442: loss 0.0248883\n",
      "Ending epoch 443: loss 0.0325938\n",
      "Ending epoch 444: loss 0.026914\n",
      "Ending epoch 445: loss 0.0320422\n",
      "Ending epoch 446: loss 0.0338314\n",
      "Ending epoch 447: loss 0.0330613\n",
      "Ending epoch 448: loss 0.0317089\n",
      "Ending epoch 449: loss 0.022514\n",
      "Ending epoch 450: loss 0.0236501\n",
      "Ending epoch 451: loss 0.0328574\n",
      "Ending epoch 452: loss 0.0355056\n",
      "Ending epoch 453: loss 0.0235841\n",
      "Ending epoch 454: loss 0.0267778\n",
      "Ending epoch 455: loss 0.0285413\n",
      "Ending epoch 456: loss 0.03799\n",
      "Ending epoch 457: loss 0.0332879\n",
      "Ending epoch 458: loss 0.0247542\n",
      "Ending epoch 459: loss 0.0251183\n",
      "Ending epoch 460: loss 0.0274898\n",
      "Ending epoch 461: loss 0.0298134\n",
      "Ending epoch 462: loss 0.0243474\n",
      "Ending epoch 463: loss 0.0284634\n",
      "Ending epoch 464: loss 0.0341143\n",
      "Ending epoch 465: loss 0.0258836\n",
      "Ending epoch 466: loss 0.0281728\n",
      "Ending epoch 467: loss 0.0290098\n",
      "Ending epoch 468: loss 0.0298933\n",
      "Ending epoch 469: loss 0.0301373\n",
      "Ending epoch 470: loss 0.0350268\n",
      "Ending epoch 471: loss 0.0331108\n",
      "Ending epoch 472: loss 0.0331098\n",
      "Ending epoch 473: loss 0.0328853\n",
      "Ending epoch 474: loss 0.0299409\n",
      "Ending epoch 475: loss 0.0287946\n",
      "Ending epoch 476: loss 0.0288035\n",
      "Ending epoch 477: loss 0.0318899\n",
      "Ending epoch 478: loss 0.0263758\n",
      "Ending epoch 479: loss 0.028737\n",
      "Ending epoch 480: loss 0.0323076\n",
      "Ending epoch 481: loss 0.0292983\n",
      "Ending epoch 482: loss 0.0273778\n",
      "Ending epoch 483: loss 0.0274457\n",
      "Ending epoch 484: loss 0.0258739\n",
      "Ending epoch 485: loss 0.0314669\n",
      "Ending epoch 486: loss 0.0323526\n",
      "Ending epoch 487: loss 0.0317784\n",
      "Ending epoch 488: loss 0.0306264\n",
      "Ending epoch 489: loss 0.0187114\n",
      "Ending epoch 490: loss 0.0277504\n",
      "Ending epoch 491: loss 0.0352009\n",
      "Ending epoch 492: loss 0.0352761\n",
      "Ending epoch 493: loss 0.0265159\n",
      "Ending epoch 494: loss 0.0306231\n",
      "Ending epoch 495: loss 0.0328872\n",
      "Ending epoch 496: loss 0.0274772\n",
      "Ending epoch 497: loss 0.0288968\n",
      "Ending epoch 498: loss 0.0283409\n",
      "Ending epoch 499: loss 0.0375142\n",
      "Model 8/8, Metric mean_absolute_error, Validation set 7: 37.705721\n",
      "\tbest_validation_score so far: 21.384058\n",
      "Best hyperparameters: (u'rmsprop', (23,), 0.0001, 100, [1.0, 1.0, 1.0], [0.077459666924148338, 0.077459666924148338, 0.077459666924148338], [0.1, 0.1, 0.1], [1000, 1000, 500], 500, 0.0, 1, 0.9)\n",
      "train_score: 20.854382\n",
      "validation_score: 21.384058\n"
     ]
    }
   ],
   "source": [
    "def tf_model_builder(tasks, task_types, params_dict, model_dir, verbosity=None):\n",
    "    \"\"\"Builds tensorflow models given hyperparameters.\n",
    "\n",
    "    \"\"\"\n",
    "    return TensorflowModel(tasks, task_types, params_dict, model_dir,\n",
    "                        tf_class=TensorflowMultiTaskRegressor,\n",
    "                        verbosity=\"low\")\n",
    "\n",
    "params_dict = { \n",
    "    \"layer_sizes\": [[1000, 1000, 100],[1000, 1000, 50],[1000, 1000, 250],[1000, 1000, 500]],\n",
    "    \"dropouts\": [[.1, .1, .1]],\n",
    "    \"learning_rate\": [0.0001],\n",
    "    \"momentum\": [.9],\n",
    "    \"batch_size\": [100],\n",
    "    \"num_regression_tasks\": [len(tasks)],\n",
    "    \"weight_init_stddevs\": [[np.sqrt(6)/np.sqrt(1000), np.sqrt(6)/np.sqrt(1000), np.sqrt(6)/np.sqrt(1000)]],\n",
    "    \"bias_init_consts\": [[1., 1., 1.]],\n",
    "    \"nb_epoch\": [500],\n",
    "    \"penalty\": [0.0],\n",
    "    \"optimizer\": [\"rmsprop\", \"momentum\"],\n",
    "    \"data_shape\": [train_dataset.get_data_shape()],\n",
    "}   \n",
    "\n",
    "verbosity=\"high\"\n",
    "metric = Metric(metrics.mean_absolute_error)\n",
    "optimizer = HyperparamOpt(tf_model_builder, tasks, task_types, verbosity=verbosity)       \n",
    "best_model, best_hyperparams, all_results = optimizer.hyperparam_search(              \n",
    "    params_dict, train_dataset, valid_dataset, output_transformers,                     \n",
    "    metric, use_max=False, logdir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test scores\n",
      "{'mean_absolute_error': 23.479550284211136}\n"
     ]
    }
   ],
   "source": [
    "test_evaluator = Evaluator(best_model, test_dataset, transformers,\n",
    "                         verbosity=verbosity)\n",
    "test_scores = test_evaluator.compute_model_performance([metric])\n",
    "\n",
    "print(\"Test scores\")\n",
    "print(test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
